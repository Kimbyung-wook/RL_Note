{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('TORCH190': conda)",
   "metadata": {
    "interpreter": {
     "hash": "a62d03de4abdbf02f2c70aa26fad76bfe5b246d84e1d7929e4e42191e53d635f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from collections import deque\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, state_size, action_size):\n",
    "        super(DQN, self).__init__()\n",
    "        self.device = device\n",
    "        # Neural Net Layers\n",
    "        self.fc1 = nn.Linear(state_size, 24)\n",
    "        self.fc2 = nn.Linear(24, 24)\n",
    "        self.out = nn.Linear(24,action_size)\n",
    "        # Random Uniform\n",
    "        torch.nn.init.uniform_(self.out.weight,-1e-3,1e-3)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        q = self.out(x)\n",
    "        return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size, device):\n",
    "        self.state_size = state_size\n",
    "        self.action_size= action_size\n",
    "        self.device = device\n",
    "        \n",
    "        # Hyper-parameters for learning\n",
    "        self.discount_factor = 0.99\n",
    "        self.learning_rate = 0.001\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_decay = 0.999\n",
    "        self.epsilon_min = 0.01\n",
    "        \n",
    "        # Experience Replay\n",
    "        self.batch_size = 64\n",
    "        self.train_start = 1000\n",
    "        self.buffer_length = 2000\n",
    "        self.memory = deque(maxlen=self.buffer_length)\n",
    "\n",
    "        # Neural Network Architecture\n",
    "        self.model        = DQN(self.state_size, self.action_size).to(self.device)\n",
    "        self.target_model = DQN(self.state_size, self.action_size).to(self.device)\n",
    "        self.optimizer    = optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "        \n",
    "        self.update_target_model()\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        # self.memory.append((torch.FloatTensor([state]), \\\n",
    "        #                     torch.LongTensor([action]), \\\n",
    "        #                     torch.FloatTensor([reward]), \\\n",
    "        #                     torch.FloatTensor([next_state]),\\\n",
    "        #                     torch.LongTensor([done])))\n",
    "\n",
    "        self.memory.append((state,\\\n",
    "                            action.to(self.device),\\\n",
    "                            torch.FloatTensor([reward]).to(self.device),\\\n",
    "                            torch.FloatTensor([next_state]).to(self.device),\\\n",
    "                            torch.LongTensor([done]).to(self.device)))\n",
    "\n",
    "    def update_target_model(self):\n",
    "        self.target_model.load_state_dict(self.model.state_dict())\n",
    "        # self.target_model.load_dict(self.model.state_dict())\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        # Exploration and Exploitation\n",
    "        if (np.random.rand() <= self.epsilon):\n",
    "            return torch.LongTensor([[random.randrange(self.action_size)]])\n",
    "        else:\n",
    "            return self.model.forward(state).max(1)[1].view(1, 1)\n",
    "\n",
    "    def train_model(self, state, action, reward, next_state, done):\n",
    "        # Train from Experience Replay\n",
    "        # Training Condition - Memory Size\n",
    "        if len(self.memory) < self.train_start:\n",
    "            return 0.0\n",
    "        # Decaying Exploration Ratio\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "        # Sampling from the memory\n",
    "        mini_batch  = random.sample(self.memory, self.batch_size)\n",
    "        batch_states, batch_actions, batch_rewards, batch_next_states, batch_dones = zip(*mini_batch)\n",
    "\n",
    "        states      = torch.cat(batch_states)\n",
    "        actions     = torch.cat(batch_actions)\n",
    "        rewards     = torch.cat(batch_rewards)\n",
    "        next_states = torch.cat(batch_next_states)\n",
    "        dones       = torch.cat(batch_dones)\n",
    "\n",
    "        q           = self.model.forward(states).gather(1,actions).squeeze()\n",
    "        max_q       = self.target_model.forward(next_states).detach().max(1)[0]\n",
    "        target      = rewards + (1 - dones) * self.discount_factor * max_q\n",
    "        loss        = F.mse_loss(q,target)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return loss.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "4, -0.0726, -0.8964]], device='cuda:0'), tensor([[-0.0713, -1.1374,  0.0977,  1.7950]], device='cuda:0'), tensor([[ 0.0562,  0.5651, -0.0124, -0.8669]], device='cuda:0'), tensor([[ 0.1035,  0.5861, -0.1868, -1.0808]], device='cuda:0'), tensor([[ 0.0143,  0.2128, -0.0537, -0.4642]], device='cuda:0'), tensor([[-0.0256, -0.1796,  0.0281,  0.3183]], device='cuda:0'), tensor([[-0.0280,  0.0224,  0.0082, -0.0079]], device='cuda:0'), tensor([[-0.0288, -0.1494,  0.0156,  0.3036]], device='cuda:0'))\n",
      "tensor([[-1.0341e-01, -3.6552e-01,  4.4091e-02,  5.2817e-01],\n",
      "        [ 7.7043e-02,  9.9891e-01, -3.1644e-05, -1.0463e+00],\n",
      "        [ 1.7822e-02,  5.5342e-01, -2.1207e-02, -8.7701e-01],\n",
      "        [-1.6200e-02, -3.8768e-01,  1.6046e-01,  1.0104e+00],\n",
      "        [ 5.9879e-02,  1.0030e+00, -1.5947e-01, -1.6811e+00],\n",
      "        [ 3.2118e-02,  2.6314e-02,  4.9648e-02,  8.1083e-02],\n",
      "        [ 3.2259e-02, -1.8608e-01, -4.3311e-02,  1.4155e-01],\n",
      "        [ 2.1092e-02,  1.5292e-01, -9.0927e-02, -4.6510e-01],\n",
      "        [ 5.2524e-02,  5.9461e-01, -3.7949e-02, -7.1384e-01],\n",
      "        [ 5.5341e-02,  2.4225e-01, -4.8538e-02, -3.5473e-01],\n",
      "        [ 6.8576e-01,  1.4624e+00, -3.1391e-03, -4.9653e-01],\n",
      "        [-5.7436e-03,  1.5549e-01,  4.0700e-04, -2.7160e-01],\n",
      "        [ 8.0266e-02, -1.4649e-02, -5.9617e-02, -1.1194e-01],\n",
      "        [-4.0009e-02,  2.0828e-01,  5.4809e-02, -2.1481e-01],\n",
      "        [ 2.8730e-02, -1.8488e-01, -4.3769e-02,  1.1517e-01],\n",
      "        [-2.3434e-02,  2.0567e-01,  3.9562e-02, -1.5705e-01],\n",
      "        [-3.2092e-02, -1.5376e-01,  3.4961e-02,  3.1167e-01],\n",
      "        [-1.1781e-01,  1.7547e-01,  1.6423e-01,  7.7646e-02],\n",
      "        [ 3.3063e-03,  6.0806e-01, -6.6679e-02, -9.7611e-01],\n",
      "        [ 1.4296e-02,  5.7809e-01, -4.4213e-02, -8.8719e-01],\n",
      "        [ 4.6152e-02,  9.2856e-01,  1.2195e-02, -1.3153e+00],\n",
      "        [-1.6297e-02,  2.4087e-01,  2.7467e-02, -2.3824e-01],\n",
      "        [-4.1655e-02, -1.1688e+00,  8.1697e-02,  1.7119e+00],\n",
      "        [ 3.7332e-01,  1.4678e+00,  6.8222e-02, -6.1836e-01],\n",
      "        [-4.0891e-03,  5.8805e-01,  2.2897e-02, -8.8939e-01],\n",
      "        [-5.6501e-03,  1.6342e-01,  1.9388e-02, -2.9713e-01],\n",
      "        [-8.0890e-02, -3.9099e-01,  1.1235e-01,  6.5329e-01],\n",
      "        [ 2.2619e-02,  1.4773e-02, -6.2701e-02, -2.7810e-01],\n",
      "        [ 5.6706e-02,  7.4612e-01, -1.1723e-01, -1.2861e+00],\n",
      "        [-5.2797e-02,  2.4257e-02, -2.7235e-02, -4.7389e-02],\n",
      "        [ 1.1518e-01,  7.8316e-01, -2.0845e-01, -1.4258e+00],\n",
      "        [-6.5878e-03, -4.0692e-01,  2.7091e-02,  6.3813e-01],\n",
      "        [ 4.3649e-02, -1.8762e-01, -5.5830e-02,  1.7570e-01],\n",
      "        [ 7.3266e-02,  9.7161e-01, -2.0616e-02, -1.3673e+00],\n",
      "        [ 3.7852e-02,  3.1079e-02, -1.3385e-01, -4.7028e-01],\n",
      "        [ 3.9492e-02,  2.0113e-01, -4.6294e-02, -3.7726e-01],\n",
      "        [ 1.7204e-01,  2.2702e-01, -6.4011e-02, -6.5197e-02],\n",
      "        [-5.8635e-02,  5.8861e-01, -1.9787e-01, -1.5336e+00],\n",
      "        [-5.0644e-02, -4.4096e-01,  8.4246e-02,  7.0937e-01],\n",
      "        [ 1.3258e-01,  4.0843e-01, -1.9937e-01, -9.8541e-01],\n",
      "        [-2.8406e-02,  3.5903e-01, -2.8595e-02, -5.8745e-01],\n",
      "        [ 1.0830e+00,  1.6746e+00, -1.8775e-01, -1.1842e+00],\n",
      "        [-3.4987e-02,  1.6558e-01,  2.2366e-02, -1.9941e-01],\n",
      "        [ 4.8617e-03, -3.4284e-01,  5.6567e-02,  6.5238e-01],\n",
      "        [ 1.4450e-02, -2.4207e-01, -9.2135e-03,  3.3159e-01],\n",
      "        [ 7.1628e-02,  5.5267e-01, -1.4295e-01, -1.0323e+00],\n",
      "        [-8.0937e-02, -5.5014e-01,  1.3518e-01,  1.0723e+00],\n",
      "        [-7.4051e-04,  1.4761e-01, -3.8671e-02, -3.4646e-01],\n",
      "        [-5.5395e-04, -3.7397e-01, -1.4079e-02,  5.9499e-01],\n",
      "        [-5.5311e-02, -5.4763e-01,  1.7633e-01,  1.1735e+00],\n",
      "        [ 6.6456e-03,  3.8253e-01, -3.2524e-02, -5.8444e-01],\n",
      "        [-2.6024e-01, -1.9022e+00,  9.4106e-02,  2.0705e+00],\n",
      "        [ 1.8647e-02, -3.7912e-02, -1.0314e-01, -2.6662e-01],\n",
      "        [ 2.1576e-02,  1.2076e-02, -4.3519e-02, -2.1829e-01],\n",
      "        [ 9.0770e-03,  1.4880e-01, -5.8622e-02, -3.7310e-01],\n",
      "        [-2.1225e-02,  5.5454e-01, -4.0344e-02, -8.8900e-01],\n",
      "        [ 3.7111e-02,  5.4743e-01, -7.2596e-02, -8.9636e-01],\n",
      "        [-7.1262e-02, -1.1374e+00,  9.7702e-02,  1.7950e+00],\n",
      "        [ 5.6215e-02,  5.6515e-01, -1.2386e-02, -8.6690e-01],\n",
      "        [ 1.0346e-01,  5.8613e-01, -1.8683e-01, -1.0808e+00],\n",
      "        [ 1.4258e-02,  2.1281e-01, -5.3736e-02, -4.6423e-01],\n",
      "        [-2.5586e-02, -1.7957e-01,  2.8079e-02,  3.1828e-01],\n",
      "        [-2.8015e-02,  2.2441e-02,  8.2484e-03, -7.9373e-03],\n",
      "        [-2.8838e-02, -1.4939e-01,  1.5577e-02,  3.0363e-01]], device='cuda:0')\n",
      "torch.Size([64, 4])\n",
      "tensor([[0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1]], device='cuda:0')\n",
      "torch.Size([64, 1])\n",
      "tensor([ 0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,\n",
      "         0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,\n",
      "         0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,\n",
      "         0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000, -1.0000,  0.1000,\n",
      "         0.1000,  0.1000,  0.1000,  0.1000,  0.1000, -1.0000,  0.1000, -1.0000,\n",
      "         0.1000, -1.0000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,\n",
      "         0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,\n",
      "         0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000],\n",
      "       device='cuda:0')\n",
      "torch.Size([64])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64])\n",
      "(tensor([[-0.0722, -0.8334,  0.1190,  1.3492]], device='cuda:0'), tensor([[ 0.0553,  0.2422, -0.0485, -0.3547]], device='cuda:0'), tensor([[ 0.1867,  0.0399, -0.1697, -0.1723]], device='cuda:0'), tensor([[-0.1090, -0.0052, -0.0503, -0.4436]], device='cuda:0'), tensor([[ 0.0410, -0.2128,  0.0211,  0.3012]], device='cuda:0'), tensor([[-0.0764, -0.5470,  0.1743,  1.1109]], device='cuda:0'), tensor([[-0.0053, -0.0046, -0.0043,  0.0298]], device='cuda:0'), tensor([[ 0.8633,  1.6599, -0.1006, -0.8450]], device='cuda:0'), tensor([[ 0.0438, -0.1934, -0.0382,  0.2497]], device='cuda:0'), tensor([[ 0.5043,  1.2690,  0.0334, -0.2420]], device='cuda:0'), tensor([[-0.0483,  0.1676,  0.0405, -0.2452]], device='cuda:0'), tensor([[ 0.0324,  0.0227,  0.0251, -0.0152]], device='cuda:0'), tensor([[ 0.0049,  0.5559, -0.0820, -0.9202]], device='cuda:0'), tensor([[-0.1046, -0.0084,  0.1575,  0.2369]], device='cuda:0'), tensor([[0.0282, 0.0502, 0.0062, 0.0054]], device='cuda:0'), tensor([[ 0.0716,  0.3738, -0.2082, -0.9324]], device='cuda:0'), tensor([[ 0.0683,  0.1990, -0.1198, -0.4540]], device='cuda:0'), tensor([[-0.0125,  0.3823, -0.0035, -0.5786]], device='cuda:0'), tensor([[-0.0420, -0.3670, -0.0436,  0.5614]], device='cuda:0'), tensor([[-0.0311,  0.5366,  0.1569, -0.1344]], device='cuda:0'), tensor([[ 0.0927,  0.1722, -0.1968, -0.6655]], device='cuda:0'), tensor([[ 0.0629,  0.6125, -0.0024, -0.7658]], device='cuda:0'), tensor([[ 0.1568,  0.7394, -0.1471, -1.1635]], device='cuda:0'), tensor([[ 0.2339,  1.2075, -0.1332, -1.6473]], device='cuda:0'), tensor([[ 0.1326,  0.6157, -0.0904, -0.8391]], device='cuda:0'), tensor([[0.0307, 0.0189, 0.0358, 0.0523]], device='cuda:0'), tensor([[-0.0124, -0.1909,  0.1470,  0.6753]], device='cuda:0'), tensor([[-0.1178,  0.1755,  0.1642,  0.0776]], device='cuda:0'), tensor([[-0.1397, -0.9620,  0.1932,  1.6767]], device='cuda:0'), tensor([[ 0.1611,  0.6183, -0.1304, -0.9016]], device='cuda:0'), tensor([[ 0.0185,  0.2400, -0.0141, -0.2196]], device='cuda:0'), tensor([[-0.0361, -0.1610,  0.0693,  0.4720]], device='cuda:0'), tensor([[ 0.0565,  0.1962, -0.0977, -0.3899]], device='cuda:0'), tensor([[ 0.0209, -0.2151, -0.1908, -0.3754]], device='cuda:0'), tensor([[ 0.0368,  0.3718, -0.0473, -0.6087]], device='cuda:0'), tensor([[ 0.0185,  0.4086, -0.0630, -0.7734]], device='cuda:0'), tensor([[-0.0016,  0.3857, -0.0090, -0.5581]], device='cuda:0'), tensor([[-0.2261, -1.7065,  0.0589,  1.7601]], device='cuda:0'), tensor([[-0.0748, -0.2200,  0.1425,  0.5175]], device='cuda:0'), tensor([[-0.0348, -0.0138, -0.0094, -0.0075]], device='cuda:0'), tensor([[ 0.0206,  0.2036, -0.0054, -0.1102]], device='cuda:0'), tensor([[ 0.0271,  0.9180,  0.1289, -0.5264]], device='cuda:0'), tensor([[-0.0232,  0.0222,  0.0021, -0.0028]], device='cuda:0'), tensor([[-0.1062, -1.1217, -0.0407,  0.8941]], device='cuda:0'), tensor([[ 0.0285,  0.0096, -0.0405, -0.1645]], device='cuda:0'), tensor([[ 0.0524,  0.0275, -0.0012,  0.1039]], device='cuda:0'), tensor([[ 0.1766,  0.4230, -0.0653, -0.3774]], device='cuda:0'), tensor([[-0.0049, -0.2419,  0.0171,  0.3288]], device='cuda:0'), tensor([[ 0.0605,  0.3925, -0.1055, -0.7117]], device='cuda:0'), tensor([[ 0.0218, -0.1824, -0.0479,  0.0604]], device='cuda:0'), tensor([[ 0.0399,  0.1958, -0.0313, -0.3135]], device='cuda:0'), tensor([[ 0.0408, -0.1454, -0.0178,  0.3073]], device='cuda:0'), tensor([[-0.0116,  0.0165,  0.0038,  0.0045]], device='cuda:0'), tensor([[ 0.0221, -0.2403, -0.0010,  0.2718]], device='cuda:0'), tensor([[ 0.1312,  0.7363, -0.1087, -1.0895]], device='cuda:0'), tensor([[-0.0849, -0.5898,  0.0906,  0.9145]], device='cuda:0'), tensor([[ 0.1460,  0.5427, -0.1304, -0.8328]], device='cuda:0'), tensor([[ 0.5297,  1.4636,  0.0286, -0.5240]], device='cuda:0'), tensor([[ 0.0093, -0.0277, -0.0125, -0.0019]], device='cuda:0'), tensor([[-0.1128,  0.1894, -0.0358, -0.7248]], device='cuda:0'), tensor([[-0.0100,  0.3801, -0.0568, -0.6752]], device='cuda:0'), tensor([[ 0.0429,  0.2227,  0.0043, -0.1911]], device='cuda:0'), tensor([[-0.1005, -0.4199,  0.1913,  0.9390]], device='cuda:0'), tensor([[ 0.1844,  0.0447, -0.1719, -0.2794]], device='cuda:0'))\n",
      "tensor([[-7.2206e-02, -8.3342e-01,  1.1898e-01,  1.3492e+00],\n",
      "        [ 5.5341e-02,  2.4225e-01, -4.8538e-02, -3.5473e-01],\n",
      "        [ 1.8665e-01,  3.9902e-02, -1.6966e-01, -1.7226e-01],\n",
      "        [-1.0903e-01, -5.2237e-03, -5.0298e-02, -4.4355e-01],\n",
      "        [ 4.0956e-02, -2.1281e-01,  2.1052e-02,  3.0122e-01],\n",
      "        [-7.6380e-02, -5.4703e-01,  1.7429e-01,  1.1109e+00],\n",
      "        [-5.2946e-03, -4.6412e-03, -4.3364e-03,  2.9770e-02],\n",
      "        [ 8.6326e-01,  1.6599e+00, -1.0063e-01, -8.4503e-01],\n",
      "        [ 4.3827e-02, -1.9340e-01, -3.8222e-02,  2.4972e-01],\n",
      "        [ 5.0434e-01,  1.2690e+00,  3.3447e-02, -2.4202e-01],\n",
      "        [-4.8333e-02,  1.6765e-01,  4.0540e-02, -2.4524e-01],\n",
      "        [ 3.2401e-02,  2.2723e-02,  2.5143e-02, -1.5151e-02],\n",
      "        [ 4.8696e-03,  5.5586e-01, -8.2006e-02, -9.2018e-01],\n",
      "        [-1.0457e-01, -8.4492e-03,  1.5752e-01,  2.3689e-01],\n",
      "        [ 2.8177e-02,  5.0164e-02,  6.1783e-03,  5.3725e-03],\n",
      "        [ 7.1626e-02,  3.7384e-01, -2.0820e-01, -9.3244e-01],\n",
      "        [ 6.8309e-02,  1.9901e-01, -1.1976e-01, -4.5400e-01],\n",
      "        [-1.2549e-02,  3.8227e-01, -3.5064e-03, -5.7856e-01],\n",
      "        [-4.2030e-02, -3.6702e-01, -4.3569e-02,  5.6140e-01],\n",
      "        [-3.1145e-02,  5.3665e-01,  1.5695e-01, -1.3441e-01],\n",
      "        [ 9.2719e-02,  1.7221e-01, -1.9675e-01, -6.6555e-01],\n",
      "        [ 6.2899e-02,  6.1247e-01, -2.3900e-03, -7.6579e-01],\n",
      "        [ 1.5683e-01,  7.3936e-01, -1.4710e-01, -1.1635e+00],\n",
      "        [ 2.3394e-01,  1.2075e+00, -1.3322e-01, -1.6473e+00],\n",
      "        [ 1.3258e-01,  6.1567e-01, -9.0418e-02, -8.3910e-01],\n",
      "        [ 3.0744e-02,  1.8939e-02,  3.5781e-02,  5.2315e-02],\n",
      "        [-1.2383e-02, -1.9086e-01,  1.4695e-01,  6.7534e-01],\n",
      "        [-1.1781e-01,  1.7547e-01,  1.6423e-01,  7.7646e-02],\n",
      "        [-1.3974e-01, -9.6201e-01,  1.9323e-01,  1.6767e+00],\n",
      "        [ 1.6113e-01,  6.1833e-01, -1.3038e-01, -9.0155e-01],\n",
      "        [ 1.8542e-02,  2.4003e-01, -1.4114e-02, -2.1961e-01],\n",
      "        [-3.6114e-02, -1.6099e-01,  6.9251e-02,  4.7196e-01],\n",
      "        [ 5.6535e-02,  1.9616e-01, -9.7724e-02, -3.8987e-01],\n",
      "        [ 2.0866e-02, -2.1507e-01, -1.9076e-01, -3.7536e-01],\n",
      "        [ 3.6846e-02,  3.7177e-01, -4.7264e-02, -6.0872e-01],\n",
      "        [ 1.8514e-02,  4.0865e-01, -6.3021e-02, -7.7336e-01],\n",
      "        [-1.5766e-03,  3.8572e-01, -9.0266e-03, -5.5814e-01],\n",
      "        [-2.2611e-01, -1.7065e+00,  5.8904e-02,  1.7601e+00],\n",
      "        [-7.4791e-02, -2.2001e-01,  1.4247e-01,  5.1746e-01],\n",
      "        [-3.4789e-02, -1.3850e-02, -9.3611e-03, -7.4651e-03],\n",
      "        [ 2.0616e-02,  2.0355e-01, -5.4231e-03, -1.1017e-01],\n",
      "        [ 2.7109e-02,  9.1798e-01,  1.2892e-01, -5.2644e-01],\n",
      "        [-2.3217e-02,  2.2207e-02,  2.1295e-03, -2.7831e-03],\n",
      "        [-1.0620e-01, -1.1217e+00, -4.0678e-02,  8.9411e-01],\n",
      "        [ 2.8537e-02,  9.6389e-03, -4.0480e-02, -1.6447e-01],\n",
      "        [ 5.2353e-02,  2.7486e-02, -1.2387e-03,  1.0391e-01],\n",
      "        [ 1.7658e-01,  4.2299e-01, -6.5315e-02, -3.7737e-01],\n",
      "        [-4.9059e-03, -2.4195e-01,  1.7096e-02,  3.2878e-01],\n",
      "        [ 6.0459e-02,  3.9252e-01, -1.0552e-01, -7.1170e-01],\n",
      "        [ 2.1817e-02, -1.8240e-01, -4.7885e-02,  6.0350e-02],\n",
      "        [ 3.9888e-02,  1.9582e-01, -3.1334e-02, -3.1351e-01],\n",
      "        [ 4.0788e-02, -1.4537e-01, -1.7814e-02,  3.0731e-01],\n",
      "        [-1.1606e-02,  1.6498e-02,  3.7793e-03,  4.5380e-03],\n",
      "        [ 2.2073e-02, -2.4026e-01, -9.8699e-04,  2.7184e-01],\n",
      "        [ 1.3125e-01,  7.3625e-01, -1.0866e-01, -1.0895e+00],\n",
      "        [-8.4932e-02, -5.8978e-01,  9.0611e-02,  9.1454e-01],\n",
      "        [ 1.4597e-01,  5.4272e-01, -1.3045e-01, -8.3279e-01],\n",
      "        [ 5.2972e-01,  1.4636e+00,  2.8606e-02, -5.2397e-01],\n",
      "        [ 9.2635e-03, -2.7687e-02, -1.2511e-02, -1.9046e-03],\n",
      "        [-1.1281e-01,  1.8939e-01, -3.5803e-02, -7.2475e-01],\n",
      "        [-1.0019e-02,  3.8009e-01, -5.6763e-02, -6.7518e-01],\n",
      "        [ 4.2896e-02,  2.2271e-01,  4.3154e-03, -1.9109e-01],\n",
      "        [-1.0050e-01, -4.1986e-01,  1.9126e-01,  9.3901e-01],\n",
      "        [ 1.8440e-01,  4.4689e-02, -1.7185e-01, -2.7945e-01]], device='cuda:0')\n",
      "torch.Size([64, 4])\n",
      "tensor([[0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1]], device='cuda:0')\n",
      "torch.Size([64, 1])\n",
      "tensor([ 0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,\n",
      "         0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000, -1.0000,\n",
      "         0.1000,  0.1000,  0.1000,  0.1000, -1.0000,  0.1000,  0.1000,  0.1000,\n",
      "         0.1000,  0.1000,  0.1000,  0.1000, -1.0000,  0.1000,  0.1000,  0.1000,\n",
      "         0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,\n",
      "         0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,\n",
      "         0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,\n",
      "         0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000, -1.0000,  0.1000],\n",
      "       device='cuda:0')\n",
      "torch.Size([64])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64])\n",
      "(tensor([[ 0.0931,  0.0189, -0.1958, -0.4991]], device='cuda:0'), tensor([[ 0.0242,  0.2405, -0.0171, -0.2299]], device='cuda:0'), tensor([[ 0.1433,  1.1958, -0.1588, -1.8586]], device='cuda:0'), tensor([[ 0.0065,  0.1685, -0.0136, -0.3184]], device='cuda:0'), tensor([[ 0.0230, -0.0451, -0.0006, -0.0207]], device='cuda:0'), tensor([[ 0.0211, -0.0349, -0.1203, -0.3333]], device='cuda:0'), tensor([[ 0.9984,  1.4735, -0.1458, -0.7478]], device='cuda:0'), tensor([[ 0.0398,  0.0495, -0.0182,  0.0204]], device='cuda:0'), tensor([[ 0.0385, -0.1619, -0.1433, -0.2226]], device='cuda:0'), tensor([[-0.0977, -0.0175,  0.1709,  0.4403]], device='cuda:0'), tensor([[-0.0160,  0.0044,  0.0426, -0.0498]], device='cuda:0'), tensor([[ 0.0935,  0.2162, -0.2057, -0.8465]], device='cuda:0'), tensor([[ 0.0958,  0.8082, -0.0426, -1.0732]], device='cuda:0'), tensor([[ 0.0879,  0.5664, -0.0481, -0.8415]], device='cuda:0'), tensor([[ 0.1492,  0.6103, -0.0725, -0.4975]], device='cuda:0'), tensor([[-0.0329, -0.4396,  0.0652,  0.6595]], device='cuda:0'), tensor([[ 0.0457, -0.0201,  0.0046,  0.0085]], device='cuda:0'), tensor([[ 0.0096, -0.0468, -0.0026,  0.0360]], device='cuda:0'), tensor([[ 0.1614,  0.4162, -0.0825, -0.2286]], device='cuda:0'), tensor([[ 0.0195,  0.3926, -0.0126, -0.5901]], device='cuda:0'), tensor([[-0.0359, -0.5483, -0.0070,  0.7787]], device='cuda:0'), tensor([[-0.0133, -0.7889, -0.0578,  0.7999]], device='cuda:0'), tensor([[ 0.0927,  1.1670, -0.0480, -1.6663]], device='cuda:0'), tensor([[-0.0524, -0.9415,  0.0681,  1.4819]], device='cuda:0'), tensor([[ 0.0172, -0.7402, -0.1420,  0.5072]], device='cuda:0'), tensor([[-0.0266, -0.1908,  0.0319,  0.2451]], device='cuda:0'), tensor([[-0.0388,  0.3586, -0.0113, -0.5768]], device='cuda:0'), tensor([[-0.0026, -0.0396, -0.0050,  0.0212]], device='cuda:0'), tensor([[ 0.0322, -0.3733,  0.0413,  0.6810]], device='cuda:0'), tensor([[-0.1291, -0.9419,  0.1291,  1.4485]], device='cuda:0'), tensor([[-0.0922, -0.5603,  0.0279,  0.8120]], device='cuda:0'), tensor([[ 0.0200,  0.4157,  0.0426, -0.2156]], device='cuda:0'), tensor([[-0.0212,  0.5545, -0.0403, -0.8890]], device='cuda:0'), tensor([[-0.0020, -0.0395, -0.0124,  0.0053]], device='cuda:0'), tensor([[-0.0367, -0.1805,  0.0468,  0.3380]], device='cuda:0'), tensor([[-0.0429, -0.9336,  0.1150,  1.6089]], device='cuda:0'), tensor([[ 0.0256,  0.1944, -0.0106, -0.2587]], device='cuda:0'), tensor([[ 0.0647,  0.5883, -0.0677, -0.9249]], device='cuda:0'), tensor([[ 0.0354, -0.2122, -0.0907,  0.1110]], device='cuda:0'), tensor([[ 0.1080,  0.5980, -0.1086, -0.7930]], device='cuda:0'), tensor([[ 0.0273,  0.4180,  0.0080, -0.4868]], device='cuda:0'), tensor([[-0.0162, -0.1598,  0.0099,  0.2812]], device='cuda:0'), tensor([[ 0.0634,  0.7587, -0.1201, -1.3096]], device='cuda:0'), tensor([[-0.1028, -1.5264,  0.2010,  2.4987]], device='cuda:0'), tensor([[-0.2261, -1.7065,  0.0589,  1.7601]], device='cuda:0'), tensor([[-0.0276, -0.0072,  0.0201, -0.0110]], device='cuda:0'), tensor([[ 0.0229,  0.2107, -0.0683, -0.5899]], device='cuda:0'), tensor([[-0.0506, -0.4410,  0.0842,  0.7094]], device='cuda:0'), tensor([[ 0.0484, -0.3624, -0.1349,  0.1927]], device='cuda:0'), tensor([[ 0.0060,  0.1788, -0.0719, -0.4079]], device='cuda:0'), tensor([[ 0.0287, -0.0453, -0.0057, -0.0169]], device='cuda:0'), tensor([[ 0.0077, -0.0292, -0.0336,  0.0859]], device='cuda:0'), tensor([[ 0.0462,  0.9286,  0.0122, -1.3153]], device='cuda:0'), tensor([[ 0.0128,  0.3524, -0.0424, -0.6181]], device='cuda:0'), tensor([[ 0.0455,  0.7213,  0.1184, -0.1961]], device='cuda:0'), tensor([[ 0.0093, -0.0277, -0.0125, -0.0019]], device='cuda:0'), tensor([[ 0.0438, -0.2074, -0.0287,  0.2354]], device='cuda:0'), tensor([[ 0.1106,  0.9028,  0.1594, -0.1898]], device='cuda:0'), tensor([[ 0.2851,  1.2770,  0.1089, -0.4212]], device='cuda:0'), tensor([[ 0.0397, -0.0092, -0.1413, -0.2744]], device='cuda:0'), tensor([[ 0.0548,  0.1965, -0.2012, -0.8123]], device='cuda:0'), tensor([[ 0.0373,  0.1948, -0.0268, -0.2670]], device='cuda:0'), tensor([[ 0.0199,  0.5481, -0.0548, -0.9238]], device='cuda:0'), tensor([[-0.1143,  0.3679,  0.1658, -0.1591]], device='cuda:0'))\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-d566a158abdd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremember\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m             \u001b[0mloss_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-7fa643546f13>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(self, state, action, reward, next_state, done)\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[0mdones\u001b[0m       \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_dones\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\TORCH190\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36m__repr__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    177\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__repr__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrelevant_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[1;31m# All strings are unicode in Python 3.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tensor_str\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\TORCH190\\lib\\site-packages\\torch\\_tensor_str.py\u001b[0m in \u001b[0;36m_str\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    370\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 372\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_str_intern\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\TORCH190\\lib\\site-packages\\torch\\_tensor_str.py\u001b[0m in \u001b[0;36m_str_intern\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    350\u001b[0m                     \u001b[0mtensor_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_dense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m                     \u001b[0mtensor_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayout\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrided\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\TORCH190\\lib\\site-packages\\torch\\_tensor_str.py\u001b[0m in \u001b[0;36m_tensor_str\u001b[1;34m(self, indent)\u001b[0m\n\u001b[0;32m    239\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_tensor_str_with_formatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreal_formatter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimag_formatter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 241\u001b[1;33m         \u001b[0mformatter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Formatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_summarized_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0msummarize\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    242\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_tensor_str_with_formatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\TORCH190\\lib\\site-packages\\torch\\_tensor_str.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    122\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msci_mode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m                     \u001b[1;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnonzero_finite_vals\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m                         \u001b[0mvalue_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'{{:.{}e}}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPRINT_OPTS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprecision\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    125\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_width\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_width\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\TORCH190\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36m__format__\u001b[1;34m(self, format_spec)\u001b[0m\n\u001b[0;32m    532\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__format__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrelevant_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat_spec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 534\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__format__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat_spec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    535\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__format__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat_spec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%matplotlib tk\n",
    "\n",
    "ENV_NAME = 'CartPole-v1'\n",
    "EPISODES = 1000\n",
    "# if gpu is to be used\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"DEVICE : \", device)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    env = gym.make(ENV_NAME)\n",
    "    state_size = env.observation_space.shape[0]\n",
    "    action_size = env.action_space.n\n",
    "    print('Env Name : ',ENV_NAME)\n",
    "    print('States {}, Actions {}'\n",
    "            .format(state_size, action_size))\n",
    "\n",
    "    agent = DQNAgent(state_size, action_size, device)\n",
    "\n",
    "    scores, episodes, epsilons, losses = [], [], [], []\n",
    "    score_avg = 0\n",
    "    \n",
    "    end = False\n",
    "    \n",
    "    # fig = plt.figure(1)\n",
    "    # fig.clf()\n",
    "    \n",
    "    for e in range(EPISODES):\n",
    "        done = False\n",
    "        score = 0\n",
    "        loss_list = []\n",
    "\n",
    "        state = env.reset()\n",
    "        \n",
    "        while not done:\n",
    "            #env.render()\n",
    "            state = torch.FloatTensor([state]).to(device)\n",
    "            action = agent.choose_action(state)\n",
    "            # print('action size : ',action.size())\n",
    "            next_state, reward, done, info = env.step(action.item())\n",
    "\n",
    "            score += reward\n",
    "            reward = 0.1 if not done or score == 500 else -1\n",
    "\n",
    "            agent.remember(state, action, reward, next_state, done)\n",
    "\n",
    "            loss = agent.train_model(state, action, reward, next_state, done)\n",
    "            loss_list.append(loss)\n",
    "\n",
    "            state = next_state\n",
    "            if done:\n",
    "                agent.update_target_model()\n",
    "\n",
    "                score_avg = 0.9 * score_avg + 0.1 * score if score_avg != 0 else score\n",
    "                print('epi: {:3d} | score avg {:3.2f} | mem length: {:4d} | epsilon: {:.4f}'\n",
    "                      .format(e, score_avg, len(agent.memory), agent.epsilon))\n",
    "\n",
    "                episodes.append(e)\n",
    "                scores.append(score_avg)\n",
    "                epsilons.append(agent.epsilon)\n",
    "                losses.append(np.mean(loss_list))\n",
    "                plt.subplot(311)\n",
    "                plt.plot(episodes, scores, 'b')\n",
    "                plt.xlabel('episode')\n",
    "                plt.ylabel('average score')\n",
    "                plt.title('cartpole DQN TORCH')\n",
    "                plt.grid()\n",
    "                \n",
    "                plt.subplot(312)\n",
    "                plt.plot(episodes, epsilons, 'b')\n",
    "                plt.xlabel('episode')\n",
    "                plt.ylabel('epsilon')\n",
    "                plt.grid()\n",
    "                \n",
    "                plt.subplot(313)\n",
    "                plt.plot(episodes, losses, 'b')\n",
    "                plt.xlabel('episode')\n",
    "                plt.ylabel('losses')\n",
    "                plt.grid()\n",
    "                \n",
    "                plt.savefig('./save_model/cartpole_Tdqn.png')\n",
    "\n",
    "                if score_avg > 400:\n",
    "                    torch.save(agent.model.state_dict(),'./save_model/cartpole_Tdqn')\n",
    "                    end = True\n",
    "                    break\n",
    "        if end == True:\n",
    "            env.close()\n",
    "            np.save('./save_model/cartpole_Tdqn_epi',  episodes)\n",
    "            np.save('./save_model/cartpole_Tdqn_score',scores)\n",
    "            np.save('./save_model/cartpole_Tdqn_loss', losses)\n",
    "            print(\"End\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ": 617, eps : 7.7%\n",
      "n_episode :62, score : 8.0, n_buffer : 625, eps : 7.7%\n",
      "n_episode :63, score : 9.0, n_buffer : 634, eps : 7.7%\n",
      "n_episode :64, score : 11.0, n_buffer : 645, eps : 7.7%\n",
      "n_episode :65, score : 10.0, n_buffer : 655, eps : 7.7%\n",
      "n_episode :66, score : 9.0, n_buffer : 664, eps : 7.7%\n",
      "n_episode :67, score : 9.0, n_buffer : 673, eps : 7.7%\n",
      "n_episode :68, score : 11.0, n_buffer : 684, eps : 7.7%\n",
      "n_episode :69, score : 10.0, n_buffer : 694, eps : 7.7%\n",
      "n_episode :70, score : 10.0, n_buffer : 704, eps : 7.6%\n",
      "n_episode :71, score : 8.0, n_buffer : 712, eps : 7.6%\n",
      "n_episode :72, score : 10.0, n_buffer : 722, eps : 7.6%\n",
      "n_episode :73, score : 8.0, n_buffer : 730, eps : 7.6%\n",
      "n_episode :74, score : 9.0, n_buffer : 739, eps : 7.6%\n",
      "n_episode :75, score : 10.0, n_buffer : 749, eps : 7.6%\n",
      "n_episode :76, score : 10.0, n_buffer : 759, eps : 7.6%\n",
      "n_episode :77, score : 10.0, n_buffer : 769, eps : 7.6%\n",
      "n_episode :78, score : 9.0, n_buffer : 778, eps : 7.6%\n",
      "n_episode :79, score : 11.0, n_buffer : 789, eps : 7.6%\n",
      "n_episode :80, score : 10.0, n_buffer : 799, eps : 7.6%\n",
      "n_episode :81, score : 9.0, n_buffer : 808, eps : 7.6%\n",
      "n_episode :82, score : 8.0, n_buffer : 816, eps : 7.6%\n",
      "n_episode :83, score : 10.0, n_buffer : 826, eps : 7.6%\n",
      "n_episode :84, score : 10.0, n_buffer : 836, eps : 7.6%\n",
      "n_episode :85, score : 9.0, n_buffer : 845, eps : 7.6%\n",
      "n_episode :86, score : 10.0, n_buffer : 855, eps : 7.6%\n",
      "n_episode :87, score : 9.0, n_buffer : 864, eps : 7.6%\n",
      "n_episode :88, score : 14.0, n_buffer : 878, eps : 7.6%\n",
      "n_episode :89, score : 10.0, n_buffer : 888, eps : 7.6%\n",
      "n_episode :90, score : 9.0, n_buffer : 897, eps : 7.5%\n",
      "n_episode :91, score : 10.0, n_buffer : 907, eps : 7.5%\n",
      "n_episode :92, score : 9.0, n_buffer : 916, eps : 7.5%\n",
      "n_episode :93, score : 10.0, n_buffer : 926, eps : 7.5%\n",
      "n_episode :94, score : 8.0, n_buffer : 934, eps : 7.5%\n",
      "n_episode :95, score : 9.0, n_buffer : 943, eps : 7.5%\n",
      "n_episode :96, score : 9.0, n_buffer : 952, eps : 7.5%\n",
      "n_episode :97, score : 9.0, n_buffer : 961, eps : 7.5%\n",
      "n_episode :98, score : 8.0, n_buffer : 969, eps : 7.5%\n",
      "n_episode :99, score : 10.0, n_buffer : 979, eps : 7.5%\n",
      "n_episode :100, score : 10.0, n_buffer : 989, eps : 7.5%\n",
      "n_episode :101, score : 9.0, n_buffer : 998, eps : 7.5%\n",
      "n_episode :102, score : 10.0, n_buffer : 1008, eps : 7.5%\n",
      "n_episode :103, score : 9.0, n_buffer : 1017, eps : 7.5%\n",
      "n_episode :104, score : 8.0, n_buffer : 1025, eps : 7.5%\n",
      "n_episode :105, score : 8.0, n_buffer : 1033, eps : 7.5%\n",
      "n_episode :106, score : 9.0, n_buffer : 1042, eps : 7.5%\n",
      "n_episode :107, score : 10.0, n_buffer : 1052, eps : 7.5%\n",
      "n_episode :108, score : 12.0, n_buffer : 1064, eps : 7.5%\n",
      "n_episode :109, score : 10.0, n_buffer : 1074, eps : 7.5%\n",
      "n_episode :110, score : 9.0, n_buffer : 1083, eps : 7.4%\n",
      "n_episode :111, score : 9.0, n_buffer : 1092, eps : 7.4%\n",
      "n_episode :112, score : 10.0, n_buffer : 1102, eps : 7.4%\n",
      "n_episode :113, score : 14.0, n_buffer : 1116, eps : 7.4%\n",
      "n_episode :114, score : 9.0, n_buffer : 1125, eps : 7.4%\n",
      "n_episode :115, score : 9.0, n_buffer : 1134, eps : 7.4%\n",
      "n_episode :116, score : 10.0, n_buffer : 1144, eps : 7.4%\n",
      "n_episode :117, score : 9.0, n_buffer : 1153, eps : 7.4%\n",
      "n_episode :118, score : 9.0, n_buffer : 1162, eps : 7.4%\n",
      "n_episode :119, score : 8.0, n_buffer : 1170, eps : 7.4%\n",
      "n_episode :120, score : 11.0, n_buffer : 1181, eps : 7.4%\n",
      "n_episode :121, score : 10.0, n_buffer : 1191, eps : 7.4%\n",
      "n_episode :122, score : 10.0, n_buffer : 1201, eps : 7.4%\n",
      "n_episode :123, score : 9.0, n_buffer : 1210, eps : 7.4%\n",
      "n_episode :124, score : 9.0, n_buffer : 1219, eps : 7.4%\n",
      "n_episode :125, score : 9.0, n_buffer : 1228, eps : 7.4%\n",
      "n_episode :126, score : 11.0, n_buffer : 1239, eps : 7.4%\n",
      "n_episode :127, score : 12.0, n_buffer : 1251, eps : 7.4%\n",
      "n_episode :128, score : 9.0, n_buffer : 1260, eps : 7.4%\n",
      "n_episode :129, score : 11.0, n_buffer : 1271, eps : 7.4%\n",
      "n_episode :130, score : 8.0, n_buffer : 1279, eps : 7.3%\n",
      "n_episode :131, score : 9.0, n_buffer : 1288, eps : 7.3%\n",
      "n_episode :132, score : 10.0, n_buffer : 1298, eps : 7.3%\n",
      "n_episode :133, score : 8.0, n_buffer : 1306, eps : 7.3%\n",
      "n_episode :134, score : 11.0, n_buffer : 1317, eps : 7.3%\n",
      "n_episode :135, score : 10.0, n_buffer : 1327, eps : 7.3%\n",
      "n_episode :136, score : 11.0, n_buffer : 1338, eps : 7.3%\n",
      "n_episode :137, score : 11.0, n_buffer : 1349, eps : 7.3%\n",
      "n_episode :138, score : 10.0, n_buffer : 1359, eps : 7.3%\n",
      "n_episode :139, score : 10.0, n_buffer : 1369, eps : 7.3%\n",
      "n_episode :140, score : 11.0, n_buffer : 1380, eps : 7.3%\n",
      "n_episode :141, score : 11.0, n_buffer : 1391, eps : 7.3%\n",
      "n_episode :142, score : 11.0, n_buffer : 1402, eps : 7.3%\n",
      "n_episode :143, score : 13.0, n_buffer : 1415, eps : 7.3%\n",
      "n_episode :144, score : 10.0, n_buffer : 1425, eps : 7.3%\n",
      "n_episode :145, score : 13.0, n_buffer : 1438, eps : 7.3%\n",
      "n_episode :146, score : 11.0, n_buffer : 1449, eps : 7.3%\n",
      "n_episode :147, score : 11.0, n_buffer : 1460, eps : 7.3%\n",
      "n_episode :148, score : 10.0, n_buffer : 1470, eps : 7.3%\n",
      "n_episode :149, score : 10.0, n_buffer : 1480, eps : 7.3%\n",
      "n_episode :150, score : 10.0, n_buffer : 1490, eps : 7.3%\n",
      "n_episode :151, score : 11.0, n_buffer : 1501, eps : 7.2%\n",
      "n_episode :152, score : 12.0, n_buffer : 1513, eps : 7.2%\n",
      "n_episode :153, score : 10.0, n_buffer : 1523, eps : 7.2%\n",
      "n_episode :154, score : 9.0, n_buffer : 1532, eps : 7.2%\n",
      "n_episode :155, score : 9.0, n_buffer : 1541, eps : 7.2%\n",
      "n_episode :156, score : 11.0, n_buffer : 1552, eps : 7.2%\n",
      "n_episode :157, score : 10.0, n_buffer : 1562, eps : 7.2%\n",
      "n_episode :158, score : 10.0, n_buffer : 1572, eps : 7.2%\n",
      "n_episode :159, score : 11.0, n_buffer : 1583, eps : 7.2%\n",
      "n_episode :160, score : 9.0, n_buffer : 1592, eps : 7.2%\n",
      "n_episode :161, score : 11.0, n_buffer : 1603, eps : 7.2%\n",
      "n_episode :162, score : 10.0, n_buffer : 1613, eps : 7.2%\n",
      "n_episode :163, score : 11.0, n_buffer : 1624, eps : 7.2%\n",
      "n_episode :164, score : 11.0, n_buffer : 1635, eps : 7.2%\n",
      "n_episode :165, score : 12.0, n_buffer : 1647, eps : 7.2%\n",
      "n_episode :166, score : 11.0, n_buffer : 1658, eps : 7.2%\n",
      "n_episode :167, score : 11.0, n_buffer : 1669, eps : 7.2%\n",
      "n_episode :168, score : 13.0, n_buffer : 1682, eps : 7.2%\n",
      "n_episode :169, score : 13.0, n_buffer : 1695, eps : 7.2%\n",
      "n_episode :170, score : 9.0, n_buffer : 1704, eps : 7.2%\n",
      "n_episode :171, score : 10.0, n_buffer : 1714, eps : 7.1%\n",
      "n_episode :172, score : 10.0, n_buffer : 1724, eps : 7.1%\n",
      "n_episode :173, score : 12.0, n_buffer : 1736, eps : 7.1%\n",
      "n_episode :174, score : 12.0, n_buffer : 1748, eps : 7.1%\n",
      "n_episode :175, score : 10.0, n_buffer : 1758, eps : 7.1%\n",
      "n_episode :176, score : 11.0, n_buffer : 1769, eps : 7.1%\n",
      "n_episode :177, score : 12.0, n_buffer : 1781, eps : 7.1%\n",
      "n_episode :178, score : 10.0, n_buffer : 1791, eps : 7.1%\n",
      "n_episode :179, score : 9.0, n_buffer : 1800, eps : 7.1%\n",
      "n_episode :180, score : 15.0, n_buffer : 1815, eps : 7.1%\n",
      "n_episode :181, score : 14.0, n_buffer : 1829, eps : 7.1%\n",
      "n_episode :182, score : 12.0, n_buffer : 1841, eps : 7.1%\n",
      "n_episode :183, score : 14.0, n_buffer : 1855, eps : 7.1%\n",
      "n_episode :184, score : 12.0, n_buffer : 1867, eps : 7.1%\n",
      "n_episode :185, score : 10.0, n_buffer : 1877, eps : 7.1%\n",
      "n_episode :186, score : 13.0, n_buffer : 1890, eps : 7.1%\n",
      "n_episode :187, score : 10.0, n_buffer : 1900, eps : 7.1%\n",
      "n_episode :188, score : 12.0, n_buffer : 1912, eps : 7.1%\n",
      "n_episode :189, score : 14.0, n_buffer : 1926, eps : 7.1%\n",
      "n_episode :190, score : 14.0, n_buffer : 1940, eps : 7.1%\n",
      "n_episode :191, score : 12.0, n_buffer : 1952, eps : 7.0%\n",
      "n_episode :192, score : 11.0, n_buffer : 1963, eps : 7.0%\n",
      "n_episode :193, score : 13.0, n_buffer : 1976, eps : 7.0%\n",
      "n_episode :194, score : 14.0, n_buffer : 1990, eps : 7.0%\n",
      "n_episode :195, score : 13.0, n_buffer : 2000, eps : 7.0%\n",
      "n_episode :196, score : 14.0, n_buffer : 2000, eps : 7.0%\n",
      "n_episode :197, score : 16.0, n_buffer : 2000, eps : 7.0%\n",
      "n_episode :198, score : 15.0, n_buffer : 2000, eps : 7.0%\n",
      "n_episode :199, score : 15.0, n_buffer : 2000, eps : 7.0%\n",
      "n_episode :200, score : 14.0, n_buffer : 2000, eps : 7.0%\n",
      "n_episode :201, score : 12.0, n_buffer : 2000, eps : 7.0%\n",
      "n_episode :202, score : 13.0, n_buffer : 2000, eps : 7.0%\n",
      "n_episode :203, score : 13.0, n_buffer : 2000, eps : 7.0%\n",
      "n_episode :204, score : 16.0, n_buffer : 2000, eps : 7.0%\n",
      "n_episode :205, score : 16.0, n_buffer : 2000, eps : 7.0%\n",
      "n_episode :206, score : 22.0, n_buffer : 2000, eps : 7.0%\n",
      "n_episode :207, score : 17.0, n_buffer : 2000, eps : 7.0%\n",
      "n_episode :208, score : 24.0, n_buffer : 2000, eps : 7.0%\n",
      "n_episode :209, score : 24.0, n_buffer : 2000, eps : 7.0%\n",
      "n_episode :210, score : 24.0, n_buffer : 2000, eps : 7.0%\n",
      "n_episode :211, score : 12.0, n_buffer : 2000, eps : 6.9%\n",
      "n_episode :212, score : 19.0, n_buffer : 2000, eps : 6.9%\n",
      "n_episode :213, score : 20.0, n_buffer : 2000, eps : 6.9%\n",
      "n_episode :214, score : 22.0, n_buffer : 2000, eps : 6.9%\n",
      "n_episode :215, score : 25.0, n_buffer : 2000, eps : 6.9%\n",
      "n_episode :216, score : 18.0, n_buffer : 2000, eps : 6.9%\n",
      "n_episode :217, score : 23.0, n_buffer : 2000, eps : 6.9%\n",
      "n_episode :218, score : 28.0, n_buffer : 2000, eps : 6.9%\n",
      "n_episode :219, score : 25.0, n_buffer : 2000, eps : 6.9%\n",
      "n_episode :220, score : 29.0, n_buffer : 2000, eps : 6.9%\n",
      "n_episode :221, score : 29.0, n_buffer : 2000, eps : 6.9%\n",
      "n_episode :222, score : 28.0, n_buffer : 2000, eps : 6.9%\n",
      "n_episode :223, score : 26.0, n_buffer : 2000, eps : 6.9%\n",
      "n_episode :224, score : 34.0, n_buffer : 2000, eps : 6.9%\n",
      "n_episode :225, score : 39.0, n_buffer : 2000, eps : 6.9%\n",
      "n_episode :226, score : 35.0, n_buffer : 2000, eps : 6.9%\n",
      "n_episode :227, score : 36.0, n_buffer : 2000, eps : 6.9%\n",
      "n_episode :228, score : 35.0, n_buffer : 2000, eps : 6.9%\n",
      "n_episode :229, score : 46.0, n_buffer : 2000, eps : 6.9%\n",
      "n_episode :230, score : 38.0, n_buffer : 2000, eps : 6.9%\n",
      "n_episode :231, score : 39.0, n_buffer : 2000, eps : 6.8%\n",
      "n_episode :232, score : 32.0, n_buffer : 2000, eps : 6.8%\n",
      "n_episode :233, score : 49.0, n_buffer : 2000, eps : 6.8%\n",
      "n_episode :234, score : 49.0, n_buffer : 2000, eps : 6.8%\n",
      "n_episode :235, score : 54.0, n_buffer : 2000, eps : 6.8%\n",
      "n_episode :236, score : 53.0, n_buffer : 2000, eps : 6.8%\n",
      "n_episode :237, score : 64.0, n_buffer : 2000, eps : 6.8%\n",
      "n_episode :238, score : 58.0, n_buffer : 2000, eps : 6.8%\n",
      "n_episode :239, score : 59.0, n_buffer : 2000, eps : 6.8%\n",
      "n_episode :240, score : 84.0, n_buffer : 2000, eps : 6.8%\n",
      "n_episode :241, score : 72.0, n_buffer : 2000, eps : 6.8%\n",
      "n_episode :242, score : 65.0, n_buffer : 2000, eps : 6.8%\n",
      "n_episode :243, score : 83.0, n_buffer : 2000, eps : 6.8%\n",
      "n_episode :244, score : 96.0, n_buffer : 2000, eps : 6.8%\n",
      "n_episode :245, score : 151.0, n_buffer : 2000, eps : 6.8%\n",
      "n_episode :246, score : 241.0, n_buffer : 2000, eps : 6.8%\n",
      "n_episode :247, score : 83.0, n_buffer : 2000, eps : 6.8%\n",
      "n_episode :248, score : 101.0, n_buffer : 2000, eps : 6.8%\n",
      "n_episode :249, score : 53.0, n_buffer : 2000, eps : 6.8%\n",
      "n_episode :250, score : 30.0, n_buffer : 2000, eps : 6.8%\n",
      "n_episode :251, score : 23.0, n_buffer : 2000, eps : 6.7%\n",
      "n_episode :252, score : 13.0, n_buffer : 2000, eps : 6.7%\n",
      "n_episode :253, score : 14.0, n_buffer : 2000, eps : 6.7%\n",
      "n_episode :254, score : 13.0, n_buffer : 2000, eps : 6.7%\n",
      "n_episode :255, score : 14.0, n_buffer : 2000, eps : 6.7%\n",
      "n_episode :256, score : 10.0, n_buffer : 2000, eps : 6.7%\n",
      "n_episode :257, score : 10.0, n_buffer : 2000, eps : 6.7%\n",
      "n_episode :258, score : 10.0, n_buffer : 2000, eps : 6.7%\n",
      "n_episode :259, score : 10.0, n_buffer : 2000, eps : 6.7%\n",
      "n_episode :260, score : 13.0, n_buffer : 2000, eps : 6.7%\n",
      "n_episode :261, score : 15.0, n_buffer : 2000, eps : 6.7%\n",
      "n_episode :262, score : 12.0, n_buffer : 2000, eps : 6.7%\n",
      "n_episode :263, score : 15.0, n_buffer : 2000, eps : 6.7%\n",
      "n_episode :264, score : 15.0, n_buffer : 2000, eps : 6.7%\n",
      "n_episode :265, score : 12.0, n_buffer : 2000, eps : 6.7%\n",
      "n_episode :266, score : 11.0, n_buffer : 2000, eps : 6.7%\n",
      "n_episode :267, score : 12.0, n_buffer : 2000, eps : 6.7%\n",
      "n_episode :268, score : 15.0, n_buffer : 2000, eps : 6.7%\n",
      "n_episode :269, score : 13.0, n_buffer : 2000, eps : 6.7%\n",
      "n_episode :270, score : 14.0, n_buffer : 2000, eps : 6.7%\n",
      "n_episode :271, score : 18.0, n_buffer : 2000, eps : 6.6%\n",
      "n_episode :272, score : 19.0, n_buffer : 2000, eps : 6.6%\n",
      "n_episode :273, score : 13.0, n_buffer : 2000, eps : 6.6%\n",
      "n_episode :274, score : 33.0, n_buffer : 2000, eps : 6.6%\n",
      "n_episode :275, score : 84.0, n_buffer : 2000, eps : 6.6%\n",
      "n_episode :276, score : 39.0, n_buffer : 2000, eps : 6.6%\n",
      "n_episode :277, score : 38.0, n_buffer : 2000, eps : 6.6%\n",
      "n_episode :278, score : 43.0, n_buffer : 2000, eps : 6.6%\n",
      "n_episode :279, score : 44.0, n_buffer : 2000, eps : 6.6%\n",
      "n_episode :280, score : 35.0, n_buffer : 2000, eps : 6.6%\n",
      "n_episode :281, score : 117.0, n_buffer : 2000, eps : 6.6%\n",
      "n_episode :282, score : 49.0, n_buffer : 2000, eps : 6.6%\n",
      "n_episode :283, score : 24.0, n_buffer : 2000, eps : 6.6%\n",
      "n_episode :284, score : 31.0, n_buffer : 2000, eps : 6.6%\n",
      "n_episode :285, score : 52.0, n_buffer : 2000, eps : 6.6%\n",
      "n_episode :286, score : 25.0, n_buffer : 2000, eps : 6.6%\n",
      "n_episode :287, score : 22.0, n_buffer : 2000, eps : 6.6%\n",
      "n_episode :288, score : 27.0, n_buffer : 2000, eps : 6.6%\n",
      "n_episode :289, score : 35.0, n_buffer : 2000, eps : 6.6%\n",
      "n_episode :290, score : 49.0, n_buffer : 2000, eps : 6.6%\n",
      "n_episode :291, score : 107.0, n_buffer : 2000, eps : 6.5%\n",
      "n_episode :292, score : 48.0, n_buffer : 2000, eps : 6.5%\n",
      "n_episode :293, score : 33.0, n_buffer : 2000, eps : 6.5%\n",
      "n_episode :294, score : 40.0, n_buffer : 2000, eps : 6.5%\n",
      "n_episode :295, score : 31.0, n_buffer : 2000, eps : 6.5%\n",
      "n_episode :296, score : 21.0, n_buffer : 2000, eps : 6.5%\n",
      "n_episode :297, score : 32.0, n_buffer : 2000, eps : 6.5%\n",
      "n_episode :298, score : 44.0, n_buffer : 2000, eps : 6.5%\n",
      "n_episode :299, score : 81.0, n_buffer : 2000, eps : 6.5%\n",
      "n_episode :300, score : 58.0, n_buffer : 2000, eps : 6.5%\n",
      "n_episode :301, score : 41.0, n_buffer : 2000, eps : 6.5%\n",
      "n_episode :302, score : 43.0, n_buffer : 2000, eps : 6.5%\n",
      "n_episode :303, score : 83.0, n_buffer : 2000, eps : 6.5%\n",
      "n_episode :304, score : 79.0, n_buffer : 2000, eps : 6.5%\n",
      "n_episode :305, score : 67.0, n_buffer : 2000, eps : 6.5%\n",
      "n_episode :306, score : 54.0, n_buffer : 2000, eps : 6.5%\n",
      "n_episode :307, score : 37.0, n_buffer : 2000, eps : 6.5%\n",
      "n_episode :308, score : 41.0, n_buffer : 2000, eps : 6.5%\n",
      "n_episode :309, score : 93.0, n_buffer : 2000, eps : 6.5%\n",
      "n_episode :310, score : 56.0, n_buffer : 2000, eps : 6.5%\n",
      "n_episode :311, score : 40.0, n_buffer : 2000, eps : 6.4%\n",
      "n_episode :312, score : 48.0, n_buffer : 2000, eps : 6.4%\n",
      "n_episode :313, score : 49.0, n_buffer : 2000, eps : 6.4%\n",
      "n_episode :314, score : 72.0, n_buffer : 2000, eps : 6.4%\n",
      "n_episode :315, score : 83.0, n_buffer : 2000, eps : 6.4%\n",
      "n_episode :316, score : 73.0, n_buffer : 2000, eps : 6.4%\n",
      "n_episode :317, score : 61.0, n_buffer : 2000, eps : 6.4%\n",
      "n_episode :318, score : 108.0, n_buffer : 2000, eps : 6.4%\n",
      "n_episode :319, score : 135.0, n_buffer : 2000, eps : 6.4%\n",
      "n_episode :320, score : 131.0, n_buffer : 2000, eps : 6.4%\n",
      "n_episode :321, score : 124.0, n_buffer : 2000, eps : 6.4%\n",
      "n_episode :322, score : 64.0, n_buffer : 2000, eps : 6.4%\n",
      "n_episode :323, score : 109.0, n_buffer : 2000, eps : 6.4%\n",
      "n_episode :324, score : 104.0, n_buffer : 2000, eps : 6.4%\n",
      "n_episode :325, score : 133.0, n_buffer : 2000, eps : 6.4%\n",
      "n_episode :326, score : 163.0, n_buffer : 2000, eps : 6.4%\n",
      "n_episode :327, score : 127.0, n_buffer : 2000, eps : 6.4%\n",
      "n_episode :328, score : 116.0, n_buffer : 2000, eps : 6.4%\n",
      "n_episode :329, score : 143.0, n_buffer : 2000, eps : 6.4%\n",
      "n_episode :330, score : 137.0, n_buffer : 2000, eps : 6.3%\n",
      "n_episode :331, score : 137.0, n_buffer : 2000, eps : 6.3%\n",
      "n_episode :332, score : 122.0, n_buffer : 2000, eps : 6.3%\n",
      "n_episode :333, score : 133.0, n_buffer : 2000, eps : 6.3%\n",
      "n_episode :334, score : 120.0, n_buffer : 2000, eps : 6.3%\n",
      "n_episode :335, score : 150.0, n_buffer : 2000, eps : 6.3%\n",
      "n_episode :336, score : 125.0, n_buffer : 2000, eps : 6.3%\n",
      "n_episode :337, score : 163.0, n_buffer : 2000, eps : 6.3%\n",
      "n_episode :338, score : 136.0, n_buffer : 2000, eps : 6.3%\n",
      "n_episode :339, score : 127.0, n_buffer : 2000, eps : 6.3%\n",
      "n_episode :340, score : 121.0, n_buffer : 2000, eps : 6.3%\n",
      "n_episode :341, score : 119.0, n_buffer : 2000, eps : 6.3%\n",
      "n_episode :342, score : 145.0, n_buffer : 2000, eps : 6.3%\n",
      "n_episode :343, score : 129.0, n_buffer : 2000, eps : 6.3%\n",
      "n_episode :344, score : 130.0, n_buffer : 2000, eps : 6.3%\n",
      "n_episode :345, score : 157.0, n_buffer : 2000, eps : 6.3%\n",
      "n_episode :346, score : 131.0, n_buffer : 2000, eps : 6.3%\n",
      "n_episode :347, score : 127.0, n_buffer : 2000, eps : 6.3%\n",
      "n_episode :348, score : 133.0, n_buffer : 2000, eps : 6.3%\n",
      "n_episode :349, score : 132.0, n_buffer : 2000, eps : 6.3%\n",
      "n_episode :350, score : 133.0, n_buffer : 2000, eps : 6.2%\n",
      "n_episode :351, score : 145.0, n_buffer : 2000, eps : 6.2%\n",
      "n_episode :352, score : 173.0, n_buffer : 2000, eps : 6.2%\n",
      "n_episode :353, score : 156.0, n_buffer : 2000, eps : 6.2%\n",
      "n_episode :354, score : 173.0, n_buffer : 2000, eps : 6.2%\n",
      "n_episode :355, score : 164.0, n_buffer : 2000, eps : 6.2%\n",
      "n_episode :356, score : 221.0, n_buffer : 2000, eps : 6.2%\n",
      "n_episode :357, score : 183.0, n_buffer : 2000, eps : 6.2%\n",
      "n_episode :358, score : 180.0, n_buffer : 2000, eps : 6.2%\n",
      "n_episode :359, score : 208.0, n_buffer : 2000, eps : 6.2%\n",
      "n_episode :360, score : 175.0, n_buffer : 2000, eps : 6.2%\n",
      "n_episode :361, score : 217.0, n_buffer : 2000, eps : 6.2%\n",
      "n_episode :362, score : 250.0, n_buffer : 2000, eps : 6.2%\n",
      "n_episode :363, score : 255.0, n_buffer : 2000, eps : 6.2%\n",
      "n_episode :364, score : 192.0, n_buffer : 2000, eps : 6.2%\n",
      "n_episode :365, score : 146.0, n_buffer : 2000, eps : 6.2%\n",
      "n_episode :366, score : 126.0, n_buffer : 2000, eps : 6.2%\n",
      "n_episode :367, score : 149.0, n_buffer : 2000, eps : 6.2%\n",
      "n_episode :368, score : 157.0, n_buffer : 2000, eps : 6.2%\n",
      "n_episode :369, score : 122.0, n_buffer : 2000, eps : 6.2%\n",
      "n_episode :370, score : 124.0, n_buffer : 2000, eps : 6.2%\n",
      "n_episode :371, score : 159.0, n_buffer : 2000, eps : 6.1%\n",
      "n_episode :372, score : 324.0, n_buffer : 2000, eps : 6.1%\n",
      "n_episode :373, score : 162.0, n_buffer : 2000, eps : 6.1%\n",
      "n_episode :374, score : 114.0, n_buffer : 2000, eps : 6.1%\n",
      "n_episode :375, score : 123.0, n_buffer : 2000, eps : 6.1%\n",
      "n_episode :376, score : 161.0, n_buffer : 2000, eps : 6.1%\n",
      "n_episode :377, score : 184.0, n_buffer : 2000, eps : 6.1%\n",
      "n_episode :378, score : 156.0, n_buffer : 2000, eps : 6.1%\n",
      "n_episode :379, score : 129.0, n_buffer : 2000, eps : 6.1%\n",
      "n_episode :380, score : 156.0, n_buffer : 2000, eps : 6.1%\n",
      "n_episode :381, score : 158.0, n_buffer : 2000, eps : 6.1%\n",
      "n_episode :382, score : 150.0, n_buffer : 2000, eps : 6.1%\n",
      "n_episode :383, score : 139.0, n_buffer : 2000, eps : 6.1%\n",
      "n_episode :384, score : 140.0, n_buffer : 2000, eps : 6.1%\n",
      "n_episode :385, score : 133.0, n_buffer : 2000, eps : 6.1%\n",
      "n_episode :386, score : 147.0, n_buffer : 2000, eps : 6.1%\n",
      "n_episode :387, score : 156.0, n_buffer : 2000, eps : 6.1%\n",
      "n_episode :388, score : 137.0, n_buffer : 2000, eps : 6.1%\n",
      "n_episode :389, score : 139.0, n_buffer : 2000, eps : 6.1%\n",
      "n_episode :390, score : 138.0, n_buffer : 2000, eps : 6.0%\n",
      "n_episode :391, score : 151.0, n_buffer : 2000, eps : 6.0%\n",
      "n_episode :392, score : 165.0, n_buffer : 2000, eps : 6.0%\n",
      "n_episode :393, score : 182.0, n_buffer : 2000, eps : 6.0%\n",
      "n_episode :394, score : 172.0, n_buffer : 2000, eps : 6.0%\n",
      "n_episode :395, score : 182.0, n_buffer : 2000, eps : 6.0%\n",
      "n_episode :396, score : 189.0, n_buffer : 2000, eps : 6.0%\n",
      "n_episode :397, score : 206.0, n_buffer : 2000, eps : 6.0%\n",
      "n_episode :398, score : 200.0, n_buffer : 2000, eps : 6.0%\n",
      "n_episode :399, score : 178.0, n_buffer : 2000, eps : 6.0%\n",
      "n_episode :400, score : 197.0, n_buffer : 2000, eps : 6.0%\n",
      "n_episode :401, score : 236.0, n_buffer : 2000, eps : 6.0%\n",
      "n_episode :402, score : 221.0, n_buffer : 2000, eps : 6.0%\n",
      "n_episode :403, score : 236.0, n_buffer : 2000, eps : 6.0%\n",
      "n_episode :404, score : 227.0, n_buffer : 2000, eps : 6.0%\n",
      "n_episode :405, score : 266.0, n_buffer : 2000, eps : 6.0%\n",
      "n_episode :406, score : 500.0, n_buffer : 2000, eps : 6.0%\n"
     ]
    }
   ],
   "source": [
    "# import gym\n",
    "# import collections\n",
    "# import random\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# import torch.optim as optim\n",
    "\n",
    "# #Hyperparameters\n",
    "# learning_rate = 0.0001\n",
    "# gamma         = 0.999\n",
    "# buffer_limit  = 2000\n",
    "# batch_size    = 64\n",
    "\n",
    "# class ReplayBuffer():\n",
    "#     def __init__(self):\n",
    "#         self.buffer = collections.deque(maxlen=buffer_limit)\n",
    "    \n",
    "#     def put(self, transition):\n",
    "#         self.buffer.append(transition)\n",
    "    \n",
    "#     def sample(self, n):\n",
    "#         mini_batch = random.sample(self.buffer, n)\n",
    "#         s_lst, a_lst, r_lst, s_prime_lst, done_mask_lst = [], [], [], [], []\n",
    "        \n",
    "#         for transition in mini_batch:\n",
    "#             s, a, r, s_prime, done_mask = transition\n",
    "#             s_lst.append(s)\n",
    "#             a_lst.append([a])\n",
    "#             r_lst.append([r])\n",
    "#             s_prime_lst.append(s_prime)\n",
    "#             done_mask_lst.append([done_mask])\n",
    "\n",
    "#         return torch.tensor(s_lst, dtype=torch.float), torch.tensor(a_lst), \\\n",
    "#                torch.tensor(r_lst), torch.tensor(s_prime_lst, dtype=torch.float), \\\n",
    "#                torch.tensor(done_mask_lst)\n",
    "    \n",
    "#     def size(self):\n",
    "#         return len(self.buffer)\n",
    "\n",
    "# class Qnet(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Qnet, self).__init__()\n",
    "#         self.fc1 = nn.Linear(4, 24)\n",
    "#         self.fc2 = nn.Linear(24, 24)\n",
    "#         self.fc3 = nn.Linear(24, 2)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = F.relu(self.fc2(x))\n",
    "#         x = self.fc3(x)\n",
    "#         return x\n",
    "      \n",
    "#     def sample_action(self, obs, epsilon):\n",
    "#         out = self.forward(obs)\n",
    "#         coin = random.random()\n",
    "#         if coin < epsilon:\n",
    "#             return random.randint(0,1)\n",
    "#         else : \n",
    "#             return out.argmax().item()\n",
    "            \n",
    "# def train(q, q_target, memory, optimizer):\n",
    "#     for i in range(10):\n",
    "#         s,a,r,s_prime,done_mask = memory.sample(batch_size)\n",
    "\n",
    "#         q_out = q(s)\n",
    "#         q_a = q_out.gather(1,a)\n",
    "#         max_q_prime = q_target(s_prime).max(1)[0].unsqueeze(1)\n",
    "#         target = r + gamma * max_q_prime * done_mask\n",
    "#         loss = F.mse_loss(q_a, target)\n",
    "        \n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "# def main():\n",
    "#     env = gym.make('CartPole-v1')\n",
    "#     q = Qnet()\n",
    "#     q_target = Qnet()\n",
    "#     q_target.load_state_dict(q.state_dict())\n",
    "#     memory = ReplayBuffer()\n",
    "\n",
    "#     print_interval = 1\n",
    "#     score = 0.0  \n",
    "#     optimizer = optim.Adam(q.parameters(), lr=learning_rate)\n",
    "#     score_avg = 0.0\n",
    "#     for n_epi in range(10000):\n",
    "#         epsilon = max(0.01, 0.08 - 0.01*(n_epi/200)) #Linear annealing from 8% to 1%\n",
    "#         s = env.reset()\n",
    "#         done = False\n",
    "\n",
    "#         while not done:\n",
    "#             a = q.sample_action(torch.from_numpy(s).float(), epsilon)      \n",
    "#             s_prime, r, done, info = env.step(a)\n",
    "#             done_mask = 0.0 if done else 1.0\n",
    "#             memory.put((s,a,r/100.0,s_prime, done_mask))\n",
    "#             s = s_prime\n",
    "\n",
    "#             score += r\n",
    "#             score_avg = 0.9 * score_avg + 0.1 * score if score_avg != 0 else score\n",
    "#             if done:\n",
    "#                 break\n",
    "            \n",
    "#         if memory.size()>1000:\n",
    "#             train(q, q_target, memory, optimizer)\n",
    "#         if n_epi%print_interval==0 and n_epi!=0:\n",
    "#             q_target.load_state_dict(q.state_dict())\n",
    "#             print(\"n_episode :{}, score : {:.1f}, n_buffer : {}, eps : {:.1f}%\".format(\n",
    "#                                                             n_epi, score/print_interval, memory.size(), epsilon*100))\n",
    "#             score = 0.0\n",
    "            \n",
    "#         if score_avg > 400:\n",
    "#             torch.save(q_target.state_dict(),'./save_model/cartpole_Tdqn')\n",
    "#             break\n",
    "#     env.close()\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}