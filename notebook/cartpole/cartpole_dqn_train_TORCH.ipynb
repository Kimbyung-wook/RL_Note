{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('TORCH190': conda)",
   "metadata": {
    "interpreter": {
     "hash": "a62d03de4abdbf02f2c70aa26fad76bfe5b246d84e1d7929e4e42191e53d635f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "Refer from.. <br>\n",
    "https://github.com/yc930401/Actor-Critic-pytorch/blob/master/Actor-Critic.py <br>\n",
    "https://github.com/pranz24/pytorch-soft-actor-critic/blob/master/model.py <br>\n",
    "https://github.com/bentrevett/pytorch-rl/blob/master/2%20-%20Actor%20Critic%20%5BCartPole%5D.ipynb <br>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym \n",
    "import random \n",
    "import numpy as np \n",
    "from collections import deque \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, state_size, action_size):\n",
    "        super(DQN, self).__init__()\n",
    "        self.device = device\n",
    "        # Neural Net Layers\n",
    "        self.fc1 = nn.Linear(state_size, 24)\n",
    "        self.fc2 = nn.Linear(24, 24)\n",
    "        self.out = nn.Linear(24,action_size)\n",
    "        # Random Uniform\n",
    "        torch.nn.init.uniform_(self.out.weight,-1e-3,1e-3)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        q = self.out(x)\n",
    "        return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size, device):\n",
    "        self.state_size = state_size\n",
    "        self.action_size= action_size\n",
    "        self.device = device\n",
    "        \n",
    "        # Hyper-parameters for learning\n",
    "        self.discount_factor = 0.99\n",
    "        self.learning_rate = 0.001\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_decay = 0.999\n",
    "        self.epsilon_min = 0.01\n",
    "        \n",
    "        # Experience Replay\n",
    "        self.batch_size = 64\n",
    "        self.train_start = 1000\n",
    "        self.buffer_length = 2000\n",
    "        self.memory = deque(maxlen=self.buffer_length)\n",
    "\n",
    "        # Neural Network Architecture\n",
    "        self.model        = DQN(self.state_size, self.action_size).to(self.device)\n",
    "        self.target_model = DQN(self.state_size, self.action_size).to(self.device)\n",
    "        self.optimizer    = optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "        \n",
    "        self.update_target_model()\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state,\\\n",
    "                            action.to(self.device),\\\n",
    "                            torch.FloatTensor([reward]).to(self.device),\\\n",
    "                            torch.FloatTensor([next_state]).to(self.device),\\\n",
    "                            torch.LongTensor([done]).to(self.device)))\n",
    "\n",
    "    def update_target_model(self):\n",
    "        self.target_model.load_state_dict(self.model.state_dict())\n",
    "        # self.target_model.load_dict(self.model.state_dict())\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        # Exploration and Exploitation\n",
    "        if (np.random.rand() <= self.epsilon):\n",
    "            return torch.LongTensor([[random.randrange(self.action_size)]])\n",
    "        else:\n",
    "            return self.model.forward(state).max(1)[1].view(1, 1)\n",
    "\n",
    "    def train_model(self):\n",
    "        # Train from Experience Replay\n",
    "        # Training Condition - Memory Size\n",
    "        if len(self.memory) < self.train_start:\n",
    "            return 0.0\n",
    "        # Decaying Exploration Ratio\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "        # Sampling from the memory\n",
    "        mini_batch  = random.sample(self.memory, self.batch_size)\n",
    "        batch_states, batch_actions, batch_rewards, batch_next_states, batch_dones = zip(*mini_batch)\n",
    "\n",
    "        states      = torch.cat(batch_states)\n",
    "        actions     = torch.cat(batch_actions)\n",
    "        rewards     = torch.cat(batch_rewards)\n",
    "        next_states = torch.cat(batch_next_states)\n",
    "        dones       = torch.cat(batch_dones)\n",
    "\n",
    "        q           = self.model.forward(states).gather(1,actions).squeeze()\n",
    "        max_q       = self.target_model.forward(next_states).detach().max(1)[0]\n",
    "        target      = rewards + (1 - dones) * self.discount_factor * max_q\n",
    "        loss        = F.mse_loss(q,target)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return loss.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 | score avg 182.23 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 181 | score avg 182.61 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 182 | score avg 181.54 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 183 | score avg 180.49 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 184 | score avg 179.64 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 185 | score avg 180.78 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 186 | score avg 182.40 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 187 | score avg 183.06 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 188 | score avg 181.05 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 189 | score avg 180.05 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 190 | score avg 180.04 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 191 | score avg 178.94 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 192 | score avg 176.85 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 193 | score avg 174.26 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 194 | score avg 171.53 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 195 | score avg 169.88 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 196 | score avg 167.09 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 197 | score avg 165.78 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 198 | score avg 164.51 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 199 | score avg 163.65 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 200 | score avg 163.29 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 201 | score avg 163.26 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 202 | score avg 164.03 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 203 | score avg 163.13 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 204 | score avg 164.82 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 205 | score avg 167.24 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 206 | score avg 169.41 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 207 | score avg 171.27 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 208 | score avg 174.14 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 209 | score avg 161.53 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 210 | score avg 155.68 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 211 | score avg 147.41 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 212 | score avg 138.47 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 213 | score avg 131.82 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 214 | score avg 120.24 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 215 | score avg 116.82 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 216 | score avg 118.83 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 217 | score avg 140.35 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 218 | score avg 151.82 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 219 | score avg 160.43 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 220 | score avg 149.39 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 221 | score avg 152.85 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 222 | score avg 158.07 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 223 | score avg 168.16 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 224 | score avg 177.24 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 225 | score avg 181.52 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 226 | score avg 185.57 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 227 | score avg 191.31 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 228 | score avg 190.98 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 229 | score avg 189.08 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 230 | score avg 186.97 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 231 | score avg 186.28 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 232 | score avg 186.95 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 233 | score avg 190.15 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 234 | score avg 193.84 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 235 | score avg 199.15 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 236 | score avg 200.74 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 237 | score avg 202.97 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 238 | score avg 205.87 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 239 | score avg 206.28 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 240 | score avg 207.45 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 241 | score avg 207.71 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 242 | score avg 208.24 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 243 | score avg 209.41 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 244 | score avg 210.87 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 245 | score avg 210.89 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 246 | score avg 211.80 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 247 | score avg 210.72 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 248 | score avg 210.15 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 249 | score avg 210.73 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 250 | score avg 208.96 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 251 | score avg 209.56 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 252 | score avg 211.81 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 253 | score avg 211.23 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 254 | score avg 212.70 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 255 | score avg 213.13 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 256 | score avg 213.82 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 257 | score avg 217.74 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 258 | score avg 220.96 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 259 | score avg 229.07 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 260 | score avg 235.16 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 261 | score avg 219.84 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 262 | score avg 203.26 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 263 | score avg 185.83 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 264 | score avg 169.65 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 265 | score avg 153.69 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 266 | score avg 139.22 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 267 | score avg 126.20 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 268 | score avg 115.58 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 269 | score avg 107.02 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 270 | score avg 98.42 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 271 | score avg 89.97 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 272 | score avg 81.98 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 273 | score avg 75.38 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 274 | score avg 68.94 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 275 | score avg 63.05 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 276 | score avg 59.34 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 277 | score avg 54.91 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 278 | score avg 52.02 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 279 | score avg 51.02 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 280 | score avg 50.61 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 281 | score avg 51.95 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 282 | score avg 56.26 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 283 | score avg 63.33 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 284 | score avg 72.40 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 285 | score avg 86.56 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 286 | score avg 99.70 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 287 | score avg 122.33 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 288 | score avg 138.90 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 289 | score avg 143.51 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 290 | score avg 159.26 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 291 | score avg 163.73 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 292 | score avg 164.16 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 293 | score avg 165.44 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 294 | score avg 169.80 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 295 | score avg 173.42 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 296 | score avg 174.68 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 297 | score avg 175.61 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 298 | score avg 176.15 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 299 | score avg 177.63 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 300 | score avg 177.07 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 301 | score avg 175.36 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 302 | score avg 177.23 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 303 | score avg 177.80 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 304 | score avg 176.22 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 305 | score avg 177.00 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 306 | score avg 178.10 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 307 | score avg 178.89 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 308 | score avg 178.60 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 309 | score avg 178.14 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 310 | score avg 177.13 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 311 | score avg 178.41 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 312 | score avg 179.17 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 313 | score avg 179.06 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 314 | score avg 180.45 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 315 | score avg 181.31 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 316 | score avg 183.67 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 317 | score avg 182.61 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 318 | score avg 184.45 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 319 | score avg 186.40 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 320 | score avg 187.06 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 321 | score avg 187.06 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 322 | score avg 189.25 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 323 | score avg 191.83 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 324 | score avg 192.84 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 325 | score avg 194.36 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 326 | score avg 195.42 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 327 | score avg 198.58 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 328 | score avg 200.92 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 329 | score avg 205.53 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 330 | score avg 209.78 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 331 | score avg 214.10 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 332 | score avg 217.99 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 333 | score avg 220.39 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 334 | score avg 222.05 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 335 | score avg 224.75 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 336 | score avg 225.07 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 337 | score avg 225.66 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 338 | score avg 226.40 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 339 | score avg 227.46 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 340 | score avg 230.11 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 341 | score avg 231.20 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 342 | score avg 233.18 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 343 | score avg 233.96 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 344 | score avg 234.97 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 345 | score avg 236.97 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 346 | score avg 239.37 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 347 | score avg 239.54 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 348 | score avg 240.78 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 349 | score avg 243.10 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 350 | score avg 244.89 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 351 | score avg 245.70 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 352 | score avg 245.33 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 353 | score avg 245.40 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 354 | score avg 246.36 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 355 | score avg 246.52 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 356 | score avg 246.87 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 357 | score avg 248.18 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 358 | score avg 226.67 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 359 | score avg 226.20 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 360 | score avg 227.08 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 361 | score avg 224.47 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 362 | score avg 222.72 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 363 | score avg 220.45 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 364 | score avg 220.71 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 365 | score avg 220.74 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 366 | score avg 219.06 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 367 | score avg 215.16 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 368 | score avg 210.54 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 369 | score avg 190.59 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 370 | score avg 188.43 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 371 | score avg 187.39 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 372 | score avg 169.95 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 373 | score avg 171.95 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 374 | score avg 156.36 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 375 | score avg 172.62 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 376 | score avg 204.36 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 377 | score avg 233.92 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 378 | score avg 260.53 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 379 | score avg 236.18 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 380 | score avg 214.26 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 381 | score avg 194.53 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 382 | score avg 225.08 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 383 | score avg 203.47 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 384 | score avg 233.13 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 385 | score avg 259.81 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 386 | score avg 283.83 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 387 | score avg 285.45 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 388 | score avg 264.40 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 389 | score avg 287.96 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 390 | score avg 309.17 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 391 | score avg 328.25 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 392 | score avg 345.43 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 393 | score avg 356.08 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 394 | score avg 365.77 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 395 | score avg 372.10 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 396 | score avg 375.79 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 397 | score avg 376.41 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 398 | score avg 377.77 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 399 | score avg 378.19 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 400 | score avg 377.57 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 401 | score avg 377.11 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 402 | score avg 375.90 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 403 | score avg 372.91 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 404 | score avg 371.92 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 405 | score avg 371.33 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 406 | score avg 370.70 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 407 | score avg 369.23 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 408 | score avg 364.90 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 409 | score avg 363.21 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 410 | score avg 362.69 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 411 | score avg 365.42 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 412 | score avg 366.68 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 413 | score avg 367.91 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 414 | score avg 370.32 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 415 | score avg 372.69 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 416 | score avg 371.12 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 417 | score avg 346.31 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 418 | score avg 348.88 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 419 | score avg 349.09 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 420 | score avg 346.38 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 421 | score avg 345.74 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 422 | score avg 345.17 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 423 | score avg 343.15 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 424 | score avg 341.84 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 425 | score avg 342.35 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 426 | score avg 343.02 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 427 | score avg 341.82 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 428 | score avg 341.33 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 429 | score avg 339.00 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 430 | score avg 334.90 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 431 | score avg 329.71 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 432 | score avg 322.84 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 433 | score avg 316.46 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 434 | score avg 306.91 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 435 | score avg 299.72 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 436 | score avg 293.75 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 437 | score avg 287.67 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 438 | score avg 290.91 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 439 | score avg 306.51 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 440 | score avg 324.66 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 441 | score avg 326.90 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 442 | score avg 331.61 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 443 | score avg 335.85 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 444 | score avg 339.76 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 445 | score avg 346.59 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 446 | score avg 353.63 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 447 | score avg 351.66 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 448 | score avg 356.60 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 449 | score avg 364.84 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 450 | score avg 369.75 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 451 | score avg 334.68 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 452 | score avg 307.71 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 453 | score avg 280.44 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 454 | score avg 275.20 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 455 | score avg 271.48 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 456 | score avg 270.13 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 457 | score avg 265.32 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 458 | score avg 261.78 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 459 | score avg 256.81 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 460 | score avg 254.23 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 461 | score avg 252.40 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 462 | score avg 252.26 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 463 | score avg 253.64 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 464 | score avg 258.97 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 465 | score avg 263.58 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 466 | score avg 270.22 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 467 | score avg 281.30 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 468 | score avg 293.07 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 469 | score avg 313.76 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 470 | score avg 332.38 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 471 | score avg 343.05 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 472 | score avg 358.74 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 473 | score avg 372.87 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 474 | score avg 385.58 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 475 | score avg 395.82 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 476 | score avg 386.94 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 477 | score avg 388.45 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 478 | score avg 373.20 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 479 | score avg 382.18 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 480 | score avg 364.86 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 481 | score avg 345.78 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 482 | score avg 333.10 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 483 | score avg 349.79 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 484 | score avg 364.41 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 485 | score avg 377.97 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 486 | score avg 390.17 | mem length: 2000 | epsilon: 0.0100\n",
      "epi: 487 | score avg 401.16 | mem length: 2000 | epsilon: 0.0100\n",
      "End\n"
     ]
    }
   ],
   "source": [
    "%matplotlib tk\n",
    "\n",
    "ENV_NAME = 'CartPole-v1'\n",
    "EPISODES = 2000\n",
    "END_SCORE = 400\n",
    "# if gpu is to be used\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"DEVICE : \", device)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    env = gym.make(ENV_NAME)\n",
    "    state_size = env.observation_space.shape[0]\n",
    "    action_size = env.action_space.n\n",
    "    print('Env Name : ',ENV_NAME)\n",
    "    print('States {}, Actions {}'\n",
    "            .format(state_size, action_size))\n",
    "\n",
    "    agent = DQNAgent(state_size, action_size, device)\n",
    "\n",
    "    scores, episodes, epsilons, losses = [], [], [], []\n",
    "    score_avg = 0\n",
    "    \n",
    "    end = False\n",
    "    \n",
    "    # fig = plt.figure(1)\n",
    "    # fig.clf()\n",
    "    \n",
    "    for e in range(EPISODES):\n",
    "        done = False\n",
    "        score = 0\n",
    "        loss_list = []\n",
    "\n",
    "        state = env.reset()\n",
    "        \n",
    "        while not done:\n",
    "            #env.render()\n",
    "\n",
    "            # Interact with env.\n",
    "            state = torch.FloatTensor([state]).to(device)\n",
    "            action = agent.choose_action(state)\n",
    "            next_state, reward, done, info = env.step(action.item())\n",
    "            agent.remember(state, action, reward, next_state, done)\n",
    "            loss = agent.train_model()\n",
    "            state = next_state\n",
    "            \n",
    "            # \n",
    "            score += reward\n",
    "            loss_list.append(loss)\n",
    "            if done:\n",
    "                agent.update_target_model()\n",
    "\n",
    "                score_avg = 0.9 * score_avg + 0.1 * score if score_avg != 0 else score\n",
    "                print('epi: {:3d} | score avg {:3.2f} | mem length: {:4d} | epsilon: {:.4f}'\n",
    "                      .format(e, score_avg, len(agent.memory), agent.epsilon))\n",
    "\n",
    "                # Save data for plot\n",
    "                episodes.append(e)\n",
    "                scores.append(score_avg)\n",
    "                epsilons.append(agent.epsilon)\n",
    "                losses.append(np.mean(loss_list))\n",
    "\n",
    "                # View data\n",
    "                plt.subplot(311)\n",
    "                plt.plot(episodes, scores, 'b')\n",
    "                plt.xlabel('episode')\n",
    "                plt.ylabel('average score')\n",
    "                plt.title('cartpole DQN TORCH')\n",
    "                plt.grid()\n",
    "                \n",
    "                plt.subplot(312)\n",
    "                plt.plot(episodes, epsilons, 'b')\n",
    "                plt.xlabel('episode')\n",
    "                plt.ylabel('epsilon')\n",
    "                plt.grid()\n",
    "                \n",
    "                plt.subplot(313)\n",
    "                plt.plot(episodes, losses, 'b')\n",
    "                plt.xlabel('episode')\n",
    "                plt.ylabel('losses')\n",
    "                plt.grid()\n",
    "                \n",
    "                plt.savefig('./save_model/cartpole_dqn_TORCH.png')\n",
    "\n",
    "                if score_avg > END_SCORE:\n",
    "                    torch.save(agent.model.state_dict(),'./save_model/cartpole_dqn_TORCH')\n",
    "                    end = True\n",
    "                    break\n",
    "        if end == True:\n",
    "            env.close()\n",
    "            np.save('./save_model/data/cartpole_dqn_TORCH_epi',  episodes)\n",
    "            np.save('./save_model/data/cartpole_dqn_TORCH_score',scores)\n",
    "            np.save('./save_model/data/cartpole_dqn_TORCH_loss', losses)\n",
    "            print(\"End\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import gym\n",
    "# import collections\n",
    "# import random\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# import torch.optim as optim\n",
    "\n",
    "# #Hyperparameters\n",
    "# learning_rate = 0.0001\n",
    "# gamma         = 0.999\n",
    "# buffer_limit  = 2000\n",
    "# batch_size    = 64\n",
    "\n",
    "# class ReplayBuffer():\n",
    "#     def __init__(self):\n",
    "#         self.buffer = collections.deque(maxlen=buffer_limit)\n",
    "    \n",
    "#     def put(self, transition):\n",
    "#         self.buffer.append(transition)\n",
    "    \n",
    "#     def sample(self, n):\n",
    "#         mini_batch = random.sample(self.buffer, n)\n",
    "#         s_lst, a_lst, r_lst, s_prime_lst, done_mask_lst = [], [], [], [], []\n",
    "        \n",
    "#         for transition in mini_batch:\n",
    "#             s, a, r, s_prime, done_mask = transition\n",
    "#             s_lst.append(s)\n",
    "#             a_lst.append([a])\n",
    "#             r_lst.append([r])\n",
    "#             s_prime_lst.append(s_prime)\n",
    "#             done_mask_lst.append([done_mask])\n",
    "\n",
    "#         return torch.tensor(s_lst, dtype=torch.float), torch.tensor(a_lst), \\\n",
    "#                torch.tensor(r_lst), torch.tensor(s_prime_lst, dtype=torch.float), \\\n",
    "#                torch.tensor(done_mask_lst)\n",
    "    \n",
    "#     def size(self):\n",
    "#         return len(self.buffer)\n",
    "\n",
    "# class Qnet(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Qnet, self).__init__()\n",
    "#         self.fc1 = nn.Linear(4, 24)\n",
    "#         self.fc2 = nn.Linear(24, 24)\n",
    "#         self.fc3 = nn.Linear(24, 2)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = F.relu(self.fc2(x))\n",
    "#         x = self.fc3(x)\n",
    "#         return x\n",
    "      \n",
    "#     def sample_action(self, obs, epsilon):\n",
    "#         out = self.forward(obs)\n",
    "#         coin = random.random()\n",
    "#         if coin < epsilon:\n",
    "#             return random.randint(0,1)\n",
    "#         else : \n",
    "#             return out.argmax().item()\n",
    "            \n",
    "# def train(q, q_target, memory, optimizer):\n",
    "#     for i in range(10):\n",
    "#         s,a,r,s_prime,done_mask = memory.sample(batch_size)\n",
    "\n",
    "#         q_out = q(s)\n",
    "#         q_a = q_out.gather(1,a)\n",
    "#         max_q_prime = q_target(s_prime).max(1)[0].unsqueeze(1)\n",
    "#         target = r + gamma * max_q_prime * done_mask\n",
    "#         loss = F.mse_loss(q_a, target)\n",
    "        \n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "# def main():\n",
    "#     env = gym.make('CartPole-v1')\n",
    "#     q = Qnet()\n",
    "#     q_target = Qnet()\n",
    "#     q_target.load_state_dict(q.state_dict())\n",
    "#     memory = ReplayBuffer()\n",
    "\n",
    "#     print_interval = 1\n",
    "#     score = 0.0  \n",
    "#     optimizer = optim.Adam(q.parameters(), lr=learning_rate)\n",
    "#     score_avg = 0.0\n",
    "#     for n_epi in range(10000):\n",
    "#         epsilon = max(0.01, 0.08 - 0.01*(n_epi/200)) #Linear annealing from 8% to 1%\n",
    "#         s = env.reset()\n",
    "#         done = False\n",
    "\n",
    "#         while not done:\n",
    "#             a = q.sample_action(torch.from_numpy(s).float(), epsilon)      \n",
    "#             s_prime, r, done, info = env.step(a)\n",
    "#             done_mask = 0.0 if done else 1.0\n",
    "#             memory.put((s,a,r/100.0,s_prime, done_mask))\n",
    "#             s = s_prime\n",
    "\n",
    "#             score += r\n",
    "#             score_avg = 0.9 * score_avg + 0.1 * score if score_avg != 0 else score\n",
    "#             if done:\n",
    "#                 break\n",
    "            \n",
    "#         if memory.size()>1000:\n",
    "#             train(q, q_target, memory, optimizer)\n",
    "#         if n_epi%print_interval==0 and n_epi!=0:\n",
    "#             q_target.load_state_dict(q.state_dict())\n",
    "#             print(\"n_episode :{}, score : {:.1f}, n_buffer : {}, eps : {:.1f}%\".format(\n",
    "#                                                             n_epi, score/print_interval, memory.size(), epsilon*100))\n",
    "#             score = 0.0\n",
    "            \n",
    "#         if score_avg > 400:\n",
    "#             torch.save(q_target.state_dict(),'./save_model/cartpole_Tdqn')\n",
    "#             break\n",
    "#     env.close()\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}