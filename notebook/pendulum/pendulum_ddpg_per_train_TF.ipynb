{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('tf240': conda)"
  },
  "interpreter": {
   "hash": "61683dc6b2a2d3d4f2fca4fc9c31d7600238da1c31c9bb494e8f77b62993b62b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Refer from\n",
    "#  https://pasus.tistory.com/138\n",
    "#  https://horomary.hatenablog.com/entry/2020/06/26/003806\n",
    "#  https://keras.io/examples/rl/ddpg_pendulum/\n",
    "#\n",
    "import gym\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate, concatenate, Lambda\n",
    "from utils.prioritized_memory import PrioritizedMemory\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-07-30 19:46:45.197742: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# https://keras.io/examples/rl/ddpg_pendulum/\n",
    "class OUActionNoise:\n",
    "    def __init__(self, mean, std_deviation, theta=0.15, dt=1e-2, x_initial=None):\n",
    "        self.theta = theta\n",
    "        self.mean = mean\n",
    "        self.std_dev = std_deviation\n",
    "        self.dt = dt\n",
    "        self.x_initial = x_initial\n",
    "        self.reset()\n",
    "\n",
    "    def __call__(self):\n",
    "        # Formula taken from https://www.wikipedia.org/wiki/Ornstein-Uhlenbeck_process.\n",
    "        x = (\n",
    "            self.x_prev\n",
    "            + self.theta * (self.mean - self.x_prev) * self.dt\n",
    "            + self.std_dev * np.sqrt(self.dt) * np.random.normal(size=self.mean.shape)\n",
    "        )\n",
    "        # Store x into x_prev\n",
    "        # Makes next noise dependent on current one\n",
    "        self.x_prev = x\n",
    "        return x\n",
    "\n",
    "    def reset(self):\n",
    "        if self.x_initial is not None:\n",
    "            self.x_prev = self.x_initial\n",
    "        else:\n",
    "            self.x_prev = np.zeros_like(self.mean)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "class Actor(tf.keras.Model):\n",
    "    def __init__(self, state_size, action_size, action_min, action_max):\n",
    "        super(Actor, self).__init__()\n",
    "        self.action_min = action_min\n",
    "        self.action_max = action_max\n",
    "\n",
    "        self.fc1 = Dense(64, activation='relu')\n",
    "        self.fc2 = Dense(64, activation='relu')\n",
    "        # self.fc3 = Dense(16, activation='relu')\n",
    "        self.out= Dense(action_size, activation='tanh',kernel_initializer = tf.random_uniform_initializer(minval=-0.003, maxval=0.003)) # -1 ~ +1\n",
    "\n",
    "    def call(self, x):\n",
    "        x       = self.fc1(x)\n",
    "        x       = self.fc2(x)\n",
    "        # x       = self.fc3(x)\n",
    "        action  = self.out(x)\n",
    "        # return self.projected_to_action_space(action)\n",
    "        a = Lambda(lambda x: x*self.action_max)(action)\n",
    "        return a\n",
    "\n",
    "class Critic(tf.keras.Model):\n",
    "    def __init__(self, state_size, action_size):\n",
    "        super(Critic, self).__init__()\n",
    "        self.s1 = Dense(16, activation='relu')\n",
    "        self.s2 = Dense(32, activation='relu')\n",
    "        self.a1 = Dense(32, activation='relu')\n",
    "        self.a2 = Dense(32, activation='relu')\n",
    "        self.fc1= Dense(64, activation='relu')\n",
    "        self.fc2= Dense(64, activation='relu')\n",
    "        self.out= Dense(1,  activation='linear')\n",
    "\n",
    "    def call(self,state_action):\n",
    "        state  = state_action[0]\n",
    "        action = state_action[1]\n",
    "        s = self.s1(state)\n",
    "        s = self.s2(s)\n",
    "        a = self.a1(action)\n",
    "        a = self.a2(a)\n",
    "        c = concatenate([s,a],axis=-1)\n",
    "        x = self.fc1(c)\n",
    "        x = self.fc2(x)\n",
    "        q = self.out(x)\n",
    "        return q"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "class DDPGAgent:\n",
    "    def __init__(self, state_size, action_size, action_min, action_max):\n",
    "        self.state_size = state_size\n",
    "        self.action_size= action_size\n",
    "        self.action_min = action_min\n",
    "        self.action_max = action_max\n",
    "\n",
    "        # Hyper params for learning\n",
    "        self.discount_factor = 0.99\n",
    "        self.actor_learning_rate  = 0.001\n",
    "        self.critic_learning_rate = 0.002\n",
    "        self.tau = 0.005\n",
    "\n",
    "        # Experience Replay\n",
    "        self.batch_size = 64\n",
    "        self.train_start = 2000\n",
    "        self.memory_size = 50000\n",
    "        # ER\n",
    "        # self.memory = deque(maxlen=self.memory_size)\n",
    "        # PER\n",
    "        self.memory = PrioritizedMemory(capacity=self.memory_size)\n",
    "        # HER\n",
    "\n",
    "\n",
    "        # self.critic         = get_critic(self.state_size, self.action_size)\n",
    "        # self.target_critic  = get_critic(self.state_size, self.action_size)\n",
    "        # self.actor          = get_actor(self.state_size, self.action_size, self.action_max)\n",
    "        # self.target_actor   = get_actor(self.state_size, self.action_size, self.action_max)\n",
    "        self.critic_optimizer   = tf.keras.optimizers.Adam(lr=self.critic_learning_rate)\n",
    "        self.actor_optimizer    = tf.keras.optimizers.Adam(lr=self.actor_learning_rate)\n",
    "\n",
    "        self.critic         = Critic(self.state_size, self.action_size)\n",
    "        self.target_critic  = Critic(self.state_size, self.action_size)\n",
    "        self.actor          = Actor(self.state_size, self.action_size, self.action_min, self.action_max)\n",
    "        self.target_actor   = Actor(self.state_size, self.action_size, self.action_min, self.action_max)\n",
    "        self.actor.build(input_shape=(None, self.state_size))\n",
    "        self.target_actor.build(input_shape=(None, self.state_size))\n",
    "        state_in = Input((self.state_size,))\n",
    "        action_in = Input((self.action_size,))\n",
    "        self.actor(state_in)\n",
    "        self.target_actor(state_in)\n",
    "        self.critic([state_in, action_in])\n",
    "        self.target_critic([state_in, action_in])\n",
    "        self.actor.summary()\n",
    "        self.critic.summary()\n",
    "        \n",
    "        self.target_actor.set_weights(self.actor.get_weights())\n",
    "        self.target_critic.set_weights(self.critic.get_weights())\n",
    "\n",
    "        std_dev = 0.1\n",
    "        self.ou_noise = OUActionNoise(mean=np.zeros(1), std_deviation=float(std_dev) * np.ones(1))\n",
    "        \n",
    "        self.show_media_info = False\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        transition = (state, action, reward, next_state, done)\n",
    "        state = tf.convert_to_tensor([state], dtype=tf.float32)\n",
    "        action = tf.convert_to_tensor([action], dtype=tf.float32)\n",
    "        next_state = tf.convert_to_tensor([next_state], dtype=tf.float32)\n",
    "        \n",
    "        self.memory.append(transition)\n",
    "\n",
    "    def update_target_model(self):\n",
    "        tau = self.tau\n",
    "        for (net, target_net) in zip(   self.actor.trainable_variables,\n",
    "                                        self.target_actor.trainable_variables):\n",
    "            target_net.assign(tau * net + (1.0 - tau) * target_net)\n",
    "        for (net, target_net) in zip(   self.critic.trainable_variables,\n",
    "                                        self.target_critic.trainable_variables):\n",
    "            target_net.assign(tau * net + (1.0 - tau) * target_net)\n",
    "\n",
    "    def get_action(self,state):\n",
    "        state = tf.convert_to_tensor([state], dtype=tf.float32)\n",
    "        action = self.actor(state)\n",
    "        # Exploration and Exploitation\n",
    "        action_from_net = action.numpy()[0]\n",
    "        action_from_noise = self.ou_noise()\n",
    "        return np.clip(action_from_net+action_from_noise,self.action_min,self.action_max)\n",
    "\n",
    "    def train_model(self):\n",
    "        # Train from Experience Replay\n",
    "        # Training Condition - Memory Size\n",
    "        if len(self.memory) < self.train_start:\n",
    "            return\n",
    "        # Sampling from the memory\n",
    "        # ER\n",
    "        # mini_batch = random.sample(self.memory, self.batch_size)\n",
    "        # PER\n",
    "        mini_batch, idxs, is_weights = self.memory.sample(self.batch_size)\n",
    "\n",
    "        states      = tf.convert_to_tensor(np.array([sample[0] for sample in mini_batch]))\n",
    "        actions     = tf.convert_to_tensor(np.array([sample[1] for sample in mini_batch]))\n",
    "        rewards     = tf.convert_to_tensor(np.array([sample[2] for sample in mini_batch]),dtype=tf.float32)\n",
    "        rewards     = tf.expand_dims(rewards, axis = 1)\n",
    "        next_states = tf.convert_to_tensor(np.array([sample[3] for sample in mini_batch]))\n",
    "        dones       = tf.convert_to_tensor(np.array([sample[4] for sample in mini_batch]),dtype=tf.float32)\n",
    "        dones       = tf.expand_dims(dones, axis = 1)\n",
    "        \n",
    "        if self.show_media_info == False:\n",
    "            self.show_media_info = True\n",
    "            print('Start to train, check batch shapes')\n",
    "            print('shape of states', np.shape(states),type(states))\n",
    "            print('shape of actions', np.shape(actions),type(actions))\n",
    "            print('shape of next_states', np.shape(next_states),type(next_states)) \n",
    "            print('shape of dones', np.shape(dones),type(dones))\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            target_actions = self.target_actor(next_states,training=True)\n",
    "            target_q = self.target_critic([next_states,target_actions],training=True)\n",
    "            target_value = rewards + (1 - dones) * self.discount_factor * target_q\n",
    "            q = self.critic([states, actions],training=True)\n",
    "            td_error = target_value - q\n",
    "            critic_loss = tf.math.reduce_mean(is_weights*tf.math.square(td_error))\n",
    "        critic_params = self.critic.trainable_variables\n",
    "        critic_grads = tape.gradient(critic_loss, critic_params)\n",
    "        self.critic_optimizer.apply_gradients(zip(critic_grads, critic_params))\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            new_actions = self.actor(states,training=True)\n",
    "            new_q = self.critic([states, new_actions],training=True)\n",
    "            actor_loss = -tf.reduce_mean(new_q)\n",
    "        actor_params = self.actor.trainable_variables\n",
    "        actor_grads = tape.gradient(actor_loss, actor_params)\n",
    "        self.actor_optimizer.apply_gradients(zip(actor_grads, actor_params))\n",
    "        \n",
    "        self.update_target_model()\n",
    "        for i in range(self.batch_size):\n",
    "            self.memory.update(idxs[i],abs(td_error[i].numpy()))\n",
    "        return\n",
    "    def save_model(self):\n",
    "        self.actor.save_weights(\"./save_model/pendulum_ddpg_per_TF_actor\", save_format=\"tf\")\n",
    "        self.critic.save_weights(\"./save_model/pendulum_ddpg_per_TF_critic\", save_format=\"tf\")\n",
    "        return\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# %matplotlib tk\n",
    "\n",
    "ENV_NAME = 'Pendulum-v0'\n",
    "EPISODES = 200\n",
    "END_SCORE = -200\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    env = gym.make(ENV_NAME)\n",
    "    state_size  = env.observation_space.shape[0]\n",
    "    action_size = env.action_space.shape[0]\n",
    "    action_min  = env.action_space.low[0]\n",
    "    action_max  = env.action_space.high[0]\n",
    "\n",
    "    agent = DDPGAgent(state_size, action_size, action_min, action_max)\n",
    "    print('Env Name : ',ENV_NAME)\n",
    "    print('States {0}, Actions {1}'.format(state_size, action_size))\n",
    "    print('Action space {0:.2f} ~ {1:.2f}'.format(action_min, action_max))\n",
    "    scores_avg, scores_raw, episodes, losses = [], [], [], []\n",
    "    score_avg = 0\n",
    "\n",
    "    end = False\n",
    "    show_media_info = True\n",
    "    \n",
    "    fig = plt.figure(1)\n",
    "    fig.clf()\n",
    "    \n",
    "    for e in range(EPISODES):\n",
    "        done = False\n",
    "        score = 0\n",
    "        state = env.reset()\n",
    "        while not done:\n",
    "            # env.render()\n",
    "\n",
    "            # Interact with env.\n",
    "            action = agent.get_action(state)\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            agent.remember(state, action, reward, next_state, done)\n",
    "            agent.train_model()\n",
    "            state = next_state\n",
    "\n",
    "            # \n",
    "            score += reward\n",
    "            if show_media_info:\n",
    "                print(\"State Shape : \", np.shape(state))\n",
    "                print(\"Action Shape : \", np.shape(action))\n",
    "                print(\"Reward Shape : \", np.shape(reward))\n",
    "                print(\"done Shape : \", np.shape(done))\n",
    "                show_media_info = False\n",
    "            if done:\n",
    "                score_avg = 0.9 * score_avg + 0.1 * score if score_avg != 0 else score\n",
    "                print(\"episode: {0:3d} | score avg: {1:3.2f} | mem size {2:6d} |\"\n",
    "                    .format(e, score_avg, len(agent.memory)))\n",
    "\n",
    "                episodes.append(e)\n",
    "                scores_avg.append(score_avg)\n",
    "                scores_raw.append(score)\n",
    "\n",
    "                plt.plot(episodes, scores_avg, 'b')\n",
    "                plt.xlabel('episode'); plt.ylabel('average score'); plt.grid()\n",
    "                plt.title('pendulum DDPG')\n",
    "                plt.savefig(\"./result//pendulum_ddpg_per_TF.png\")\n",
    "\n",
    "                # 이동 평균이 0 이상일 때 종료\n",
    "                if score_avg > END_SCORE:\n",
    "                    agent.save_model()\n",
    "                    end = True\n",
    "                    break\n",
    "        if end == True:\n",
    "            env.close()\n",
    "            np.save('./save_model/data/pendulum_ddpg_per_TF_epi',  episodes)\n",
    "            np.save('./save_model/data/pendulum_ddpg_per_TF_score',scores)\n",
    "            print(\"End\")\n",
    "            break"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-07-30 19:46:46.365165: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-07-30 19:46:46.366330: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-07-30 19:46:46.395698: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:65:00.0 name: GeForce RTX 3080 computeCapability: 8.6\n",
      "coreClock: 1.74GHz coreCount: 68 deviceMemorySize: 9.75GiB deviceMemoryBandwidth: 707.88GiB/s\n",
      "2021-07-30 19:46:46.395763: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-07-30 19:46:46.401468: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-07-30 19:46:46.401586: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-07-30 19:46:46.403156: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-07-30 19:46:46.403512: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-07-30 19:46:46.403735: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory\n",
      "2021-07-30 19:46:46.404730: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-07-30 19:46:46.404922: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-07-30 19:46:46.404937: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-07-30 19:46:46.405417: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-07-30 19:46:46.406922: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-07-30 19:46:46.406960: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-07-30 19:46:46.406967: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"actor\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_14 (Dense)             multiple                  256       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             multiple                  4160      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             multiple                  65        \n",
      "=================================================================\n",
      "Total params: 4,481\n",
      "Trainable params: 4,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"critic\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                multiple                  64        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  544       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  64        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              multiple                  1056      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              multiple                  4160      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              multiple                  4160      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              multiple                  65        \n",
      "=================================================================\n",
      "Total params: 10,113\n",
      "Trainable params: 10,113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Env Name :  Pendulum-v0\n",
      "States 3, Actions 1\n",
      "Action space -2.00 ~ 2.00\n",
      "State Shape :  (3,)\n",
      "Action Shape :  (1,)\n",
      "Reward Shape :  ()\n",
      "done Shape :  ()\n",
      "episode:   0 | score avg: -1480.80 | mem size    200 |\n",
      "episode:   1 | score avg: -1473.28 | mem size    400 |\n",
      "episode:   2 | score avg: -1495.11 | mem size    600 |\n",
      "episode:   3 | score avg: -1460.24 | mem size    800 |\n",
      "episode:   4 | score avg: -1454.05 | mem size   1000 |\n",
      "episode:   5 | score avg: -1433.72 | mem size   1200 |\n",
      "episode:   6 | score avg: -1386.63 | mem size   1400 |\n",
      "episode:   7 | score avg: -1364.61 | mem size   1600 |\n",
      "episode:   8 | score avg: -1334.96 | mem size   1800 |\n",
      "Start to train, check batch shapes\n",
      "shape of states (64, 3) <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "shape of actions (64, 1) <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "shape of next_states (64, 3) <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "shape of dones (64, 1) <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "episode:   9 | score avg: -1328.62 | mem size   2000 |\n",
      "episode:  10 | score avg: -1356.15 | mem size   2200 |\n",
      "episode:  11 | score avg: -1345.55 | mem size   2400 |\n",
      "episode:  12 | score avg: -1324.98 | mem size   2600 |\n",
      "episode:  13 | score avg: -1317.40 | mem size   2800 |\n",
      "episode:  14 | score avg: -1331.88 | mem size   3000 |\n",
      "episode:  15 | score avg: -1369.81 | mem size   3200 |\n",
      "episode:  16 | score avg: -1341.54 | mem size   3400 |\n",
      "episode:  17 | score avg: -1336.02 | mem size   3600 |\n",
      "episode:  18 | score avg: -1316.32 | mem size   3800 |\n",
      "episode:  19 | score avg: -1368.21 | mem size   4000 |\n",
      "episode:  20 | score avg: -1322.51 | mem size   4200 |\n",
      "episode:  21 | score avg: -1299.55 | mem size   4400 |\n",
      "episode:  22 | score avg: -1332.00 | mem size   4600 |\n",
      "episode:  23 | score avg: -1300.10 | mem size   4800 |\n",
      "episode:  24 | score avg: -1281.75 | mem size   5000 |\n",
      "episode:  25 | score avg: -1272.37 | mem size   5200 |\n",
      "episode:  26 | score avg: -1255.71 | mem size   5400 |\n",
      "episode:  27 | score avg: -1228.77 | mem size   5600 |\n",
      "episode:  28 | score avg: -1220.98 | mem size   5800 |\n",
      "episode:  29 | score avg: -1217.43 | mem size   6000 |\n",
      "episode:  30 | score avg: -1216.53 | mem size   6200 |\n",
      "episode:  31 | score avg: -1287.07 | mem size   6400 |\n",
      "episode:  32 | score avg: -1260.19 | mem size   6600 |\n",
      "episode:  33 | score avg: -1255.15 | mem size   6800 |\n",
      "episode:  34 | score avg: -1247.35 | mem size   7000 |\n",
      "episode:  35 | score avg: -1225.89 | mem size   7200 |\n",
      "episode:  36 | score avg: -1277.67 | mem size   7400 |\n",
      "episode:  37 | score avg: -1252.66 | mem size   7600 |\n",
      "episode:  38 | score avg: -1226.43 | mem size   7800 |\n",
      "episode:  39 | score avg: -1215.11 | mem size   8000 |\n",
      "episode:  40 | score avg: -1201.98 | mem size   8200 |\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/moai/Documents/RL_Note/notebook/pendulum/utils/prioritized_memory.py:48: RuntimeWarning: divide by zero encountered in power\n",
      "  is_weight = np.power(self.tree.n_entries * sampling_probabilities, -self.beta)\n",
      "/home/moai/Documents/RL_Note/notebook/pendulum/utils/prioritized_memory.py:49: RuntimeWarning: invalid value encountered in true_divide\n",
      "  is_weight /= is_weight.max()\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_110869/4078732369.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremember\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_110869/1805366281.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mmini_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mstates\u001b[0m      \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmini_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mactions\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmini_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mrewards\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmini_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_110869/1805366281.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mmini_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mstates\u001b[0m      \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmini_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mactions\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmini_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mrewards\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmini_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not subscriptable"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "env.close()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ]
}