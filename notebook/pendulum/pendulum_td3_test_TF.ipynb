{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('TF240': conda)",
   "metadata": {
    "interpreter": {
     "hash": "8f237aa33f5a133d3a67a1e00bf3cb9d47b6c38bcc6ab493273f5d4df41b8866"
    }
   }
  },
  "interpreter": {
   "hash": "fbba320975a9114d2433fba427f26c389728c846a7c4900c481dce2a1a9f6231"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Refer from\r\n",
    "#  https://pasus.tistory.com/138\r\n",
    "#  https://horomary.hatenablog.com/entry/2020/06/26/003806\r\n",
    "#  https://keras.io/examples/rl/ddpg_pendulum/\r\n",
    "#\r\n",
    "import gym\r\n",
    "import sys\r\n",
    "import random\r\n",
    "import numpy as np\r\n",
    "import tensorflow as tf\r\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate, concatenate, Lambda\r\n",
    "from collections import deque\r\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "class Actor(tf.keras.Model):\r\n",
    "    def __init__(self, state_size, action_size, action_min, action_max):\r\n",
    "        super(Actor, self).__init__()\r\n",
    "        self.action_min = action_min\r\n",
    "        self.action_max = action_max\r\n",
    "\r\n",
    "        self.fc1 = Dense(64, activation='relu')\r\n",
    "        self.fc2 = Dense(64, activation='relu')\r\n",
    "        # self.fc3 = Dense(16, activation='relu')\r\n",
    "        self.out= Dense(action_size, activation='tanh',kernel_initializer = tf.random_uniform_initializer(minval=-0.003, maxval=0.003)) # -1 ~ +1\r\n",
    "\r\n",
    "    def call(self, x):\r\n",
    "        x       = self.fc1(x)\r\n",
    "        x       = self.fc2(x)\r\n",
    "        # x       = self.fc3(x)\r\n",
    "        action  = self.out(x)\r\n",
    "        # return self.projected_to_action_space(action)\r\n",
    "        a = Lambda(lambda x: x*self.action_max)(action)\r\n",
    "        return a\r\n",
    "\r\n",
    "class Critic(tf.keras.Model):\r\n",
    "    def __init__(self, state_size, action_size):\r\n",
    "        super(Critic, self).__init__()\r\n",
    "        self.s1 = Dense(16, activation='relu')\r\n",
    "        self.s2 = Dense(32, activation='relu')\r\n",
    "        self.a1 = Dense(32, activation='relu')\r\n",
    "        self.a2 = Dense(32, activation='relu')\r\n",
    "        self.fc1= Dense(64, activation='relu')\r\n",
    "        self.fc2= Dense(64, activation='relu')\r\n",
    "        self.out= Dense(1,  activation='linear')\r\n",
    "\r\n",
    "    def call(self,state,action):\r\n",
    "        # state  = state_action[0]\r\n",
    "        # action = state_action[1]\r\n",
    "        s = self.s1(state)\r\n",
    "        s = self.s2(s)\r\n",
    "        a = self.a1(action)\r\n",
    "        a = self.a2(a)\r\n",
    "        c = concatenate([s,a],axis=-1)\r\n",
    "        x = self.fc1(c)\r\n",
    "        x = self.fc2(x)\r\n",
    "        q = self.out(x)\r\n",
    "        return q"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "class TD3Agent:\r\n",
    "    def __init__(self, state_size, action_size, action_min, action_max):\r\n",
    "        self.state_size = state_size\r\n",
    "        self.action_size= action_size\r\n",
    "        self.action_min = action_min\r\n",
    "        self.action_max = action_max\r\n",
    "        \r\n",
    "        self.actor          = Actor(self.state_size, self.action_size, self.action_min, self.action_max)\r\n",
    "\r\n",
    "        self.actor.build(input_shape=(None, self.state_size))\r\n",
    "        state_in = Input((self.state_size,))\r\n",
    "        self.actor(state_in)\r\n",
    "        self.actor.summary()\r\n",
    "\r\n",
    "        self.load_model()\r\n",
    "\r\n",
    "    def get_action(self,state):\r\n",
    "        state = tf.convert_to_tensor([state], dtype=tf.float32)\r\n",
    "        action = self.actor(state)\r\n",
    "        # Exploration and Exploitation\r\n",
    "        return np.clip(action.numpy()[0],self.action_min,self.action_max)\r\n",
    "\r\n",
    "    def load_model(self):\r\n",
    "        self.actor.load_weights(\"./save_model/pendulum_td3_TF_actor\")\r\n",
    "        return\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# %matplotlib tk\r\n",
    "\r\n",
    "ENV_NAME = 'Pendulum-v0'\r\n",
    "EPISODES = 5\r\n",
    "# END_SCORE = -200\r\n",
    "\r\n",
    "if __name__ == \"__main__\":\r\n",
    "    env = gym.make(ENV_NAME)\r\n",
    "    state_size  = env.observation_space.shape[0]\r\n",
    "    action_size = env.action_space.shape[0]\r\n",
    "    action_min  = env.action_space.low[0]\r\n",
    "    action_max  = env.action_space.high[0]\r\n",
    "\r\n",
    "    agent = TD3Agent(state_size, action_size, action_min, action_max)\r\n",
    "    print('Env Name : ',ENV_NAME)\r\n",
    "    print('States {0}, Actions {1}'.format(state_size, action_size))\r\n",
    "    print('Action space {0:.2f} ~ {1:.2f}'.format(action_min, action_max))\r\n",
    "    \r\n",
    "    fig = plt.figure(1)\r\n",
    "    fig.clf()\r\n",
    "    \r\n",
    "    for e in range(EPISODES):\r\n",
    "        done = False\r\n",
    "        score = 0\r\n",
    "        state = env.reset()\r\n",
    "        while not done:\r\n",
    "            env.render()\r\n",
    "\r\n",
    "            # Interact with env.\r\n",
    "            action = agent.get_action(state)\r\n",
    "            next_state, reward, done, info = env.step(action)\r\n",
    "            state = next_state\r\n",
    "\r\n",
    "            # \r\n",
    "            score += reward\r\n",
    "            if done:\r\n",
    "                print(\"episode: {0:3d} | score : {1:3.2f} |\".format(e, score))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"actor\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                multiple                  256       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  4160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  65        \n",
      "=================================================================\n",
      "Total params: 4,481\n",
      "Trainable params: 4,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Env Name :  Pendulum-v0\n",
      "States 3, Actions 1\n",
      "Action space -2.00 ~ 2.00\n",
      "state at loop :  (3,) <class 'numpy.ndarray'>\n",
      "state_new at loop :  (3,) <class 'numpy.ndarray'>\n",
      "state at loop :  (3,) <class 'numpy.ndarray'>\n",
      "state_new at loop :  (3,) <class 'numpy.ndarray'>\n",
      "state at loop :  (3,) <class 'numpy.ndarray'>\n",
      "state_new at loop :  (3,) <class 'numpy.ndarray'>\n",
      "state at loop :  (3,) <class 'numpy.ndarray'>\n",
      "state_new at loop :  (3,) <class 'numpy.ndarray'>\n",
      "state at loop :  (3,) <class 'numpy.ndarray'>\n",
      "state_new at loop :  (3,) <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "env.close()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ]
}