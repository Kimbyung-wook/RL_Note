{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('tf240': conda)"
  },
  "interpreter": {
   "hash": "61683dc6b2a2d3d4f2fca4fc9c31d7600238da1c31c9bb494e8f77b62993b62b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find RL_Note path and append sys path\n",
    "import os, sys\n",
    "cwd = os.getcwd()\n",
    "pos = cwd.find('RL_Note')\n",
    "root_path = cwd[0:pos] + 'RL_Note'\n",
    "sys.path.append(root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Refer from\n",
    "#  https://pasus.tistory.com/138\n",
    "#  https://horomary.hatenablog.com/entry/2020/06/26/003806\n",
    "#  https://keras.io/examples/rl/ddpg_pendulum/\n",
    "#\n",
    "import gym\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate, concatenate, Lambda\n",
    "import matplotlib.pyplot as plt\n",
    "from pys.utils.memory import ReplayMemory"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-08-02 13:46:14.955101: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "class Actor(tf.keras.Model):\n",
    "    def __init__(self, state_size, action_size, action_min, action_max):\n",
    "        super(Actor, self).__init__()\n",
    "        self.action_min = action_min\n",
    "        self.action_max = action_max\n",
    "\n",
    "        self.fc1 = Dense(64, activation='relu')\n",
    "        self.fc2 = Dense(64, activation='relu')\n",
    "        # self.fc3 = Dense(16, activation='relu')\n",
    "        self.out= Dense(action_size, activation='tanh',kernel_initializer = tf.random_uniform_initializer(minval=-0.003, maxval=0.003)) # -1 ~ +1\n",
    "\n",
    "    def call(self, x):\n",
    "        x       = self.fc1(x)\n",
    "        x       = self.fc2(x)\n",
    "        # x       = self.fc3(x)\n",
    "        action  = self.out(x)\n",
    "        # return self.projected_to_action_space(action)\n",
    "        a = Lambda(lambda x: x*self.action_max)(action)\n",
    "        return a\n",
    "\n",
    "class Critic(tf.keras.Model):\n",
    "    def __init__(self, state_size, action_size):\n",
    "        super(Critic, self).__init__()\n",
    "        self.s1 = Dense(16, activation='relu')\n",
    "        self.s2 = Dense(32, activation='relu')\n",
    "        self.a1 = Dense(32, activation='relu')\n",
    "        self.a2 = Dense(32, activation='relu')\n",
    "        self.fc1= Dense(64, activation='relu')\n",
    "        self.fc2= Dense(64, activation='relu')\n",
    "        self.out= Dense(1,  activation='linear')\n",
    "\n",
    "    def call(self,state,action):\n",
    "        # state  = state_action[0]\n",
    "        # action = state_action[1]\n",
    "        s = self.s1(state)\n",
    "        s = self.s2(s)\n",
    "        a = self.a1(action)\n",
    "        a = self.a2(a)\n",
    "        c = concatenate([s,a],axis=-1)\n",
    "        x = self.fc1(c)\n",
    "        x = self.fc2(x)\n",
    "        q = self.out(x)\n",
    "        return q"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "class TD3Agent:\n",
    "    def __init__(self, state_size, action_size, action_min, action_max):\n",
    "        self.state_size = state_size\n",
    "        self.action_size= action_size\n",
    "        self.action_min = action_min\n",
    "        self.action_max = action_max\n",
    "\n",
    "        # Hyper params for learning\n",
    "        self.discount_factor = 0.99\n",
    "        self.actor_learning_rate  = 0.001\n",
    "        self.critic_learning_rate = 0.002\n",
    "        self.tau = 0.005\n",
    "\n",
    "        # Experience Replay\n",
    "        self.batch_size = 64\n",
    "        self.train_start = 2000\n",
    "        self.buffer_size = 50000\n",
    "        self.memory = ReplayMemory(capacity=self.buffer_size)\n",
    "        \n",
    "        self.critic1_optimizer   = tf.keras.optimizers.Adam(lr=self.critic_learning_rate)\n",
    "        self.critic2_optimizer   = tf.keras.optimizers.Adam(lr=self.critic_learning_rate)\n",
    "        self.actor_optimizer    = tf.keras.optimizers.Adam(lr=self.actor_learning_rate)\n",
    "\n",
    "        self.critic1        = Critic(self.state_size, self.action_size)\n",
    "        self.critic2        = Critic(self.state_size, self.action_size)\n",
    "        self.target_critic1 = Critic(self.state_size, self.action_size)\n",
    "        self.target_critic2 = Critic(self.state_size, self.action_size)\n",
    "        self.actor          = Actor(self.state_size, self.action_size, self.action_min, self.action_max)\n",
    "        self.target_actor   = Actor(self.state_size, self.action_size, self.action_min, self.action_max)\n",
    "\n",
    "        self.actor.build(input_shape=(None, self.state_size))\n",
    "        self.target_actor.build(input_shape=(None, self.state_size))\n",
    "        state_in = Input((self.state_size,))\n",
    "        action_in = Input((self.action_size,))\n",
    "        self.actor(state_in)\n",
    "        self.target_actor(state_in)\n",
    "        self.critic1(state_in, action_in)\n",
    "        self.critic2(state_in, action_in)\n",
    "        self.target_critic1(state_in, action_in)\n",
    "        self.target_critic2(state_in, action_in)\n",
    "\n",
    "        self.actor.summary()\n",
    "        self.critic1.summary()\n",
    "        self.critic2.summary()\n",
    "        \n",
    "        self.target_actor.set_weights(self.actor.get_weights())\n",
    "        self.target_critic1.set_weights(self.critic1.get_weights())\n",
    "        self.target_critic2.set_weights(self.critic2.get_weights())\n",
    "\n",
    "        self.update_freq = 2\n",
    "        self.train_idx = 0\n",
    "        self.show_media_info = False\n",
    "        self.noise_std_dev = 0.2\n",
    "        self.noise_mean = 0.0\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def update_target_model(self):\n",
    "        tau = self.tau\n",
    "        for (net, target_net) in zip(   self.actor.trainable_variables,\n",
    "                                        self.target_actor.trainable_variables):\n",
    "            target_net.assign(tau * net + (1.0 - tau) * target_net)\n",
    "        for (net, target_net) in zip(   self.critic1.trainable_variables,\n",
    "                                        self.target_critic1.trainable_variables):\n",
    "            target_net.assign(tau * net + (1.0 - tau) * target_net)\n",
    "        for (net, target_net) in zip(   self.critic2.trainable_variables,\n",
    "                                        self.target_critic2.trainable_variables):\n",
    "            target_net.assign(tau * net + (1.0 - tau) * target_net)\n",
    "            \n",
    "    def get_action(self,state):\n",
    "        state = tf.convert_to_tensor([state], dtype=tf.float32)\n",
    "        action = self.actor(state)\n",
    "        noise = np.random.randn(self.action_size)*self.noise_std_dev + self.noise_mean\n",
    "        # Exploration and Exploitation\n",
    "        return np.clip(action.numpy()[0]+noise,self.action_min,self.action_max)\n",
    "\n",
    "    def train_model(self):\n",
    "        # Train from Experience Replay\n",
    "        # Training Condition - Memory Size\n",
    "        if len(self.memory) < self.train_start:\n",
    "            return\n",
    "        # Sampling from the memory\n",
    "        mini_batch = self.memory.sample(self.batch_size)\n",
    "        \n",
    "        states      = tf.convert_to_tensor(np.array([sample[0] for sample in mini_batch]))\n",
    "        actions     = tf.convert_to_tensor(np.array([sample[1] for sample in mini_batch]))\n",
    "        rewards     = tf.convert_to_tensor(np.array([sample[2] for sample in mini_batch]),dtype=tf.float32)\n",
    "        rewards     = tf.expand_dims(rewards, axis = 1)\n",
    "        next_states = tf.convert_to_tensor(np.array([sample[3] for sample in mini_batch]))\n",
    "        dones       = tf.convert_to_tensor(np.array([sample[4] for sample in mini_batch]),dtype=tf.float32)\n",
    "        dones       = tf.expand_dims(dones, axis = 1)\n",
    "        \n",
    "        if self.show_media_info == False:\n",
    "            self.show_media_info = True\n",
    "            print('Start to train, check batch shapes')\n",
    "            print('**** shape of states', np.shape(states),type(states))\n",
    "            print('**** shape of actions', np.shape(actions),type(actions))\n",
    "            print('**** shape of rewards', np.shape(rewards),type(rewards))\n",
    "            print('**** shape of next_states', np.shape(next_states),type(next_states))\n",
    "            print('**** shape of dones', np.shape(dones),type(dones))\n",
    "\n",
    "        target_actions = self.target_actor(next_states,training=True)\n",
    "        target_q1 = self.target_critic1(next_states,target_actions,training=True)\n",
    "        target_q2 = self.target_critic2(next_states,target_actions,training=True)\n",
    "        target_q_min = tf.minimum(target_q1,target_q2) # Clipping Double Q\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            target_value = rewards + (1.0 - dones) * self.discount_factor * target_q_min\n",
    "            q = self.critic1(states, actions, training=True)\n",
    "            critic1_loss = tf.math.reduce_mean(tf.math.square(target_value - q))\n",
    "        critic1_params = self.critic1.trainable_variables\n",
    "        critic1_grads = tape.gradient(critic1_loss, critic1_params)\n",
    "        self.critic1_optimizer.apply_gradients(zip(critic1_grads, critic1_params))\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            target_value = rewards + (1.0 - dones) * self.discount_factor * target_q_min\n",
    "            q = self.critic2(states, actions, training=True)\n",
    "            critic2_loss = tf.math.reduce_mean(tf.math.square(target_value - q))\n",
    "        critic2_params = self.critic2.trainable_variables\n",
    "        critic2_grads = tape.gradient(critic2_loss, critic2_params)\n",
    "        self.critic2_optimizer.apply_gradients(zip(critic2_grads, critic2_params))\n",
    "\n",
    "        self.train_idx = self.train_idx + 1\n",
    "        if self.train_idx % self.update_freq == 0:\n",
    "          with tf.GradientTape() as tape:\n",
    "              new_actions = self.actor(states,training=True)\n",
    "              new_q = self.critic1(states, new_actions,training=True)\n",
    "              actor_loss = -tf.reduce_mean(new_q)\n",
    "          actor_params = self.actor.trainable_variables\n",
    "          actor_grads = tape.gradient(actor_loss, actor_params)\n",
    "          self.actor_optimizer.apply_gradients(zip(actor_grads, actor_params))\n",
    "\n",
    "          self.update_target_model()\n",
    "        return\n",
    "\n",
    "    def save_model(self):\n",
    "        self.actor.save_weights(\"./save_model/pendulum_td3_TF_actor\", save_format=\"tf\")\n",
    "        self.critic1.save_weights(\"./save_model/pendulum_td3_TF_critic1\", save_format=\"tf\")\n",
    "        self.critic2.save_weights(\"./save_model/pendulum_td3_TF_critic2\", save_format=\"tf\")\n",
    "        return\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# %matplotlib tk\n",
    "\n",
    "ENV_NAME = 'Pendulum-v0'\n",
    "EPISODES = 300\n",
    "END_SCORE = -200\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    env = gym.make(ENV_NAME)\n",
    "    state_size  = env.observation_space.shape[0]\n",
    "    action_size = env.action_space.shape[0]\n",
    "    action_min  = env.action_space.low[0]\n",
    "    action_max  = env.action_space.high[0]\n",
    "\n",
    "    agent = TD3Agent(state_size, action_size, action_min, action_max)\n",
    "    print('Env Name : ',ENV_NAME)\n",
    "    print('States {0}, Actions {1}'.format(state_size, action_size))\n",
    "    print('Action space {0:.2f} ~ {1:.2f}'.format(action_min, action_max))\n",
    "    scores_avg, scores_raw, episodes, losses = [], [], [], []\n",
    "    score_avg = 0\n",
    "\n",
    "    end = False\n",
    "    show_media_info = True\n",
    "    \n",
    "    fig = plt.figure(1)\n",
    "    fig.clf()\n",
    "    \n",
    "    for e in range(EPISODES):\n",
    "        done = False\n",
    "        score = 0\n",
    "        state = env.reset()\n",
    "        while not done:\n",
    "            # env.render()\n",
    "\n",
    "            # Interact with env.\n",
    "            action = agent.get_action(state)\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            agent.remember(state, action, reward, next_state, done)\n",
    "            agent.train_model()\n",
    "            state = next_state\n",
    "\n",
    "            # \n",
    "            score += reward\n",
    "            if show_media_info:\n",
    "                print(\"State Shape : \", np.shape(state))\n",
    "                print(\"Action Shape : \", np.shape(action))\n",
    "                print(\"Reward Shape : \", np.shape(reward))\n",
    "                print(\"done Shape : \", np.shape(done))\n",
    "                show_media_info = False\n",
    "            if done:\n",
    "                score_avg = 0.9 * score_avg + 0.1 * score if score_avg != 0 else score\n",
    "                print(\"episode: {0:3d} | score avg: {1:3.2f} | mem size {2:6d} |\"\n",
    "                    .format(e, score_avg, len(agent.memory)))\n",
    "\n",
    "                episodes.append(e)\n",
    "                scores_avg.append(score_avg)\n",
    "                scores_raw.append(score)\n",
    "\n",
    "                plt.plot(episodes, scores_avg, 'b')\n",
    "                plt.xlabel('episode')\n",
    "                plt.ylabel('average score')\n",
    "                plt.title('pendulum DDPG')\n",
    "                plt.grid()\n",
    "                plt.savefig(\"./result/pendulum_td3_TF.png\")\n",
    "\n",
    "                # 이동 평균이 0 이상일 때 종료\n",
    "                if score_avg > END_SCORE:\n",
    "                    agent.save_model()\n",
    "                    end = True\n",
    "                    break\n",
    "        if end == True:\n",
    "            env.close()\n",
    "            np.save('./save_model/data/pendulum_td3_TF_epi',  episodes)\n",
    "            np.save('./save_model/data/pendulum_td3_TF_scores_avg',scores_avg)\n",
    "            np.save('./save_model/data/pendulum_td3_TF_scores_raw',scores_raw)\n",
    "            print(\"End\")\n",
    "            break"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-08-02 13:46:16.259307: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-08-02 13:46:16.259939: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-08-02 13:46:16.303122: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:65:00.0 name: GeForce RTX 3080 computeCapability: 8.6\n",
      "coreClock: 1.74GHz coreCount: 68 deviceMemorySize: 9.75GiB deviceMemoryBandwidth: 707.88GiB/s\n",
      "2021-08-02 13:46:16.303157: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-08-02 13:46:16.305996: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-08-02 13:46:16.306065: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-08-02 13:46:16.306960: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-08-02 13:46:16.307207: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-08-02 13:46:16.307361: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory\n",
      "2021-08-02 13:46:16.308045: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-08-02 13:46:16.308181: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-08-02 13:46:16.308192: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-08-02 13:46:16.308602: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-08-02 13:46:16.309695: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-08-02 13:46:16.309719: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-08-02 13:46:16.309724: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"actor\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_28 (Dense)             multiple                  256       \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             multiple                  4160      \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             multiple                  65        \n",
      "=================================================================\n",
      "Total params: 4,481\n",
      "Trainable params: 4,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"critic\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                multiple                  64        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  544       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  64        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              multiple                  1056      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              multiple                  4160      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              multiple                  4160      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              multiple                  65        \n",
      "=================================================================\n",
      "Total params: 10,113\n",
      "Trainable params: 10,113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"critic_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              multiple                  64        \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              multiple                  544       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              multiple                  64        \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             multiple                  1056      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             multiple                  4160      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             multiple                  4160      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             multiple                  65        \n",
      "=================================================================\n",
      "Total params: 10,113\n",
      "Trainable params: 10,113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Env Name :  Pendulum-v0\n",
      "States 3, Actions 1\n",
      "Action space -2.00 ~ 2.00\n",
      "State Shape :  (3,)\n",
      "Action Shape :  (1,)\n",
      "Reward Shape :  ()\n",
      "done Shape :  ()\n",
      "episode:   0 | score avg: -1553.35 | mem size    200 |\n",
      "episode:   1 | score avg: -1513.05 | mem size    400 |\n",
      "episode:   2 | score avg: -1468.58 | mem size    600 |\n",
      "episode:   3 | score avg: -1449.37 | mem size    800 |\n",
      "episode:   4 | score avg: -1409.65 | mem size   1000 |\n",
      "episode:   5 | score avg: -1437.60 | mem size   1200 |\n",
      "episode:   6 | score avg: -1437.37 | mem size   1400 |\n",
      "episode:   7 | score avg: -1430.50 | mem size   1600 |\n",
      "episode:   8 | score avg: -1396.71 | mem size   1800 |\n",
      "Start to train, check batch shapes\n",
      "**** shape of states (64, 3) <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "**** shape of actions (64, 1) <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "**** shape of rewards (64, 1) <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "**** shape of next_states (64, 3) <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "**** shape of dones (64, 1) <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "episode:   9 | score avg: -1341.83 | mem size   2000 |\n",
      "episode:  10 | score avg: -1324.63 | mem size   2200 |\n",
      "episode:  11 | score avg: -1309.59 | mem size   2400 |\n",
      "episode:  12 | score avg: -1285.06 | mem size   2600 |\n",
      "episode:  13 | score avg: -1337.63 | mem size   2800 |\n",
      "episode:  14 | score avg: -1331.19 | mem size   3000 |\n",
      "episode:  15 | score avg: -1316.25 | mem size   3200 |\n",
      "episode:  16 | score avg: -1301.19 | mem size   3400 |\n",
      "episode:  17 | score avg: -1284.23 | mem size   3600 |\n",
      "episode:  18 | score avg: -1252.58 | mem size   3800 |\n",
      "episode:  19 | score avg: -1298.86 | mem size   4000 |\n",
      "episode:  20 | score avg: -1318.54 | mem size   4200 |\n",
      "episode:  21 | score avg: -1327.14 | mem size   4400 |\n",
      "episode:  22 | score avg: -1341.39 | mem size   4600 |\n",
      "episode:  23 | score avg: -1313.57 | mem size   4800 |\n",
      "episode:  24 | score avg: -1348.81 | mem size   5000 |\n",
      "episode:  25 | score avg: -1355.62 | mem size   5200 |\n",
      "episode:  26 | score avg: -1402.06 | mem size   5400 |\n",
      "episode:  27 | score avg: -1375.06 | mem size   5600 |\n",
      "episode:  28 | score avg: -1355.81 | mem size   5800 |\n",
      "episode:  29 | score avg: -1342.34 | mem size   6000 |\n",
      "episode:  30 | score avg: -1357.78 | mem size   6200 |\n",
      "episode:  31 | score avg: -1351.67 | mem size   6400 |\n",
      "episode:  32 | score avg: -1336.58 | mem size   6600 |\n",
      "episode:  33 | score avg: -1321.22 | mem size   6800 |\n",
      "episode:  34 | score avg: -1291.06 | mem size   7000 |\n",
      "episode:  35 | score avg: -1278.09 | mem size   7200 |\n",
      "episode:  36 | score avg: -1261.12 | mem size   7400 |\n",
      "episode:  37 | score avg: -1238.68 | mem size   7600 |\n",
      "episode:  38 | score avg: -1233.09 | mem size   7800 |\n",
      "episode:  39 | score avg: -1214.52 | mem size   8000 |\n",
      "episode:  40 | score avg: -1275.48 | mem size   8200 |\n",
      "episode:  41 | score avg: -1197.82 | mem size   8400 |\n",
      "episode:  42 | score avg: -1167.90 | mem size   8600 |\n",
      "episode:  43 | score avg: -1163.67 | mem size   8800 |\n",
      "episode:  44 | score avg: -1162.03 | mem size   9000 |\n",
      "episode:  45 | score avg: -1158.68 | mem size   9200 |\n",
      "episode:  46 | score avg: -1156.94 | mem size   9400 |\n",
      "episode:  47 | score avg: -1132.02 | mem size   9600 |\n",
      "episode:  48 | score avg: -1180.94 | mem size   9800 |\n",
      "episode:  49 | score avg: -1170.29 | mem size  10000 |\n",
      "episode:  50 | score avg: -1169.08 | mem size  10200 |\n",
      "episode:  51 | score avg: -1165.34 | mem size  10400 |\n",
      "episode:  52 | score avg: -1165.57 | mem size  10600 |\n",
      "episode:  53 | score avg: -1166.89 | mem size  10800 |\n",
      "episode:  54 | score avg: -1167.16 | mem size  11000 |\n",
      "episode:  55 | score avg: -1167.09 | mem size  11200 |\n",
      "episode:  56 | score avg: -1166.29 | mem size  11400 |\n",
      "episode:  57 | score avg: -1166.22 | mem size  11600 |\n",
      "episode:  58 | score avg: -1166.47 | mem size  11800 |\n",
      "episode:  59 | score avg: -1165.84 | mem size  12000 |\n",
      "episode:  60 | score avg: -1167.00 | mem size  12200 |\n",
      "episode:  61 | score avg: -1167.86 | mem size  12400 |\n",
      "episode:  62 | score avg: -1158.65 | mem size  12600 |\n",
      "episode:  63 | score avg: -1161.39 | mem size  12800 |\n",
      "episode:  64 | score avg: -1158.59 | mem size  13000 |\n",
      "episode:  65 | score avg: -1144.99 | mem size  13200 |\n",
      "episode:  66 | score avg: -1144.98 | mem size  13400 |\n",
      "episode:  67 | score avg: -1095.84 | mem size  13600 |\n",
      "episode:  68 | score avg: -1035.47 | mem size  13800 |\n",
      "episode:  69 | score avg: -1036.99 | mem size  14000 |\n",
      "episode:  70 | score avg: -945.80 | mem size  14200 |\n",
      "episode:  71 | score avg: -906.22 | mem size  14400 |\n",
      "episode:  72 | score avg: -877.59 | mem size  14600 |\n",
      "episode:  73 | score avg: -893.97 | mem size  14800 |\n",
      "episode:  74 | score avg: -909.12 | mem size  15000 |\n",
      "episode:  75 | score avg: -936.26 | mem size  15200 |\n",
      "episode:  76 | score avg: -880.18 | mem size  15400 |\n",
      "episode:  77 | score avg: -900.33 | mem size  15600 |\n",
      "episode:  78 | score avg: -927.60 | mem size  15800 |\n",
      "episode:  79 | score avg: -953.20 | mem size  16000 |\n",
      "episode:  80 | score avg: -964.43 | mem size  16200 |\n",
      "episode:  81 | score avg: -947.86 | mem size  16400 |\n",
      "episode:  82 | score avg: -865.20 | mem size  16600 |\n",
      "episode:  83 | score avg: -803.33 | mem size  16800 |\n",
      "episode:  84 | score avg: -783.84 | mem size  17000 |\n",
      "episode:  85 | score avg: -769.44 | mem size  17200 |\n",
      "episode:  86 | score avg: -693.44 | mem size  17400 |\n",
      "episode:  87 | score avg: -625.16 | mem size  17600 |\n",
      "episode:  88 | score avg: -679.34 | mem size  17800 |\n",
      "episode:  89 | score avg: -729.31 | mem size  18000 |\n",
      "episode:  90 | score avg: -794.54 | mem size  18200 |\n",
      "episode:  91 | score avg: -831.32 | mem size  18400 |\n",
      "episode:  92 | score avg: -798.06 | mem size  18600 |\n",
      "episode:  93 | score avg: -821.09 | mem size  18800 |\n",
      "episode:  94 | score avg: -786.73 | mem size  19000 |\n",
      "episode:  95 | score avg: -795.76 | mem size  19200 |\n",
      "episode:  96 | score avg: -741.19 | mem size  19400 |\n",
      "episode:  97 | score avg: -716.87 | mem size  19600 |\n",
      "episode:  98 | score avg: -749.16 | mem size  19800 |\n",
      "episode:  99 | score avg: -792.68 | mem size  20000 |\n",
      "episode: 100 | score avg: -726.19 | mem size  20200 |\n",
      "episode: 101 | score avg: -775.87 | mem size  20400 |\n",
      "episode: 102 | score avg: -815.42 | mem size  20600 |\n",
      "episode: 103 | score avg: -758.17 | mem size  20800 |\n",
      "episode: 104 | score avg: -795.03 | mem size  21000 |\n",
      "episode: 105 | score avg: -740.33 | mem size  21200 |\n",
      "episode: 106 | score avg: -678.67 | mem size  21400 |\n",
      "episode: 107 | score avg: -729.95 | mem size  21600 |\n",
      "episode: 108 | score avg: -718.51 | mem size  21800 |\n",
      "episode: 109 | score avg: -671.49 | mem size  22000 |\n",
      "episode: 110 | score avg: -721.48 | mem size  22200 |\n",
      "episode: 111 | score avg: -750.28 | mem size  22400 |\n",
      "episode: 112 | score avg: -700.05 | mem size  22600 |\n",
      "episode: 113 | score avg: -747.74 | mem size  22800 |\n",
      "episode: 114 | score avg: -791.55 | mem size  23000 |\n",
      "episode: 115 | score avg: -736.91 | mem size  23200 |\n",
      "episode: 116 | score avg: -780.49 | mem size  23400 |\n",
      "episode: 117 | score avg: -803.41 | mem size  23600 |\n",
      "episode: 118 | score avg: -799.65 | mem size  23800 |\n",
      "episode: 119 | score avg: -838.19 | mem size  24000 |\n",
      "episode: 120 | score avg: -870.29 | mem size  24200 |\n",
      "episode: 121 | score avg: -882.69 | mem size  24400 |\n",
      "episode: 122 | score avg: -906.98 | mem size  24600 |\n",
      "episode: 123 | score avg: -922.22 | mem size  24800 |\n",
      "episode: 124 | score avg: -943.35 | mem size  25000 |\n",
      "episode: 125 | score avg: -952.30 | mem size  25200 |\n",
      "episode: 126 | score avg: -959.50 | mem size  25400 |\n",
      "episode: 127 | score avg: -976.34 | mem size  25600 |\n",
      "episode: 128 | score avg: -975.49 | mem size  25800 |\n",
      "episode: 129 | score avg: -969.03 | mem size  26000 |\n",
      "episode: 130 | score avg: -951.86 | mem size  26200 |\n",
      "episode: 131 | score avg: -970.55 | mem size  26400 |\n",
      "episode: 132 | score avg: -885.98 | mem size  26600 |\n",
      "episode: 133 | score avg: -915.09 | mem size  26800 |\n",
      "episode: 134 | score avg: -936.64 | mem size  27000 |\n",
      "episode: 135 | score avg: -880.60 | mem size  27200 |\n",
      "episode: 136 | score avg: -895.97 | mem size  27400 |\n",
      "episode: 137 | score avg: -818.13 | mem size  27600 |\n",
      "episode: 138 | score avg: -772.53 | mem size  27800 |\n",
      "episode: 139 | score avg: -799.05 | mem size  28000 |\n",
      "episode: 140 | score avg: -768.29 | mem size  28200 |\n",
      "episode: 141 | score avg: -797.85 | mem size  28400 |\n",
      "episode: 142 | score avg: -832.79 | mem size  28600 |\n",
      "episode: 143 | score avg: -847.79 | mem size  28800 |\n",
      "episode: 144 | score avg: -873.70 | mem size  29000 |\n",
      "episode: 145 | score avg: -822.99 | mem size  29200 |\n",
      "episode: 146 | score avg: -863.41 | mem size  29400 |\n",
      "episode: 147 | score avg: -825.52 | mem size  29600 |\n",
      "episode: 148 | score avg: -768.44 | mem size  29800 |\n",
      "episode: 149 | score avg: -714.80 | mem size  30000 |\n",
      "episode: 150 | score avg: -759.56 | mem size  30200 |\n",
      "episode: 151 | score avg: -684.73 | mem size  30400 |\n",
      "episode: 152 | score avg: -651.59 | mem size  30600 |\n",
      "episode: 153 | score avg: -599.39 | mem size  30800 |\n",
      "episode: 154 | score avg: -551.90 | mem size  31000 |\n",
      "episode: 155 | score avg: -509.35 | mem size  31200 |\n",
      "episode: 156 | score avg: -576.45 | mem size  31400 |\n",
      "episode: 157 | score avg: -566.72 | mem size  31600 |\n",
      "episode: 158 | score avg: -628.03 | mem size  31800 |\n",
      "episode: 159 | score avg: -592.24 | mem size  32000 |\n",
      "episode: 160 | score avg: -560.63 | mem size  32200 |\n",
      "episode: 161 | score avg: -623.65 | mem size  32400 |\n",
      "episode: 162 | score avg: -573.59 | mem size  32600 |\n",
      "episode: 163 | score avg: -623.36 | mem size  32800 |\n",
      "episode: 164 | score avg: -573.84 | mem size  33000 |\n",
      "episode: 165 | score avg: -552.57 | mem size  33200 |\n",
      "episode: 166 | score avg: -546.19 | mem size  33400 |\n",
      "episode: 167 | score avg: -504.32 | mem size  33600 |\n",
      "episode: 168 | score avg: -558.66 | mem size  33800 |\n",
      "episode: 169 | score avg: -527.69 | mem size  34000 |\n",
      "episode: 170 | score avg: -487.61 | mem size  34200 |\n",
      "episode: 171 | score avg: -463.02 | mem size  34400 |\n",
      "episode: 172 | score avg: -474.75 | mem size  34600 |\n",
      "episode: 173 | score avg: -463.52 | mem size  34800 |\n",
      "episode: 174 | score avg: -418.53 | mem size  35000 |\n",
      "episode: 175 | score avg: -400.73 | mem size  35200 |\n",
      "episode: 176 | score avg: -372.88 | mem size  35400 |\n",
      "episode: 177 | score avg: -426.02 | mem size  35600 |\n",
      "episode: 178 | score avg: -443.66 | mem size  35800 |\n",
      "episode: 179 | score avg: -449.45 | mem size  36000 |\n",
      "episode: 180 | score avg: -440.48 | mem size  36200 |\n",
      "episode: 181 | score avg: -445.76 | mem size  36400 |\n",
      "episode: 182 | score avg: -426.76 | mem size  36600 |\n",
      "episode: 183 | score avg: -445.06 | mem size  36800 |\n",
      "episode: 184 | score avg: -425.95 | mem size  37000 |\n",
      "episode: 185 | score avg: -429.31 | mem size  37200 |\n",
      "episode: 186 | score avg: -422.90 | mem size  37400 |\n",
      "episode: 187 | score avg: -417.06 | mem size  37600 |\n",
      "episode: 188 | score avg: -398.53 | mem size  37800 |\n",
      "episode: 189 | score avg: -383.65 | mem size  38000 |\n",
      "episode: 190 | score avg: -358.90 | mem size  38200 |\n",
      "episode: 191 | score avg: -347.50 | mem size  38400 |\n",
      "episode: 192 | score avg: -325.23 | mem size  38600 |\n",
      "episode: 193 | score avg: -317.47 | mem size  38800 |\n",
      "episode: 194 | score avg: -309.34 | mem size  39000 |\n",
      "episode: 195 | score avg: -291.24 | mem size  39200 |\n",
      "episode: 196 | score avg: -274.22 | mem size  39400 |\n",
      "episode: 197 | score avg: -271.40 | mem size  39600 |\n",
      "episode: 198 | score avg: -269.49 | mem size  39800 |\n",
      "episode: 199 | score avg: -243.18 | mem size  40000 |\n",
      "episode: 200 | score avg: -242.88 | mem size  40200 |\n",
      "episode: 201 | score avg: -242.55 | mem size  40400 |\n",
      "episode: 202 | score avg: -218.78 | mem size  40600 |\n",
      "episode: 203 | score avg: -221.24 | mem size  40800 |\n",
      "episode: 204 | score avg: -223.06 | mem size  41000 |\n",
      "episode: 205 | score avg: -201.23 | mem size  41200 |\n",
      "episode: 206 | score avg: -235.02 | mem size  41400 |\n",
      "episode: 207 | score avg: -246.82 | mem size  41600 |\n",
      "episode: 208 | score avg: -290.83 | mem size  41800 |\n",
      "episode: 209 | score avg: -262.09 | mem size  42000 |\n",
      "episode: 210 | score avg: -259.53 | mem size  42200 |\n",
      "episode: 211 | score avg: -246.39 | mem size  42400 |\n",
      "episode: 212 | score avg: -245.54 | mem size  42600 |\n",
      "episode: 213 | score avg: -247.57 | mem size  42800 |\n",
      "episode: 214 | score avg: -246.70 | mem size  43000 |\n",
      "episode: 215 | score avg: -245.45 | mem size  43200 |\n",
      "episode: 216 | score avg: -257.36 | mem size  43400 |\n",
      "episode: 217 | score avg: -281.61 | mem size  43600 |\n",
      "episode: 218 | score avg: -276.27 | mem size  43800 |\n",
      "episode: 219 | score avg: -273.35 | mem size  44000 |\n",
      "episode: 220 | score avg: -269.34 | mem size  44200 |\n",
      "episode: 221 | score avg: -243.20 | mem size  44400 |\n",
      "episode: 222 | score avg: -242.70 | mem size  44600 |\n",
      "episode: 223 | score avg: -252.67 | mem size  44800 |\n",
      "episode: 224 | score avg: -250.64 | mem size  45000 |\n",
      "episode: 225 | score avg: -225.89 | mem size  45200 |\n",
      "episode: 226 | score avg: -215.04 | mem size  45400 |\n",
      "episode: 227 | score avg: -240.71 | mem size  45600 |\n",
      "episode: 228 | score avg: -250.91 | mem size  45800 |\n",
      "episode: 229 | score avg: -335.07 | mem size  46000 |\n",
      "episode: 230 | score avg: -363.13 | mem size  46200 |\n",
      "episode: 231 | score avg: -403.31 | mem size  46400 |\n",
      "episode: 232 | score avg: -433.92 | mem size  46600 |\n",
      "episode: 233 | score avg: -425.73 | mem size  46800 |\n",
      "episode: 234 | score avg: -395.75 | mem size  47000 |\n",
      "episode: 235 | score avg: -392.40 | mem size  47200 |\n",
      "episode: 236 | score avg: -353.57 | mem size  47400 |\n",
      "episode: 237 | score avg: -352.45 | mem size  47600 |\n",
      "episode: 238 | score avg: -364.74 | mem size  47800 |\n",
      "episode: 239 | score avg: -328.74 | mem size  48000 |\n",
      "episode: 240 | score avg: -319.95 | mem size  48200 |\n",
      "episode: 241 | score avg: -311.97 | mem size  48400 |\n",
      "episode: 242 | score avg: -292.69 | mem size  48600 |\n",
      "episode: 243 | score avg: -316.02 | mem size  48800 |\n",
      "episode: 244 | score avg: -284.48 | mem size  49000 |\n",
      "episode: 245 | score avg: -268.04 | mem size  49200 |\n",
      "episode: 246 | score avg: -265.76 | mem size  49400 |\n",
      "episode: 247 | score avg: -239.30 | mem size  49600 |\n",
      "episode: 248 | score avg: -215.43 | mem size  49800 |\n",
      "episode: 249 | score avg: -218.44 | mem size  50000 |\n",
      "episode: 250 | score avg: -221.13 | mem size  50000 |\n",
      "episode: 251 | score avg: -199.30 | mem size  50000 |\n",
      "End\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "env.close()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ]
}