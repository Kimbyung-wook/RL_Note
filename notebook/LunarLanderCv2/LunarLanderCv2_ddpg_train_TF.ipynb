{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('tf240': conda)"
  },
  "interpreter": {
   "hash": "61683dc6b2a2d3d4f2fca4fc9c31d7600238da1c31c9bb494e8f77b62993b62b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Find RL_Note path and append sys path\r\n",
    "import os, sys\r\n",
    "cwd = os.getcwd()\r\n",
    "pos = cwd.find('RL_Note')\r\n",
    "root_path = cwd[0:pos] + 'RL_Note'\r\n",
    "sys.path.append(root_path)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import gym\r\n",
    "import random\r\n",
    "import numpy as np\r\n",
    "import tensorflow as tf\r\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate, concatenate, Lambda\r\n",
    "from collections import deque\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from pys.utils.ou_noise import OUActionNoise\r\n",
    "from pys.utils.ER import ReplayMemory\r\n",
    "from pys.utils.PER import ProportionalPrioritizedMemory\r\n",
    "from pys.utils.HER import HindsightMemory"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-08-02 16:56:06.061322: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "class Actor(tf.keras.Model):\r\n",
    "    def __init__(self, state_size, action_size, action_min, action_max):\r\n",
    "        super(Actor, self).__init__()\r\n",
    "        self.action_min = action_min\r\n",
    "        self.action_max = action_max\r\n",
    "\r\n",
    "        self.fc1 = Dense(64, activation='relu')\r\n",
    "        self.fc2 = Dense(64, activation='relu')\r\n",
    "        # self.fc3 = Dense(16, activation='relu')\r\n",
    "        self.out= Dense(action_size, activation='tanh',kernel_initializer = tf.random_uniform_initializer(minval=-0.003, maxval=0.003)) # -1 ~ +1\r\n",
    "\r\n",
    "    def call(self, x):\r\n",
    "        x       = self.fc1(x)\r\n",
    "        x       = self.fc2(x)\r\n",
    "        # x       = self.fc3(x)\r\n",
    "        action  = self.out(x)\r\n",
    "        # return self.projected_to_action_space(action)\r\n",
    "        a = Lambda(lambda x: x*self.action_max)(action)\r\n",
    "        return a\r\n",
    "\r\n",
    "class Critic(tf.keras.Model):\r\n",
    "    def __init__(self, state_size, action_size):\r\n",
    "        super(Critic, self).__init__()\r\n",
    "        self.s1 = Dense(16, activation='relu')\r\n",
    "        self.s2 = Dense(32, activation='relu')\r\n",
    "        self.a1 = Dense(30, activation='relu')\r\n",
    "        self.a2 = Dense(32, activation='relu')\r\n",
    "        self.fc1= Dense(64, activation='relu')\r\n",
    "        self.fc2= Dense(64, activation='relu')\r\n",
    "        self.out= Dense(1,  activation='linear')\r\n",
    "\r\n",
    "    def call(self,state_action):\r\n",
    "        state  = state_action[0]\r\n",
    "        action = state_action[1]\r\n",
    "        s = self.s1(state)\r\n",
    "        s = self.s2(s)\r\n",
    "        a = self.a1(action)\r\n",
    "        a = self.a2(a)\r\n",
    "        c = concatenate([s,a],axis=-1)\r\n",
    "        x = self.fc1(c)\r\n",
    "        x = self.fc2(x)\r\n",
    "        q = self.out(x)\r\n",
    "        return q"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "class DDPGAgent:\r\n",
    "    def __init__(self, state_size, action_size, action_min, action_max, cfg:dict):\r\n",
    "        self.state_size = state_size\r\n",
    "        self.action_size= action_size\r\n",
    "        self.action_min = action_min\r\n",
    "        self.action_max = action_max\r\n",
    "        self.env_name   = cfg[\"ENV\"]\r\n",
    "        self.rl_type    = \"DDPG\"\r\n",
    "        self.er_type    = cfg[\"ER\"].upper()\r\n",
    "\r\n",
    "        # Hyper params for learning\r\n",
    "        self.discount_factor = 0.99\r\n",
    "        self.actor_learning_rate  = 0.0003\r\n",
    "        self.critic_learning_rate = 0.0005\r\n",
    "        self.tau = 0.005\r\n",
    "\r\n",
    "        # Experience Replay\r\n",
    "        self.batch_size = 64\r\n",
    "        self.train_start = 2000\r\n",
    "        self.buffer_size = 50000\r\n",
    "        if self.er_type == \"ER\":\r\n",
    "            self.memory = ReplayMemory(capacity=self.buffer_size)\r\n",
    "        elif self.er_type == \"PER\":\r\n",
    "            self.memory = ProportionalPrioritizedMemory(capacity=self.buffer_size)\r\n",
    "        elif self.er_type == \"HER\":\r\n",
    "            self.memory = HindsightMemory(\\\r\n",
    "                capacity            = self.buffer_size,\\\r\n",
    "                replay_n            = cfg[\"HER\"][\"REPLAY_N\"],\\\r\n",
    "                replay_strategy     = cfg[\"HER\"][\"STRATEGY\"],\\\r\n",
    "                reward_func         = cfg[\"HER\"][\"REWARD_FUNC\"],\\\r\n",
    "                done_func           = cfg[\"HER\"][\"DONE_FUNC\"])\r\n",
    "\r\n",
    "        self.critic         = Critic(self.state_size, self.action_size)\r\n",
    "        self.target_critic  = Critic(self.state_size, self.action_size)\r\n",
    "        self.actor          = Actor(self.state_size, self.action_size, self.action_min, self.action_max)\r\n",
    "        self.target_actor   = Actor(self.state_size, self.action_size, self.action_min, self.action_max)\r\n",
    "        self.critic_optimizer   = tf.keras.optimizers.Adam(lr=self.critic_learning_rate)\r\n",
    "        self.actor_optimizer    = tf.keras.optimizers.Adam(lr=self.actor_learning_rate)\r\n",
    "        self.actor.build(input_shape=(None, self.state_size))\r\n",
    "        self.target_actor.build(input_shape=(None, self.state_size))\r\n",
    "        state_in = Input((self.state_size,))\r\n",
    "        action_in = Input((self.action_size,))\r\n",
    "        self.actor(state_in)\r\n",
    "        self.target_actor(state_in)\r\n",
    "        self.critic([state_in, action_in])\r\n",
    "        self.target_critic([state_in, action_in])\r\n",
    "        self.actor.summary()\r\n",
    "        self.critic.summary()\r\n",
    "        \r\n",
    "        self.hard_update_target_model()\r\n",
    "\r\n",
    "        self.noise_std_dev = 0.2\r\n",
    "        self.ou_noise = OUActionNoise(mean=np.zeros(1), std_deviation=float(self.noise_std_dev) * np.ones(1))\r\n",
    "        self.show_media_info = False\r\n",
    "\r\n",
    "    def remember(self, state, action, reward, next_state, done, goal=None):\r\n",
    "        state       = np.array(state,       dtype=np.float32)\r\n",
    "        action      = np.array(action,      dtype=np.float32)\r\n",
    "        reward      = np.array([reward],    dtype=np.float32)\r\n",
    "        done        = np.array([done],      dtype=np.float32)\r\n",
    "        next_state  = np.array(next_state,  dtype=np.float32)\r\n",
    "        if self.er_type == \"HER\":\r\n",
    "            goal        = np.array(goal,        dtype=np.float32)\r\n",
    "            transition  = (state, action, reward, next_state, done, goal)\r\n",
    "        else:\r\n",
    "            transition  = (state, action, reward, next_state, done)\r\n",
    "        self.memory.append(transition)\r\n",
    "\r\n",
    "    def hard_update_target_model(self):\r\n",
    "        self.target_actor.set_weights(self.actor.get_weights())\r\n",
    "        self.target_critic.set_weights(self.critic.get_weights())\r\n",
    "\r\n",
    "    def soft_update_target_model(self):\r\n",
    "        tau = self.tau\r\n",
    "        for (net, target_net) in zip(   self.actor.trainable_variables,\r\n",
    "                                        self.target_actor.trainable_variables):\r\n",
    "            target_net.assign(tau * net + (1.0 - tau) * target_net)\r\n",
    "        for (net, target_net) in zip(   self.critic.trainable_variables,\r\n",
    "                                        self.target_critic.trainable_variables):\r\n",
    "            target_net.assign(tau * net + (1.0 - tau) * target_net)\r\n",
    "\r\n",
    "    def get_action(self,state):\r\n",
    "        state = tf.convert_to_tensor([state], dtype=tf.float32)\r\n",
    "        action = self.actor(state)\r\n",
    "        # Exploration and Exploitation\r\n",
    "        action_from_net = action.numpy()[0]\r\n",
    "        action_from_noise = self.ou_noise()\r\n",
    "        return np.clip(action_from_net+action_from_noise,self.action_min,self.action_max)\r\n",
    "\r\n",
    "    def train_model(self):\r\n",
    "        # Train from Experience Replay\r\n",
    "        # Training Condition - Memory Size\r\n",
    "        if len(self.memory) < self.train_start:\r\n",
    "            return 0.0,0.0\r\n",
    "        # Sampling from the memory\r\n",
    "        if self.er_type == \"ER\" or self.er_type == \"HER\":\r\n",
    "            mini_batch = self.memory.sample(self.batch_size)\r\n",
    "        elif self.er_type == \"PER\":\r\n",
    "            mini_batch, idxs, is_weights = self.memory.sample(self.batch_size)\r\n",
    "\r\n",
    "        states      = tf.convert_to_tensor(np.array([sample[0] for sample in mini_batch]))\r\n",
    "        actions     = tf.convert_to_tensor(np.array([sample[1] for sample in mini_batch]))\r\n",
    "        rewards     = tf.convert_to_tensor(np.array([sample[2] for sample in mini_batch]))\r\n",
    "        next_states = tf.convert_to_tensor(np.array([sample[3] for sample in mini_batch]))\r\n",
    "        dones       = tf.convert_to_tensor(np.array([sample[4] for sample in mini_batch]))\r\n",
    "        \r\n",
    "        if self.show_media_info == False:\r\n",
    "            self.show_media_info = True\r\n",
    "            print('Start to train, check batch shapes')\r\n",
    "            print('shape of mini_batch', np.shape(mini_batch),type(mini_batch))\r\n",
    "            print('shape of states', np.shape(states),type(states))\r\n",
    "            print('shape of actions', np.shape(actions),type(actions))\r\n",
    "            print('shape of rewards', np.shape(rewards),type(rewards))\r\n",
    "            print('shape of next_states', np.shape(next_states),type(next_states))\r\n",
    "            print('shape of dones', np.shape(dones),type(dones))\r\n",
    "            if self.er_type == \"HER\":\r\n",
    "                goals = tf.convert_to_tensor(np.array([sample[5] for sample in mini_batch]))\r\n",
    "                print('shape of goals', np.shape(goals),type(goals))\r\n",
    "\r\n",
    "        with tf.GradientTape() as tape:\r\n",
    "            target_actions = self.target_actor(next_states,training=True)\r\n",
    "            target_q = self.target_critic([next_states,target_actions],training=True)\r\n",
    "            target_value = rewards + (1 - dones) * self.discount_factor * target_q\r\n",
    "            q = self.critic([states, actions],training=True)\r\n",
    "            td_error = target_value - q\r\n",
    "            if self.er_type == \"ER\" or self.er_type == \"HER\":\r\n",
    "                critic_loss = tf.math.reduce_mean(tf.math.square(target_value - q))\r\n",
    "            elif self.er_type == \"PER\":\r\n",
    "                critic_loss = tf.math.reduce_mean(is_weights * tf.math.square(target_value - q))\r\n",
    "        critic_loss_out = critic_loss.numpy()\r\n",
    "        critic_params = self.critic.trainable_variables\r\n",
    "        critic_grads = tape.gradient(critic_loss, critic_params)\r\n",
    "        self.critic_optimizer.apply_gradients(zip(critic_grads, critic_params))\r\n",
    "\r\n",
    "        with tf.GradientTape() as tape:\r\n",
    "            new_actions = self.actor(states,training=True)\r\n",
    "            new_q = self.critic([states, new_actions],training=True)\r\n",
    "            actor_loss = -tf.reduce_mean(new_q)\r\n",
    "        actor_loss_out = actor_loss.numpy()\r\n",
    "        actor_params = self.actor.trainable_variables\r\n",
    "        actor_grads = tape.gradient(actor_loss, actor_params)\r\n",
    "        self.actor_optimizer.apply_gradients(zip(actor_grads, actor_params))\r\n",
    "        \r\n",
    "        if self.er_type == \"PER\":\r\n",
    "            sample_importance = td_error.numpy()\r\n",
    "            for i in range(self.batch_size):\r\n",
    "                self.memory.update(idxs[i], sample_importance[i])\r\n",
    "\r\n",
    "        self.soft_update_target_model()\r\n",
    "        return critic_loss_out, actor_loss_out\r\n",
    "\r\n",
    "    def load_model(self):\r\n",
    "        self.actor.load_weights( \"./save_model/\" + self.env_name + \"_\" + self.rl_type + \"_\" + self.er_type + \"_TF_actor\")\r\n",
    "        self.critic.load_weights(\"./save_model/\" + self.env_name + \"_\" + self.rl_type + \"_\" + self.er_type + \"_TF_critic\")\r\n",
    "        return\r\n",
    "\r\n",
    "    def save_model(self):\r\n",
    "        self.actor.save_weights( \"./save_model/\" + self.env_name + \"_\" + self.rl_type + \"_\" + self.er_type + \"_TF_actor\", save_format=\"tf\")\r\n",
    "        self.critic.save_weights(\"./save_model/\" + self.env_name + \"_\" + self.rl_type + \"_\" + self.er_type + \"_TF_critic\", save_format=\"tf\")\r\n",
    "        return"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def done_function(state):\r\n",
    "    return False\r\n",
    "\r\n",
    "def reward_function(state, action, next_state, done):\r\n",
    "    costh   = state[0]\r\n",
    "    sinth   = state[1]\r\n",
    "    th      = np.arctan2(sinth,costh)\r\n",
    "    thdot   = state[2]\r\n",
    "    u       = action[0]\r\n",
    "    costs   = th ** 2 + 0.1 * thdot + 0.001 * (u ** 2)\r\n",
    "    return -costs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "%matplotlib tk\r\n",
    "cfg = { \"ENV\":\"LunarLanderContinuous-v2\",\\\r\n",
    "        \"RL\":\"DDPG\",\\\r\n",
    "        \"ER\":\"ER\",\\\r\n",
    "        \"HER\":\\\r\n",
    "            {\r\n",
    "                \"REPLAY_N\":8,\\\r\n",
    "                \"STRATEGY\":\"FINAL\",\\\r\n",
    "                \"REWARD_FUNC\":reward_function,\\\r\n",
    "                \"DONE_FUNC\":done_function,\\\r\n",
    "            }\r\n",
    "        }\r\n",
    "EPISODES = 10000\r\n",
    "END_SCORE = 200\r\n",
    "figure = plt.gcf()\r\n",
    "figure.set_size_inches(8,6)\r\n",
    "\r\n",
    "if __name__ == \"__main__\":\r\n",
    "    env = gym.make(cfg[\"ENV\"])\r\n",
    "    state_size  = env.observation_space.shape[0]\r\n",
    "    action_size = env.action_space.shape[0]\r\n",
    "    action_min  = env.action_space.low[0]\r\n",
    "    action_max  = env.action_space.high[0]\r\n",
    "\r\n",
    "    agent = DDPGAgent(state_size, action_size, action_min, action_max, cfg)\r\n",
    "    print('Env Name : ',cfg[\"ENV\"])\r\n",
    "    print('States {0}, Actions {1}'.format(state_size, action_size))\r\n",
    "    print('Action space {0:.2f} ~ {1:.2f}'.format(action_min, action_max))\r\n",
    "    scores_avg, scores_raw, episodes, losses = [], [], [], []\r\n",
    "    critic_mean, actor_mean = [], []\r\n",
    "    score_avg = 0\r\n",
    "\r\n",
    "    end = False\r\n",
    "    show_media_info = True\r\n",
    "    goal = np.array([1.0,0.0,0.0])\r\n",
    "    \r\n",
    "    for e in range(EPISODES):\r\n",
    "        done = False\r\n",
    "        score = 0\r\n",
    "        state = env.reset()\r\n",
    "        critic_losses = []\r\n",
    "        actor_losses = []\r\n",
    "        while not done:\r\n",
    "            # env.render()\r\n",
    "\r\n",
    "            # Interact with env.\r\n",
    "            action = agent.get_action(state)\r\n",
    "            next_state, reward, done, info = env.step(action)\r\n",
    "            agent.remember(state, action, reward, next_state, done, goal)\r\n",
    "            critic_loss, actor_loss = agent.train_model()\r\n",
    "            state = next_state\r\n",
    "\r\n",
    "            score += reward\r\n",
    "            critic_losses.append(critic_loss)\r\n",
    "            actor_losses.append(actor_loss)\r\n",
    "            if show_media_info:\r\n",
    "                print(\"State Shape : \", np.shape(state),    type(state),    state)\r\n",
    "                print(\"Action Shape : \",np.shape(action),   type(action),   action)\r\n",
    "                print(\"Reward Shape : \",np.shape(reward),   type(reward),   reward)\r\n",
    "                print(\"Done Shape : \",  np.shape(done),     type(done),     done)\r\n",
    "                print(\"Goal Shape : \",  np.shape(goal),     type(goal),     goal)\r\n",
    "                show_media_info = False\r\n",
    "            if done:\r\n",
    "                score_avg = 0.9 * score_avg + 0.1 * score if score_avg != 0 else score\r\n",
    "                print(\"episode: {0:3d} | score avg: {1:3.2f} | mem size {2:6d} |\"\r\n",
    "                    .format(e, score_avg, len(agent.memory)))\r\n",
    "\r\n",
    "                episodes.append(e)\r\n",
    "                scores_avg.append(score_avg)\r\n",
    "                scores_raw.append(score)\r\n",
    "                critic_mean.append(np.mean(critic_losses))\r\n",
    "                actor_mean.append(np.mean(actor_losses))\r\n",
    "                # View data\r\n",
    "                plt.clf()\r\n",
    "                plt.subplot(311)\r\n",
    "                plt.plot(episodes, scores_avg, 'b')\r\n",
    "                plt.plot(episodes, scores_raw, 'b', alpha=0.8, linewidth=0.5)\r\n",
    "                plt.xlabel('episode'); plt.ylabel('average score'); plt.grid()\r\n",
    "                plt.title(cfg[\"ENV\"] +'_' + cfg[\"RL\"] +'_' + cfg[\"ER\"])\r\n",
    "                plt.subplot(312)\r\n",
    "                plt.plot(episodes, critic_mean, 'b.',markersize=3)\r\n",
    "                plt.xlabel('episode'); plt.ylabel('critic loss'); plt.grid()\r\n",
    "                plt.subplot(313)\r\n",
    "                plt.plot(episodes, actor_mean, 'b.',markersize=3)\r\n",
    "                plt.xlabel('episode'); plt.ylabel('actor loss'); plt.grid()\r\n",
    "                plt.savefig(\"./result/\" + cfg[\"ENV\"] +'_' + cfg[\"RL\"] +'_' + cfg[\"ER\"] + \"_TF.jpg\")\r\n",
    "\r\n",
    "                # 이동 평균이 0 이상일 때 종료\r\n",
    "                if score_avg > END_SCORE:\r\n",
    "                    agent.save_model()\r\n",
    "                    end = True\r\n",
    "                    break\r\n",
    "        if end == True:\r\n",
    "            env.close()\r\n",
    "            np.save(\"./save_model/data/\" + cfg[\"ENV\"] + '_' + cfg[\"RL\"] + '_' + cfg[\"ER\"] + \"_TF_epi\",  episodes)\r\n",
    "            np.save(\"./save_model/data/\" + cfg[\"ENV\"] + '_' + cfg[\"RL\"] + '_' + cfg[\"ER\"] + \"_TF_scores_avg\",scores_avg)\r\n",
    "            np.save(\"./save_model/data/\" + cfg[\"ENV\"] + '_' + cfg[\"RL\"] + '_' + cfg[\"ER\"] + \"_TF_scores_raw\",scores_raw)\r\n",
    "            np.save(\"./save_model/data/\" + cfg[\"ENV\"] + '_' + cfg[\"RL\"] + '_' + cfg[\"ER\"] + \"_TF_critic_mean\",critic_mean)\r\n",
    "            np.save(\"./save_model/data/\" + cfg[\"ENV\"] + '_' + cfg[\"RL\"] + '_' + cfg[\"ER\"] + \"_TF_actor_mean\",actor_mean)\r\n",
    "            print(\"End\")\r\n",
    "            break"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-08-02 16:56:07.279056: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-08-02 16:56:07.279583: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-08-02 16:56:07.302580: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:65:00.0 name: GeForce RTX 3080 computeCapability: 8.6\n",
      "coreClock: 1.74GHz coreCount: 68 deviceMemorySize: 9.75GiB deviceMemoryBandwidth: 707.88GiB/s\n",
      "2021-08-02 16:56:07.302607: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-08-02 16:56:07.305569: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-08-02 16:56:07.305625: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-08-02 16:56:07.306580: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-08-02 16:56:07.306826: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-08-02 16:56:07.306988: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory\n",
      "2021-08-02 16:56:07.307726: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-08-02 16:56:07.307858: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-08-02 16:56:07.307869: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-08-02 16:56:07.308278: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-08-02 16:56:07.309426: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-08-02 16:56:07.309459: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-08-02 16:56:07.309462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"actor\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_14 (Dense)             multiple                  576       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             multiple                  4160      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             multiple                  130       \n",
      "=================================================================\n",
      "Total params: 4,866\n",
      "Trainable params: 4,866\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"critic\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                multiple                  144       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  544       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  90        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              multiple                  992       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              multiple                  4160      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              multiple                  4160      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              multiple                  65        \n",
      "=================================================================\n",
      "Total params: 10,155\n",
      "Trainable params: 10,155\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Env Name :  LunarLanderContinuous-v2\n",
      "States 8, Actions 2\n",
      "Action0 space -1.00 ~ 1.00\n",
      "Action1 space -1.00 ~ 1.00\n",
      "State Shape :  (8,)\n",
      "Action Shape :  (2,)\n",
      "Reward Shape :  ()\n",
      "done Shape :  ()\n",
      "episode:   0 | score avg: -364.57 | mem size    172 |\n",
      "episode:   1 | score avg: -374.59 | mem size    258 |\n",
      "episode:   2 | score avg: -365.59 | mem size    367 |\n",
      "episode:   3 | score avg: -366.97 | mem size    461 |\n",
      "episode:   4 | score avg: -410.87 | mem size    595 |\n",
      "episode:   5 | score avg: -413.99 | mem size    696 |\n",
      "episode:   6 | score avg: -392.93 | mem size    820 |\n",
      "episode:   7 | score avg: -384.87 | mem size    907 |\n",
      "episode:   8 | score avg: -378.76 | mem size   1074 |\n",
      "episode:   9 | score avg: -344.19 | mem size   1164 |\n",
      "episode:  10 | score avg: -357.11 | mem size   1316 |\n",
      "episode:  11 | score avg: -364.42 | mem size   1397 |\n",
      "episode:  12 | score avg: -389.22 | mem size   1487 |\n",
      "episode:  13 | score avg: -412.85 | mem size   1602 |\n",
      "episode:  14 | score avg: -447.10 | mem size   1673 |\n",
      "episode:  15 | score avg: -473.78 | mem size   1777 |\n",
      "episode:  16 | score avg: -475.90 | mem size   1917 |\n",
      "Start to train, check batch shapes\n",
      "shape of states (64, 8) <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "shape of actions (64, 2) <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "shape of rewards (64, 1) <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "shape of next_states (64, 8) <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "shape of dones (64, 1) <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "episode:  17 | score avg: -536.42 | mem size   2042 |\n",
      "episode:  18 | score avg: -525.33 | mem size   2123 |\n",
      "episode:  19 | score avg: -572.87 | mem size   2230 |\n",
      "episode:  20 | score avg: -584.82 | mem size   2296 |\n",
      "episode:  21 | score avg: -574.25 | mem size   2398 |\n",
      "episode:  22 | score avg: -598.30 | mem size   2463 |\n",
      "episode:  23 | score avg: -621.81 | mem size   2535 |\n",
      "episode:  24 | score avg: -696.71 | mem size   2639 |\n",
      "episode:  25 | score avg: -709.48 | mem size   2729 |\n",
      "episode:  26 | score avg: -791.57 | mem size   2879 |\n",
      "episode:  27 | score avg: -781.44 | mem size   3066 |\n",
      "episode:  28 | score avg: -798.96 | mem size   3157 |\n",
      "episode:  29 | score avg: -823.10 | mem size   3254 |\n",
      "episode:  30 | score avg: -778.56 | mem size   3337 |\n",
      "episode:  31 | score avg: -738.18 | mem size   3438 |\n",
      "episode:  32 | score avg: -721.47 | mem size   3520 |\n",
      "episode:  33 | score avg: -717.17 | mem size   3616 |\n",
      "episode:  34 | score avg: -721.15 | mem size   3741 |\n",
      "episode:  35 | score avg: -712.01 | mem size   3803 |\n",
      "episode:  36 | score avg: -703.26 | mem size   3859 |\n",
      "episode:  37 | score avg: -706.50 | mem size   3939 |\n",
      "episode:  38 | score avg: -730.30 | mem size   4037 |\n",
      "episode:  39 | score avg: -718.04 | mem size   4162 |\n",
      "episode:  40 | score avg: -671.28 | mem size   4270 |\n",
      "episode:  41 | score avg: -652.36 | mem size   4458 |\n",
      "episode:  42 | score avg: -659.76 | mem size   4532 |\n",
      "episode:  43 | score avg: -646.20 | mem size   4690 |\n",
      "episode:  44 | score avg: -655.74 | mem size   4820 |\n",
      "episode:  45 | score avg: -641.19 | mem size   4902 |\n",
      "episode:  46 | score avg: -630.83 | mem size   5111 |\n",
      "episode:  47 | score avg: -602.02 | mem size   5224 |\n",
      "episode:  48 | score avg: -599.76 | mem size   5303 |\n",
      "episode:  49 | score avg: -589.70 | mem size   5368 |\n",
      "episode:  50 | score avg: -562.74 | mem size   5495 |\n",
      "episode:  51 | score avg: -535.42 | mem size   5580 |\n",
      "episode:  52 | score avg: -526.55 | mem size   5655 |\n",
      "episode:  53 | score avg: -546.90 | mem size   6141 |\n",
      "episode:  54 | score avg: -549.28 | mem size   6234 |\n",
      "episode:  55 | score avg: -534.84 | mem size   6359 |\n",
      "episode:  56 | score avg: -518.98 | mem size   6448 |\n",
      "episode:  57 | score avg: -496.41 | mem size   6534 |\n",
      "episode:  58 | score avg: -480.71 | mem size   6608 |\n",
      "episode:  59 | score avg: -455.57 | mem size   6687 |\n",
      "episode:  60 | score avg: -416.85 | mem size   6747 |\n",
      "episode:  61 | score avg: -394.07 | mem size   6821 |\n",
      "episode:  62 | score avg: -366.57 | mem size   6876 |\n",
      "episode:  63 | score avg: -336.74 | mem size   6972 |\n",
      "episode:  64 | score avg: -310.85 | mem size   7057 |\n",
      "episode:  65 | score avg: -300.55 | mem size   7173 |\n",
      "episode:  66 | score avg: -305.43 | mem size   7270 |\n",
      "episode:  67 | score avg: -317.86 | mem size   7436 |\n",
      "episode:  68 | score avg: -333.75 | mem size   7554 |\n",
      "episode:  69 | score avg: -376.02 | mem size   7688 |\n",
      "episode:  70 | score avg: -423.20 | mem size   7788 |\n",
      "episode:  71 | score avg: -460.20 | mem size   7909 |\n",
      "episode:  72 | score avg: -467.32 | mem size   7992 |\n",
      "episode:  73 | score avg: -438.03 | mem size   8059 |\n",
      "episode:  74 | score avg: -408.23 | mem size   8129 |\n",
      "episode:  75 | score avg: -377.60 | mem size   8181 |\n",
      "episode:  76 | score avg: -362.43 | mem size   8267 |\n",
      "episode:  77 | score avg: -343.10 | mem size   8399 |\n",
      "episode:  78 | score avg: -319.03 | mem size   8524 |\n",
      "episode:  79 | score avg: -325.15 | mem size   8622 |\n",
      "episode:  80 | score avg: -305.14 | mem size   8686 |\n",
      "episode:  81 | score avg: -288.74 | mem size   8766 |\n",
      "episode:  82 | score avg: -273.73 | mem size   8838 |\n",
      "episode:  83 | score avg: -259.49 | mem size   8917 |\n",
      "episode:  84 | score avg: -238.85 | mem size   9014 |\n",
      "episode:  85 | score avg: -232.44 | mem size   9094 |\n",
      "episode:  86 | score avg: -215.61 | mem size   9244 |\n",
      "episode:  87 | score avg: -206.05 | mem size   9304 |\n",
      "episode:  88 | score avg: -197.07 | mem size   9416 |\n",
      "episode:  89 | score avg: -190.55 | mem size   9524 |\n",
      "episode:  90 | score avg: -184.67 | mem size   9618 |\n",
      "episode:  91 | score avg: -168.28 | mem size   9774 |\n",
      "episode:  92 | score avg: -153.05 | mem size   9874 |\n",
      "episode:  93 | score avg: -154.19 | mem size  10010 |\n",
      "episode:  94 | score avg: -150.08 | mem size  10101 |\n",
      "episode:  95 | score avg: -151.79 | mem size  10207 |\n",
      "episode:  96 | score avg: -150.30 | mem size  10358 |\n",
      "episode:  97 | score avg: -159.81 | mem size  10446 |\n",
      "episode:  98 | score avg: -179.82 | mem size  10511 |\n",
      "episode:  99 | score avg: -187.06 | mem size  10636 |\n",
      "episode: 100 | score avg: -182.28 | mem size  10737 |\n",
      "episode: 101 | score avg: -184.65 | mem size  10828 |\n",
      "episode: 102 | score avg: -193.77 | mem size  10958 |\n",
      "episode: 103 | score avg: -206.53 | mem size  11035 |\n",
      "episode: 104 | score avg: -208.92 | mem size  11174 |\n",
      "episode: 105 | score avg: -201.75 | mem size  11229 |\n",
      "episode: 106 | score avg: -197.18 | mem size  11295 |\n",
      "episode: 107 | score avg: -201.96 | mem size  11388 |\n",
      "episode: 108 | score avg: -201.39 | mem size  11468 |\n",
      "episode: 109 | score avg: -190.42 | mem size  11544 |\n",
      "episode: 110 | score avg: -187.53 | mem size  11612 |\n",
      "episode: 111 | score avg: -186.15 | mem size  11712 |\n",
      "episode: 112 | score avg: -186.90 | mem size  11824 |\n",
      "episode: 113 | score avg: -193.65 | mem size  11918 |\n",
      "episode: 114 | score avg: -187.44 | mem size  12074 |\n",
      "episode: 115 | score avg: -201.69 | mem size  12242 |\n",
      "episode: 116 | score avg: -269.57 | mem size  12350 |\n",
      "episode: 117 | score avg: -375.47 | mem size  12462 |\n",
      "episode: 118 | score avg: -412.77 | mem size  12531 |\n",
      "episode: 119 | score avg: -462.66 | mem size  12648 |\n",
      "episode: 120 | score avg: -496.34 | mem size  12729 |\n",
      "episode: 121 | score avg: -486.44 | mem size  12835 |\n",
      "episode: 122 | score avg: -469.13 | mem size  12916 |\n",
      "episode: 123 | score avg: -439.45 | mem size  12997 |\n",
      "episode: 124 | score avg: -412.89 | mem size  13077 |\n",
      "episode: 125 | score avg: -387.78 | mem size  13137 |\n",
      "episode: 126 | score avg: -346.16 | mem size  13223 |\n",
      "episode: 127 | score avg: -332.15 | mem size  13341 |\n",
      "episode: 128 | score avg: -326.80 | mem size  13436 |\n",
      "episode: 129 | score avg: -310.21 | mem size  13581 |\n",
      "episode: 130 | score avg: -313.92 | mem size  13673 |\n",
      "episode: 131 | score avg: -307.20 | mem size  13738 |\n",
      "episode: 132 | score avg: -303.66 | mem size  13810 |\n",
      "episode: 133 | score avg: -304.67 | mem size  13896 |\n",
      "episode: 134 | score avg: -299.72 | mem size  13977 |\n",
      "episode: 135 | score avg: -290.98 | mem size  14095 |\n",
      "episode: 136 | score avg: -274.92 | mem size  14197 |\n",
      "episode: 137 | score avg: -269.74 | mem size  14300 |\n",
      "episode: 138 | score avg: -259.75 | mem size  14367 |\n",
      "episode: 139 | score avg: -248.63 | mem size  14438 |\n",
      "episode: 140 | score avg: -234.08 | mem size  14574 |\n",
      "episode: 141 | score avg: -222.06 | mem size  14721 |\n",
      "episode: 142 | score avg: -215.50 | mem size  14908 |\n",
      "episode: 143 | score avg: -213.57 | mem size  15251 |\n",
      "episode: 144 | score avg: -208.91 | mem size  15405 |\n",
      "episode: 145 | score avg: -211.83 | mem size  15482 |\n",
      "episode: 146 | score avg: -211.97 | mem size  15624 |\n",
      "episode: 147 | score avg: -211.83 | mem size  15771 |\n",
      "episode: 148 | score avg: -209.70 | mem size  15873 |\n",
      "episode: 149 | score avg: -212.94 | mem size  16023 |\n",
      "episode: 150 | score avg: -219.45 | mem size  16123 |\n",
      "episode: 151 | score avg: -228.00 | mem size  16275 |\n",
      "episode: 152 | score avg: -235.36 | mem size  16456 |\n",
      "episode: 153 | score avg: -238.34 | mem size  16703 |\n",
      "episode: 154 | score avg: -244.37 | mem size  16877 |\n",
      "episode: 155 | score avg: -244.48 | mem size  17018 |\n",
      "episode: 156 | score avg: -247.64 | mem size  17173 |\n",
      "episode: 157 | score avg: -244.12 | mem size  17289 |\n",
      "episode: 158 | score avg: -246.84 | mem size  17409 |\n",
      "episode: 159 | score avg: -245.10 | mem size  17673 |\n",
      "episode: 160 | score avg: -251.78 | mem size  17816 |\n",
      "episode: 161 | score avg: -250.31 | mem size  17927 |\n",
      "episode: 162 | score avg: -246.17 | mem size  18511 |\n",
      "episode: 163 | score avg: -237.63 | mem size  18598 |\n",
      "episode: 164 | score avg: -220.35 | mem size  18784 |\n",
      "episode: 165 | score avg: -207.17 | mem size  18886 |\n",
      "episode: 166 | score avg: -206.15 | mem size  19248 |\n",
      "episode: 167 | score avg: -192.12 | mem size  19523 |\n",
      "episode: 168 | score avg: -182.94 | mem size  19737 |\n",
      "episode: 169 | score avg: -174.87 | mem size  19916 |\n",
      "episode: 170 | score avg: -165.95 | mem size  20149 |\n",
      "episode: 171 | score avg: -157.31 | mem size  20265 |\n",
      "episode: 172 | score avg: -151.19 | mem size  20397 |\n",
      "episode: 173 | score avg: -150.64 | mem size  20479 |\n",
      "episode: 174 | score avg: -140.37 | mem size  20647 |\n",
      "episode: 175 | score avg: -132.63 | mem size  21059 |\n",
      "episode: 176 | score avg: -126.15 | mem size  21580 |\n",
      "episode: 177 | score avg: -127.89 | mem size  22580 |\n",
      "episode: 178 | score avg: -133.37 | mem size  23217 |\n",
      "episode: 179 | score avg: -128.29 | mem size  23287 |\n",
      "episode: 180 | score avg: -119.30 | mem size  23405 |\n",
      "episode: 181 | score avg: -122.07 | mem size  23469 |\n",
      "episode: 182 | score avg: -120.56 | mem size  23529 |\n",
      "episode: 183 | score avg: -118.26 | mem size  23585 |\n",
      "episode: 184 | score avg: -121.19 | mem size  23654 |\n",
      "episode: 185 | score avg: -119.45 | mem size  23775 |\n",
      "episode: 186 | score avg: -121.09 | mem size  23871 |\n",
      "episode: 187 | score avg: -130.56 | mem size  23966 |\n",
      "episode: 188 | score avg: -127.85 | mem size  24021 |\n",
      "episode: 189 | score avg: -130.42 | mem size  24104 |\n",
      "episode: 190 | score avg: -132.24 | mem size  24195 |\n",
      "episode: 191 | score avg: -132.32 | mem size  24270 |\n",
      "episode: 192 | score avg: -133.06 | mem size  24330 |\n",
      "episode: 193 | score avg: -132.78 | mem size  24394 |\n",
      "episode: 194 | score avg: -137.19 | mem size  24471 |\n",
      "episode: 195 | score avg: -141.88 | mem size  24549 |\n",
      "episode: 196 | score avg: -143.68 | mem size  24627 |\n",
      "episode: 197 | score avg: -142.85 | mem size  24683 |\n",
      "episode: 198 | score avg: -156.94 | mem size  24797 |\n",
      "episode: 199 | score avg: -158.78 | mem size  24874 |\n",
      "episode: 200 | score avg: -160.49 | mem size  24955 |\n",
      "episode: 201 | score avg: -165.48 | mem size  25041 |\n",
      "episode: 202 | score avg: -182.50 | mem size  25181 |\n",
      "episode: 203 | score avg: -176.87 | mem size  25241 |\n",
      "episode: 204 | score avg: -164.77 | mem size  25404 |\n",
      "episode: 205 | score avg: -156.88 | mem size  25625 |\n",
      "episode: 206 | score avg: -148.01 | mem size  25710 |\n",
      "episode: 207 | score avg: -173.89 | mem size  26117 |\n",
      "episode: 208 | score avg: -201.96 | mem size  26330 |\n",
      "episode: 209 | score avg: -185.80 | mem size  26586 |\n",
      "episode: 210 | score avg: -175.54 | mem size  26875 |\n",
      "episode: 211 | score avg: -167.48 | mem size  27286 |\n",
      "episode: 212 | score avg: -160.62 | mem size  27356 |\n",
      "episode: 213 | score avg: -149.10 | mem size  27468 |\n",
      "episode: 214 | score avg: -164.47 | mem size  27665 |\n",
      "episode: 215 | score avg: -163.34 | mem size  27971 |\n",
      "episode: 216 | score avg: -168.20 | mem size  28318 |\n",
      "episode: 217 | score avg: -168.98 | mem size  28669 |\n",
      "episode: 218 | score avg: -169.97 | mem size  29014 |\n",
      "episode: 219 | score avg: -162.48 | mem size  29117 |\n",
      "episode: 220 | score avg: -154.10 | mem size  29332 |\n",
      "episode: 221 | score avg: -159.06 | mem size  29567 |\n",
      "episode: 222 | score avg: -158.15 | mem size  29851 |\n",
      "episode: 223 | score avg: -154.77 | mem size  30851 |\n",
      "episode: 224 | score avg: -160.64 | mem size  31201 |\n",
      "episode: 225 | score avg: -158.97 | mem size  31516 |\n",
      "episode: 226 | score avg: -159.31 | mem size  31781 |\n",
      "episode: 227 | score avg: -185.66 | mem size  32294 |\n",
      "episode: 228 | score avg: -184.34 | mem size  32440 |\n",
      "episode: 229 | score avg: -193.33 | mem size  32588 |\n",
      "episode: 230 | score avg: -187.11 | mem size  32665 |\n",
      "episode: 231 | score avg: -212.64 | mem size  32848 |\n",
      "episode: 232 | score avg: -228.13 | mem size  33380 |\n",
      "episode: 233 | score avg: -243.74 | mem size  33691 |\n",
      "episode: 234 | score avg: -244.85 | mem size  33911 |\n",
      "episode: 235 | score avg: -248.97 | mem size  33993 |\n",
      "episode: 236 | score avg: -250.04 | mem size  34255 |\n",
      "episode: 237 | score avg: -241.91 | mem size  34496 |\n",
      "episode: 238 | score avg: -241.91 | mem size  35236 |\n",
      "episode: 239 | score avg: -227.27 | mem size  35569 |\n",
      "episode: 240 | score avg: -258.17 | mem size  36149 |\n",
      "episode: 241 | score avg: -254.62 | mem size  36291 |\n",
      "episode: 242 | score avg: -234.60 | mem size  36504 |\n",
      "episode: 243 | score avg: -217.69 | mem size  36984 |\n",
      "episode: 244 | score avg: -196.59 | mem size  37131 |\n",
      "episode: 245 | score avg: -193.88 | mem size  37292 |\n",
      "episode: 246 | score avg: -184.69 | mem size  37556 |\n",
      "episode: 247 | score avg: -176.33 | mem size  38556 |\n",
      "episode: 248 | score avg: -163.62 | mem size  38796 |\n",
      "episode: 249 | score avg: -148.81 | mem size  39041 |\n",
      "episode: 250 | score avg: -112.72 | mem size  39412 |\n",
      "episode: 251 | score avg: -107.23 | mem size  39558 |\n",
      "episode: 252 | score avg: -106.51 | mem size  39643 |\n",
      "episode: 253 | score avg: -115.60 | mem size  39976 |\n",
      "episode: 254 | score avg: -123.25 | mem size  40380 |\n",
      "episode: 255 | score avg: -123.02 | mem size  40580 |\n",
      "episode: 256 | score avg: -141.10 | mem size  40665 |\n",
      "episode: 257 | score avg: -135.99 | mem size  40876 |\n",
      "episode: 258 | score avg: -112.63 | mem size  41489 |\n",
      "episode: 259 | score avg: -241.54 | mem size  42437 |\n",
      "episode: 260 | score avg: -334.34 | mem size  43004 |\n",
      "episode: 261 | score avg: -330.82 | mem size  43219 |\n",
      "episode: 262 | score avg: -405.75 | mem size  44126 |\n",
      "episode: 263 | score avg: -390.15 | mem size  44381 |\n",
      "episode: 264 | score avg: -359.44 | mem size  45381 |\n",
      "episode: 265 | score avg: -304.22 | mem size  45842 |\n",
      "episode: 266 | score avg: -288.83 | mem size  46088 |\n",
      "episode: 267 | score avg: -287.75 | mem size  46772 |\n",
      "episode: 268 | score avg: -279.24 | mem size  46965 |\n",
      "episode: 269 | score avg: -284.60 | mem size  47088 |\n",
      "episode: 270 | score avg: -237.70 | mem size  47813 |\n",
      "episode: 271 | score avg: -193.06 | mem size  48338 |\n",
      "episode: 272 | score avg: -153.93 | mem size  48643 |\n",
      "episode: 273 | score avg: -122.49 | mem size  49250 |\n",
      "episode: 274 | score avg: -116.68 | mem size  49494 |\n",
      "episode: 275 | score avg: -123.84 | mem size  49974 |\n",
      "episode: 276 | score avg: -116.66 | mem size  50000 |\n",
      "episode: 277 | score avg: -111.52 | mem size  50000 |\n",
      "episode: 278 | score avg: -108.00 | mem size  50000 |\n",
      "episode: 279 | score avg: -109.90 | mem size  50000 |\n",
      "episode: 280 | score avg: -111.33 | mem size  50000 |\n",
      "episode: 281 | score avg: -109.80 | mem size  50000 |\n",
      "episode: 282 | score avg: -108.74 | mem size  50000 |\n",
      "episode: 283 | score avg: -84.71 | mem size  50000 |\n",
      "episode: 284 | score avg: -56.08 | mem size  50000 |\n",
      "episode: 285 | score avg: -52.18 | mem size  50000 |\n",
      "episode: 286 | score avg: -55.25 | mem size  50000 |\n",
      "episode: 287 | score avg: -66.32 | mem size  50000 |\n",
      "episode: 288 | score avg: -70.54 | mem size  50000 |\n",
      "episode: 289 | score avg: -74.46 | mem size  50000 |\n",
      "episode: 290 | score avg: -81.61 | mem size  50000 |\n",
      "episode: 291 | score avg: -86.42 | mem size  50000 |\n",
      "episode: 292 | score avg: -110.88 | mem size  50000 |\n",
      "episode: 293 | score avg: -180.98 | mem size  50000 |\n",
      "episode: 294 | score avg: -179.85 | mem size  50000 |\n",
      "episode: 295 | score avg: -185.47 | mem size  50000 |\n",
      "episode: 296 | score avg: -186.72 | mem size  50000 |\n",
      "episode: 297 | score avg: -190.83 | mem size  50000 |\n",
      "episode: 298 | score avg: -198.54 | mem size  50000 |\n",
      "episode: 299 | score avg: -201.98 | mem size  50000 |\n",
      "episode: 300 | score avg: -197.90 | mem size  50000 |\n",
      "episode: 301 | score avg: -190.39 | mem size  50000 |\n",
      "episode: 302 | score avg: -184.15 | mem size  50000 |\n",
      "episode: 303 | score avg: -180.53 | mem size  50000 |\n",
      "episode: 304 | score avg: -183.68 | mem size  50000 |\n",
      "episode: 305 | score avg: -189.64 | mem size  50000 |\n",
      "episode: 306 | score avg: -188.39 | mem size  50000 |\n",
      "episode: 307 | score avg: -181.67 | mem size  50000 |\n",
      "episode: 308 | score avg: -173.63 | mem size  50000 |\n",
      "episode: 309 | score avg: -166.04 | mem size  50000 |\n",
      "episode: 310 | score avg: -154.68 | mem size  50000 |\n",
      "episode: 311 | score avg: -146.06 | mem size  50000 |\n",
      "episode: 312 | score avg: -140.08 | mem size  50000 |\n",
      "episode: 313 | score avg: -131.19 | mem size  50000 |\n",
      "episode: 314 | score avg: -123.92 | mem size  50000 |\n",
      "episode: 315 | score avg: -123.89 | mem size  50000 |\n",
      "episode: 316 | score avg: -135.07 | mem size  50000 |\n",
      "episode: 317 | score avg: -134.04 | mem size  50000 |\n",
      "episode: 318 | score avg: -130.28 | mem size  50000 |\n",
      "episode: 319 | score avg: -133.32 | mem size  50000 |\n",
      "episode: 320 | score avg: -129.21 | mem size  50000 |\n",
      "episode: 321 | score avg: -119.20 | mem size  50000 |\n",
      "episode: 322 | score avg: -123.13 | mem size  50000 |\n",
      "episode: 323 | score avg: -117.97 | mem size  50000 |\n",
      "episode: 324 | score avg: -116.16 | mem size  50000 |\n",
      "episode: 325 | score avg: -112.21 | mem size  50000 |\n",
      "episode: 326 | score avg: -113.64 | mem size  50000 |\n",
      "episode: 327 | score avg: -110.02 | mem size  50000 |\n",
      "episode: 328 | score avg: -112.41 | mem size  50000 |\n",
      "episode: 329 | score avg: -113.18 | mem size  50000 |\n",
      "episode: 330 | score avg: -116.38 | mem size  50000 |\n",
      "episode: 331 | score avg: -118.56 | mem size  50000 |\n",
      "episode: 332 | score avg: -123.54 | mem size  50000 |\n",
      "episode: 333 | score avg: -126.57 | mem size  50000 |\n",
      "episode: 334 | score avg: -130.03 | mem size  50000 |\n",
      "episode: 335 | score avg: -123.07 | mem size  50000 |\n",
      "episode: 336 | score avg: -128.83 | mem size  50000 |\n",
      "episode: 337 | score avg: -127.55 | mem size  50000 |\n",
      "episode: 338 | score avg: -125.08 | mem size  50000 |\n",
      "episode: 339 | score avg: -117.08 | mem size  50000 |\n",
      "episode: 340 | score avg: -88.89 | mem size  50000 |\n",
      "episode: 341 | score avg: -88.02 | mem size  50000 |\n",
      "episode: 342 | score avg: -98.08 | mem size  50000 |\n",
      "episode: 343 | score avg: -106.86 | mem size  50000 |\n",
      "episode: 344 | score avg: -112.71 | mem size  50000 |\n",
      "episode: 345 | score avg: -117.87 | mem size  50000 |\n",
      "episode: 346 | score avg: -116.74 | mem size  50000 |\n",
      "episode: 347 | score avg: -120.40 | mem size  50000 |\n",
      "episode: 348 | score avg: -123.95 | mem size  50000 |\n",
      "episode: 349 | score avg: -129.48 | mem size  50000 |\n",
      "episode: 350 | score avg: -124.02 | mem size  50000 |\n",
      "episode: 351 | score avg: -121.51 | mem size  50000 |\n",
      "episode: 352 | score avg: -118.99 | mem size  50000 |\n",
      "episode: 353 | score avg: -127.49 | mem size  50000 |\n",
      "episode: 354 | score avg: -128.57 | mem size  50000 |\n",
      "episode: 355 | score avg: -130.42 | mem size  50000 |\n",
      "episode: 356 | score avg: -133.52 | mem size  50000 |\n",
      "episode: 357 | score avg: -134.00 | mem size  50000 |\n",
      "episode: 358 | score avg: -134.66 | mem size  50000 |\n",
      "episode: 359 | score avg: -136.54 | mem size  50000 |\n",
      "episode: 360 | score avg: -141.21 | mem size  50000 |\n",
      "episode: 361 | score avg: -131.35 | mem size  50000 |\n",
      "episode: 362 | score avg: -127.18 | mem size  50000 |\n",
      "episode: 363 | score avg: -129.41 | mem size  50000 |\n",
      "episode: 364 | score avg: -132.96 | mem size  50000 |\n",
      "episode: 365 | score avg: -135.60 | mem size  50000 |\n",
      "episode: 366 | score avg: -137.21 | mem size  50000 |\n",
      "episode: 367 | score avg: -142.52 | mem size  50000 |\n",
      "episode: 368 | score avg: -148.62 | mem size  50000 |\n",
      "episode: 369 | score avg: -150.29 | mem size  50000 |\n",
      "episode: 370 | score avg: -148.17 | mem size  50000 |\n",
      "episode: 371 | score avg: -151.99 | mem size  50000 |\n",
      "episode: 372 | score avg: -149.19 | mem size  50000 |\n",
      "episode: 373 | score avg: -146.96 | mem size  50000 |\n",
      "episode: 374 | score avg: -151.56 | mem size  50000 |\n",
      "episode: 375 | score avg: -155.86 | mem size  50000 |\n",
      "episode: 376 | score avg: -156.29 | mem size  50000 |\n",
      "episode: 377 | score avg: -150.32 | mem size  50000 |\n",
      "episode: 378 | score avg: -148.62 | mem size  50000 |\n",
      "episode: 379 | score avg: -151.51 | mem size  50000 |\n",
      "episode: 380 | score avg: -154.47 | mem size  50000 |\n",
      "episode: 381 | score avg: -136.66 | mem size  50000 |\n",
      "episode: 382 | score avg: -115.01 | mem size  50000 |\n",
      "episode: 383 | score avg: -123.28 | mem size  50000 |\n",
      "episode: 384 | score avg: -86.43 | mem size  50000 |\n",
      "episode: 385 | score avg: -88.88 | mem size  50000 |\n",
      "episode: 386 | score avg: -129.32 | mem size  50000 |\n",
      "episode: 387 | score avg: -138.91 | mem size  50000 |\n",
      "episode: 388 | score avg: -133.70 | mem size  50000 |\n",
      "episode: 389 | score avg: -129.51 | mem size  50000 |\n",
      "episode: 390 | score avg: -126.91 | mem size  50000 |\n",
      "episode: 391 | score avg: -92.03 | mem size  50000 |\n",
      "episode: 392 | score avg: -59.88 | mem size  50000 |\n",
      "episode: 393 | score avg: -42.47 | mem size  50000 |\n",
      "episode: 394 | score avg: -52.76 | mem size  50000 |\n",
      "episode: 395 | score avg: -61.70 | mem size  50000 |\n",
      "episode: 396 | score avg: -69.45 | mem size  50000 |\n",
      "episode: 397 | score avg: -67.50 | mem size  50000 |\n",
      "episode: 398 | score avg: -41.22 | mem size  50000 |\n",
      "episode: 399 | score avg: -62.83 | mem size  50000 |\n",
      "episode: 400 | score avg: -80.52 | mem size  50000 |\n",
      "episode: 401 | score avg: -101.83 | mem size  50000 |\n",
      "episode: 402 | score avg: -117.26 | mem size  50000 |\n",
      "episode: 403 | score avg: -131.39 | mem size  50000 |\n",
      "episode: 404 | score avg: -146.06 | mem size  50000 |\n",
      "episode: 405 | score avg: -105.92 | mem size  50000 |\n",
      "episode: 406 | score avg: -110.49 | mem size  50000 |\n",
      "episode: 407 | score avg: -118.60 | mem size  50000 |\n",
      "episode: 408 | score avg: -133.46 | mem size  50000 |\n",
      "episode: 409 | score avg: -144.44 | mem size  50000 |\n",
      "episode: 410 | score avg: -146.99 | mem size  50000 |\n",
      "episode: 411 | score avg: -138.45 | mem size  50000 |\n",
      "episode: 412 | score avg: -134.99 | mem size  50000 |\n",
      "episode: 413 | score avg: -136.50 | mem size  50000 |\n",
      "episode: 414 | score avg: -129.38 | mem size  50000 |\n",
      "episode: 415 | score avg: -97.32 | mem size  50000 |\n",
      "episode: 416 | score avg: -105.82 | mem size  50000 |\n",
      "episode: 417 | score avg: -125.96 | mem size  50000 |\n",
      "episode: 418 | score avg: -138.54 | mem size  50000 |\n",
      "episode: 419 | score avg: -150.53 | mem size  50000 |\n",
      "episode: 420 | score avg: -150.33 | mem size  50000 |\n",
      "episode: 421 | score avg: -147.77 | mem size  50000 |\n",
      "episode: 422 | score avg: -142.67 | mem size  50000 |\n",
      "episode: 423 | score avg: -149.96 | mem size  50000 |\n",
      "episode: 424 | score avg: -160.38 | mem size  50000 |\n",
      "episode: 425 | score avg: -157.14 | mem size  50000 |\n",
      "episode: 426 | score avg: -150.81 | mem size  50000 |\n",
      "episode: 427 | score avg: -163.09 | mem size  50000 |\n",
      "episode: 428 | score avg: -139.69 | mem size  50000 |\n",
      "episode: 429 | score avg: -106.95 | mem size  50000 |\n",
      "episode: 430 | score avg: -104.92 | mem size  50000 |\n",
      "episode: 431 | score avg: -104.35 | mem size  50000 |\n",
      "episode: 432 | score avg: -121.23 | mem size  50000 |\n",
      "episode: 433 | score avg: -87.37 | mem size  50000 |\n",
      "episode: 434 | score avg: -80.01 | mem size  50000 |\n",
      "episode: 435 | score avg: -89.88 | mem size  50000 |\n",
      "episode: 436 | score avg: -83.96 | mem size  50000 |\n",
      "episode: 437 | score avg: -79.33 | mem size  50000 |\n",
      "episode: 438 | score avg: -49.97 | mem size  50000 |\n",
      "episode: 439 | score avg: -54.61 | mem size  50000 |\n",
      "episode: 440 | score avg: -67.80 | mem size  50000 |\n",
      "episode: 441 | score avg: -77.42 | mem size  50000 |\n",
      "episode: 442 | score avg: -86.68 | mem size  50000 |\n",
      "episode: 443 | score avg: -88.22 | mem size  50000 |\n",
      "episode: 444 | score avg: -96.08 | mem size  50000 |\n",
      "episode: 445 | score avg: -109.76 | mem size  50000 |\n",
      "episode: 446 | score avg: -116.11 | mem size  50000 |\n",
      "episode: 447 | score avg: -124.52 | mem size  50000 |\n",
      "episode: 448 | score avg: -136.21 | mem size  50000 |\n",
      "episode: 449 | score avg: -131.08 | mem size  50000 |\n",
      "episode: 450 | score avg: -117.95 | mem size  50000 |\n",
      "episode: 451 | score avg: -87.77 | mem size  50000 |\n",
      "episode: 452 | score avg: -56.61 | mem size  50000 |\n",
      "episode: 453 | score avg: -55.54 | mem size  50000 |\n",
      "episode: 454 | score avg: -27.15 | mem size  50000 |\n",
      "episode: 455 | score avg: -4.47 | mem size  50000 |\n",
      "episode: 456 | score avg: 14.09 | mem size  50000 |\n",
      "episode: 457 | score avg: -7.84 | mem size  50000 |\n",
      "episode: 458 | score avg: 12.07 | mem size  50000 |\n",
      "episode: 459 | score avg: -12.30 | mem size  50000 |\n",
      "episode: 460 | score avg: -18.17 | mem size  50000 |\n",
      "episode: 461 | score avg: -38.03 | mem size  50000 |\n",
      "episode: 462 | score avg: -50.19 | mem size  50000 |\n",
      "episode: 463 | score avg: -65.39 | mem size  50000 |\n",
      "episode: 464 | score avg: -59.47 | mem size  50000 |\n",
      "episode: 465 | score avg: -68.20 | mem size  50000 |\n",
      "episode: 466 | score avg: -58.63 | mem size  50000 |\n",
      "episode: 467 | score avg: -79.78 | mem size  50000 |\n",
      "episode: 468 | score avg: -90.74 | mem size  50000 |\n",
      "episode: 469 | score avg: -80.24 | mem size  50000 |\n",
      "episode: 470 | score avg: -123.06 | mem size  50000 |\n",
      "episode: 471 | score avg: -162.59 | mem size  50000 |\n",
      "episode: 472 | score avg: -167.68 | mem size  50000 |\n",
      "episode: 473 | score avg: -174.21 | mem size  50000 |\n",
      "episode: 474 | score avg: -182.43 | mem size  50000 |\n",
      "episode: 475 | score avg: -186.69 | mem size  50000 |\n",
      "episode: 476 | score avg: -195.24 | mem size  50000 |\n",
      "episode: 477 | score avg: -192.52 | mem size  50000 |\n",
      "episode: 478 | score avg: -203.46 | mem size  50000 |\n",
      "episode: 479 | score avg: -212.88 | mem size  50000 |\n",
      "episode: 480 | score avg: -220.63 | mem size  50000 |\n",
      "episode: 481 | score avg: -219.82 | mem size  50000 |\n",
      "episode: 482 | score avg: -217.61 | mem size  50000 |\n",
      "episode: 483 | score avg: -226.10 | mem size  50000 |\n",
      "episode: 484 | score avg: -234.59 | mem size  50000 |\n",
      "episode: 485 | score avg: -241.71 | mem size  50000 |\n",
      "episode: 486 | score avg: -243.89 | mem size  50000 |\n",
      "episode: 487 | score avg: -287.74 | mem size  50000 |\n",
      "episode: 488 | score avg: -295.11 | mem size  50000 |\n",
      "episode: 489 | score avg: -299.59 | mem size  50000 |\n",
      "episode: 490 | score avg: -301.60 | mem size  50000 |\n",
      "episode: 491 | score avg: -298.61 | mem size  50000 |\n",
      "episode: 492 | score avg: -305.29 | mem size  50000 |\n",
      "episode: 493 | score avg: -311.30 | mem size  50000 |\n",
      "episode: 494 | score avg: -317.86 | mem size  50000 |\n",
      "episode: 495 | score avg: -322.28 | mem size  50000 |\n",
      "episode: 496 | score avg: -325.01 | mem size  50000 |\n",
      "episode: 497 | score avg: -303.74 | mem size  50000 |\n",
      "episode: 498 | score avg: -310.16 | mem size  50000 |\n",
      "episode: 499 | score avg: -309.15 | mem size  50000 |\n",
      "episode: 500 | score avg: -310.30 | mem size  50000 |\n",
      "episode: 501 | score avg: -253.78 | mem size  50000 |\n",
      "episode: 502 | score avg: -200.17 | mem size  50000 |\n",
      "episode: 503 | score avg: -206.25 | mem size  50000 |\n",
      "episode: 504 | score avg: -203.10 | mem size  50000 |\n",
      "episode: 505 | score avg: -210.52 | mem size  50000 |\n",
      "episode: 506 | score avg: -220.58 | mem size  50000 |\n",
      "episode: 507 | score avg: -220.68 | mem size  50000 |\n",
      "episode: 508 | score avg: -233.25 | mem size  50000 |\n",
      "episode: 509 | score avg: -243.37 | mem size  50000 |\n",
      "episode: 510 | score avg: -240.89 | mem size  50000 |\n",
      "episode: 511 | score avg: -241.38 | mem size  50000 |\n",
      "episode: 512 | score avg: -234.31 | mem size  50000 |\n",
      "episode: 513 | score avg: -239.74 | mem size  50000 |\n",
      "episode: 514 | score avg: -244.10 | mem size  50000 |\n",
      "episode: 515 | score avg: -239.17 | mem size  50000 |\n",
      "episode: 516 | score avg: -225.76 | mem size  50000 |\n",
      "episode: 517 | score avg: -218.98 | mem size  50000 |\n",
      "episode: 518 | score avg: -205.11 | mem size  50000 |\n",
      "episode: 519 | score avg: -190.21 | mem size  50000 |\n",
      "episode: 520 | score avg: -193.87 | mem size  50000 |\n",
      "episode: 521 | score avg: -198.19 | mem size  50000 |\n",
      "episode: 522 | score avg: -200.52 | mem size  50000 |\n",
      "episode: 523 | score avg: -189.47 | mem size  50000 |\n",
      "episode: 524 | score avg: -189.38 | mem size  50000 |\n",
      "episode: 525 | score avg: -196.53 | mem size  50000 |\n",
      "episode: 526 | score avg: -222.84 | mem size  50000 |\n",
      "episode: 527 | score avg: -244.24 | mem size  50000 |\n",
      "episode: 528 | score avg: -357.39 | mem size  50000 |\n",
      "episode: 529 | score avg: -338.05 | mem size  50000 |\n",
      "episode: 530 | score avg: -316.80 | mem size  50000 |\n",
      "episode: 531 | score avg: -302.04 | mem size  50000 |\n",
      "episode: 532 | score avg: -326.29 | mem size  50000 |\n",
      "episode: 533 | score avg: -336.30 | mem size  50000 |\n",
      "episode: 534 | score avg: -337.07 | mem size  50000 |\n",
      "episode: 535 | score avg: -278.82 | mem size  50000 |\n",
      "episode: 536 | score avg: -298.97 | mem size  50000 |\n",
      "episode: 537 | score avg: -303.74 | mem size  50000 |\n",
      "episode: 538 | score avg: -302.11 | mem size  50000 |\n",
      "episode: 539 | score avg: -242.11 | mem size  50000 |\n",
      "episode: 540 | score avg: -194.81 | mem size  50000 |\n",
      "episode: 541 | score avg: -184.72 | mem size  50000 |\n",
      "episode: 542 | score avg: -178.86 | mem size  50000 |\n",
      "episode: 543 | score avg: -164.11 | mem size  50000 |\n",
      "episode: 544 | score avg: -166.53 | mem size  50000 |\n",
      "episode: 545 | score avg: -181.47 | mem size  50000 |\n",
      "episode: 546 | score avg: -158.95 | mem size  50000 |\n",
      "episode: 547 | score avg: -120.82 | mem size  50000 |\n",
      "episode: 548 | score avg: -113.27 | mem size  50000 |\n",
      "episode: 549 | score avg: -118.80 | mem size  50000 |\n",
      "episode: 550 | score avg: -123.61 | mem size  50000 |\n",
      "episode: 551 | score avg: -126.01 | mem size  50000 |\n",
      "episode: 552 | score avg: -91.48 | mem size  50000 |\n",
      "episode: 553 | score avg: -80.98 | mem size  50000 |\n",
      "episode: 554 | score avg: -86.05 | mem size  50000 |\n",
      "episode: 555 | score avg: -111.59 | mem size  50000 |\n",
      "episode: 556 | score avg: -123.57 | mem size  50000 |\n",
      "episode: 557 | score avg: -117.11 | mem size  50000 |\n",
      "episode: 558 | score avg: -107.37 | mem size  50000 |\n",
      "episode: 559 | score avg: -97.58 | mem size  50000 |\n",
      "episode: 560 | score avg: -104.40 | mem size  50000 |\n",
      "episode: 561 | score avg: -70.37 | mem size  50000 |\n",
      "episode: 562 | score avg: -61.10 | mem size  50000 |\n",
      "episode: 563 | score avg: -53.62 | mem size  50000 |\n",
      "episode: 564 | score avg: -69.69 | mem size  50000 |\n",
      "episode: 565 | score avg: -60.01 | mem size  50000 |\n",
      "episode: 566 | score avg: -56.72 | mem size  50000 |\n",
      "episode: 567 | score avg: -55.71 | mem size  50000 |\n",
      "episode: 568 | score avg: -71.58 | mem size  50000 |\n",
      "episode: 569 | score avg: -68.40 | mem size  50000 |\n",
      "episode: 570 | score avg: -78.28 | mem size  50000 |\n",
      "episode: 571 | score avg: -86.57 | mem size  50000 |\n",
      "episode: 572 | score avg: -79.17 | mem size  50000 |\n",
      "episode: 573 | score avg: -46.11 | mem size  50000 |\n",
      "episode: 574 | score avg: -24.56 | mem size  50000 |\n",
      "episode: 575 | score avg: -30.32 | mem size  50000 |\n",
      "episode: 576 | score avg: -28.47 | mem size  50000 |\n",
      "episode: 577 | score avg: -29.32 | mem size  50000 |\n",
      "episode: 578 | score avg: -47.13 | mem size  50000 |\n",
      "episode: 579 | score avg: -46.27 | mem size  50000 |\n",
      "episode: 580 | score avg: -19.43 | mem size  50000 |\n",
      "episode: 581 | score avg: -28.44 | mem size  50000 |\n",
      "episode: 582 | score avg: -54.32 | mem size  50000 |\n",
      "episode: 583 | score avg: -94.48 | mem size  50000 |\n",
      "episode: 584 | score avg: -100.91 | mem size  50000 |\n",
      "episode: 585 | score avg: -101.42 | mem size  50000 |\n",
      "episode: 586 | score avg: -86.07 | mem size  50000 |\n",
      "episode: 587 | score avg: -86.84 | mem size  50000 |\n",
      "episode: 588 | score avg: -84.91 | mem size  50000 |\n",
      "episode: 589 | score avg: -97.54 | mem size  50000 |\n",
      "episode: 590 | score avg: -98.33 | mem size  50000 |\n",
      "episode: 591 | score avg: -67.02 | mem size  50000 |\n",
      "episode: 592 | score avg: -88.35 | mem size  50000 |\n",
      "episode: 593 | score avg: -101.12 | mem size  50000 |\n",
      "episode: 594 | score avg: -111.10 | mem size  50000 |\n",
      "episode: 595 | score avg: -114.36 | mem size  50000 |\n",
      "episode: 596 | score avg: -117.85 | mem size  50000 |\n",
      "episode: 597 | score avg: -111.30 | mem size  50000 |\n",
      "episode: 598 | score avg: -114.92 | mem size  50000 |\n",
      "episode: 599 | score avg: -103.15 | mem size  50000 |\n",
      "episode: 600 | score avg: -107.83 | mem size  50000 |\n",
      "episode: 601 | score avg: -112.45 | mem size  50000 |\n",
      "episode: 602 | score avg: -118.14 | mem size  50000 |\n",
      "episode: 603 | score avg: -124.26 | mem size  50000 |\n",
      "episode: 604 | score avg: -128.91 | mem size  50000 |\n",
      "episode: 605 | score avg: -144.94 | mem size  50000 |\n",
      "episode: 606 | score avg: -183.17 | mem size  50000 |\n",
      "episode: 607 | score avg: -177.55 | mem size  50000 |\n",
      "episode: 608 | score avg: -200.43 | mem size  50000 |\n",
      "episode: 609 | score avg: -186.34 | mem size  50000 |\n",
      "episode: 610 | score avg: -204.10 | mem size  50000 |\n",
      "episode: 611 | score avg: -197.06 | mem size  50000 |\n",
      "episode: 612 | score avg: -205.36 | mem size  50000 |\n",
      "episode: 613 | score avg: -199.08 | mem size  50000 |\n",
      "episode: 614 | score avg: -196.24 | mem size  50000 |\n",
      "episode: 615 | score avg: -185.34 | mem size  50000 |\n",
      "episode: 616 | score avg: -176.23 | mem size  50000 |\n",
      "episode: 617 | score avg: -163.12 | mem size  50000 |\n",
      "episode: 618 | score avg: -179.38 | mem size  50000 |\n",
      "episode: 619 | score avg: -166.33 | mem size  50000 |\n",
      "episode: 620 | score avg: -183.38 | mem size  50000 |\n",
      "episode: 621 | score avg: -146.36 | mem size  50000 |\n",
      "episode: 622 | score avg: -144.07 | mem size  50000 |\n",
      "episode: 623 | score avg: -151.47 | mem size  50000 |\n",
      "episode: 624 | score avg: -153.84 | mem size  50000 |\n",
      "episode: 625 | score avg: -165.17 | mem size  50000 |\n",
      "episode: 626 | score avg: -148.18 | mem size  50000 |\n",
      "episode: 627 | score avg: -115.87 | mem size  50000 |\n",
      "episode: 628 | score avg: -88.01 | mem size  50000 |\n",
      "episode: 629 | score avg: -56.58 | mem size  50000 |\n",
      "episode: 630 | score avg: -23.10 | mem size  50000 |\n",
      "episode: 631 | score avg: 4.09 | mem size  50000 |\n",
      "episode: 632 | score avg: 28.20 | mem size  50000 |\n",
      "episode: 633 | score avg: 13.31 | mem size  50000 |\n",
      "episode: 634 | score avg: -25.24 | mem size  50000 |\n",
      "episode: 635 | score avg: -52.98 | mem size  50000 |\n",
      "episode: 636 | score avg: -84.69 | mem size  50000 |\n",
      "episode: 637 | score avg: -120.07 | mem size  50000 |\n",
      "episode: 638 | score avg: -103.44 | mem size  50000 |\n",
      "episode: 639 | score avg: -88.13 | mem size  50000 |\n",
      "episode: 640 | score avg: -53.67 | mem size  50000 |\n",
      "episode: 641 | score avg: -25.47 | mem size  50000 |\n",
      "episode: 642 | score avg: -27.06 | mem size  50000 |\n",
      "episode: 643 | score avg: 1.24 | mem size  50000 |\n",
      "episode: 644 | score avg: 0.83 | mem size  50000 |\n",
      "episode: 645 | score avg: 1.23 | mem size  50000 |\n",
      "episode: 646 | score avg: 23.16 | mem size  50000 |\n",
      "episode: 647 | score avg: 15.19 | mem size  50000 |\n",
      "episode: 648 | score avg: 34.98 | mem size  50000 |\n",
      "episode: 649 | score avg: 31.45 | mem size  50000 |\n",
      "episode: 650 | score avg: 24.23 | mem size  50000 |\n",
      "episode: 651 | score avg: 26.53 | mem size  50000 |\n",
      "episode: 652 | score avg: 19.66 | mem size  50000 |\n",
      "episode: 653 | score avg: 39.75 | mem size  50000 |\n",
      "episode: 654 | score avg: 60.05 | mem size  50000 |\n",
      "episode: 655 | score avg: 25.10 | mem size  50000 |\n",
      "episode: 656 | score avg: 3.06 | mem size  50000 |\n",
      "episode: 657 | score avg: 27.42 | mem size  50000 |\n",
      "episode: 658 | score avg: 43.98 | mem size  50000 |\n",
      "episode: 659 | score avg: 58.54 | mem size  50000 |\n",
      "episode: 660 | score avg: 55.27 | mem size  50000 |\n",
      "episode: 661 | score avg: 74.61 | mem size  50000 |\n",
      "episode: 662 | score avg: 79.52 | mem size  50000 |\n",
      "episode: 663 | score avg: 54.50 | mem size  50000 |\n",
      "episode: 664 | score avg: 31.36 | mem size  50000 |\n",
      "episode: 665 | score avg: 16.86 | mem size  50000 |\n",
      "episode: 666 | score avg: 7.62 | mem size  50000 |\n",
      "episode: 667 | score avg: -6.28 | mem size  50000 |\n",
      "episode: 668 | score avg: -25.10 | mem size  50000 |\n",
      "episode: 669 | score avg: -38.47 | mem size  50000 |\n",
      "episode: 670 | score avg: -51.42 | mem size  50000 |\n",
      "episode: 671 | score avg: -62.48 | mem size  50000 |\n",
      "episode: 672 | score avg: -79.32 | mem size  50000 |\n",
      "episode: 673 | score avg: -87.01 | mem size  50000 |\n",
      "episode: 674 | score avg: -96.06 | mem size  50000 |\n",
      "episode: 675 | score avg: -97.39 | mem size  50000 |\n",
      "episode: 676 | score avg: -121.17 | mem size  50000 |\n",
      "episode: 677 | score avg: -125.68 | mem size  50000 |\n",
      "episode: 678 | score avg: -123.93 | mem size  50000 |\n",
      "episode: 679 | score avg: -127.15 | mem size  50000 |\n",
      "episode: 680 | score avg: -163.43 | mem size  50000 |\n",
      "episode: 681 | score avg: -167.41 | mem size  50000 |\n",
      "episode: 682 | score avg: -157.65 | mem size  50000 |\n",
      "episode: 683 | score avg: -149.29 | mem size  50000 |\n",
      "episode: 684 | score avg: -139.76 | mem size  50000 |\n",
      "episode: 685 | score avg: -134.64 | mem size  50000 |\n",
      "episode: 686 | score avg: -153.76 | mem size  50000 |\n",
      "episode: 687 | score avg: -156.85 | mem size  50000 |\n",
      "episode: 688 | score avg: -165.36 | mem size  50000 |\n",
      "episode: 689 | score avg: -176.18 | mem size  50000 |\n",
      "episode: 690 | score avg: -182.59 | mem size  50000 |\n",
      "episode: 691 | score avg: -189.04 | mem size  50000 |\n",
      "episode: 692 | score avg: -189.25 | mem size  50000 |\n",
      "episode: 693 | score avg: -195.57 | mem size  50000 |\n",
      "episode: 694 | score avg: -215.14 | mem size  50000 |\n",
      "episode: 695 | score avg: -245.33 | mem size  50000 |\n",
      "episode: 696 | score avg: -243.20 | mem size  50000 |\n",
      "episode: 697 | score avg: -232.65 | mem size  50000 |\n",
      "episode: 698 | score avg: -219.34 | mem size  50000 |\n",
      "episode: 699 | score avg: -224.21 | mem size  50000 |\n",
      "episode: 700 | score avg: -222.11 | mem size  50000 |\n",
      "episode: 701 | score avg: -213.51 | mem size  50000 |\n",
      "episode: 702 | score avg: -212.57 | mem size  50000 |\n",
      "episode: 703 | score avg: -209.28 | mem size  50000 |\n",
      "episode: 704 | score avg: -205.93 | mem size  50000 |\n",
      "episode: 705 | score avg: -198.04 | mem size  50000 |\n",
      "episode: 706 | score avg: -191.78 | mem size  50000 |\n",
      "episode: 707 | score avg: -170.74 | mem size  50000 |\n",
      "episode: 708 | score avg: -163.02 | mem size  50000 |\n",
      "episode: 709 | score avg: -171.77 | mem size  50000 |\n",
      "episode: 710 | score avg: -172.11 | mem size  50000 |\n",
      "episode: 711 | score avg: -182.44 | mem size  50000 |\n",
      "episode: 712 | score avg: -189.71 | mem size  50000 |\n",
      "episode: 713 | score avg: -191.57 | mem size  50000 |\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "env.close()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ]
}