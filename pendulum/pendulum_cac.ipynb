{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3710jvsc74a57bd0d58761fb0507901c753af48a6b8c3f78eaa64b9d21040326b9f6cfad30dd9f9c",
   "display_name": "Python 3.7.10 64-bit ('tf240_gpu': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import sys\n",
    "import pylab\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow_probability import distributions as tfd\n",
    "from tensorflow.keras.initializers import RandomUniform\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "dist = tfd.Normal(loc=0., scale=3.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CAC(tf.keras.Model):\n",
    "    def __init__(self, state_size, action_size):\n",
    "        super(CAC, self).__init__()\n",
    "        self.actor_fc1 = Dense(24,activation='tanh')\n",
    "        self.actor_mu  = Dense(action_size,kernel_initializer=RandomUniform(-1e-3,1e-3))\n",
    "        self.actor_sig = Dense(action_size, activation='sigmoid',kernel_initializer=RandomUniform(-1e-3,1e-3))\n",
    "\n",
    "        self.critic_fc1 = Dense(24,activation='tanh')\n",
    "        self.critic_fc2 = Dense(24,activation='tanh')\n",
    "        self.critic_out = Dense(1,kernel_initializer=tf.keras.initializers.RandomUniform(-1e-3,1e-3))\n",
    "\n",
    "    def call(self,x):\n",
    "        x1  = self.actor_fc1(x)\n",
    "        mu  = self.actor_mu(x1)\n",
    "        sig = self.actor_sig(x1)\n",
    "        sig+= 1e-5\n",
    "\n",
    "        x1  = self.critic_fc1(x)\n",
    "        x2  = self.critic_fc2(x1)\n",
    "        val = self.critic_out(x2)\n",
    "\n",
    "        return mu, sig, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CACAgent:\n",
    "    def __init__(self, state_size, action_size, act_min, act_max):\n",
    "        self.state_size = state_size\n",
    "        self.action_size= action_size\n",
    "        self.act_min = act_min\n",
    "        self.act_max = act_max\n",
    "\n",
    "        # Hyper params for learning\n",
    "        self.discount_factor = 0.99\n",
    "        self.learning_rate = 0.001\n",
    "\n",
    "        self.model     = CAC(self.state_size, self.action_size)\n",
    "        self.optimizer = tf.keras.optimizers.Adam(lr=self.learning_rate, clipnorm=1.0)\n",
    "\n",
    "    def get_action(self, state):\n",
    "        mu, sigma, _ = self.model(state)\n",
    "        distrib = tfd.Normal(loc=mu[0], scale=sigma[0])\n",
    "        action = distrib.sample([1])[0]\n",
    "        return np.clip(action, self.act_min, self.act_max)\n",
    "\n",
    "    def train_model(self, state, action, reward, next_state, done):\n",
    "        model_params = self.model.trainable_variables\n",
    "        with tf.GradientTape() as tape:\n",
    "            mu, sigma, value = self.model(state)\n",
    "            _, _, next_value = self.model(next_state)\n",
    "            target = reward + (1 - done) * self.discount_factor * next_value[0]\n",
    "\n",
    "            # Policy Network\n",
    "            advantage = tf.stop_gradient(target - value[0])\n",
    "            distrib = tfd.Normal(loc=mu[0], scale=sigma[0])\n",
    "            action_prob = distrib.prob([action])[0]\n",
    "            cross_entropy = - tf.math.log(action_prob + 1e-5)\n",
    "            actor_loss = tf.reduce_mean(cross_entropy * advantage)\n",
    "\n",
    "            # Value Network\n",
    "            critic_loss = 0.5 * tf.square(tf.stop_gradient(target) - value[0])\n",
    "            critic_loss = tf.reduce_mean(critic_loss)\n",
    "\n",
    "            loss = 0.1 * actor_loss + critic_loss\n",
    "        \n",
    "        # Update weights\n",
    "        grads = tape.gradient(loss, model_params)\n",
    "        self.optimizer.apply_gradients(zip(grads, model_params))\n",
    "        return loss, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "95 | loss: 0.240 | sigma: 0.278\n",
      "episode: 323 | score avg: -1452.30 | loss: 0.238 | sigma: 0.280\n",
      "episode: 324 | score avg: -1447.60 | loss: 0.237 | sigma: 0.165\n",
      "episode: 325 | score avg: -1446.77 | loss: 0.236 | sigma: 0.266\n",
      "episode: 326 | score avg: -1452.96 | loss: 0.237 | sigma: 0.257\n",
      "episode: 327 | score avg: -1457.61 | loss: 0.235 | sigma: 0.277\n",
      "episode: 328 | score avg: -1461.85 | loss: 0.239 | sigma: 0.348\n",
      "episode: 329 | score avg: -1454.87 | loss: 0.459 | sigma: 0.335\n",
      "episode: 330 | score avg: -1459.80 | loss: 0.240 | sigma: 0.329\n",
      "episode: 331 | score avg: -1463.70 | loss: 0.236 | sigma: 0.313\n",
      "episode: 332 | score avg: -1460.31 | loss: 0.237 | sigma: 0.183\n",
      "episode: 333 | score avg: -1458.43 | loss: 0.284 | sigma: 0.307\n",
      "episode: 334 | score avg: -1455.77 | loss: 0.243 | sigma: 0.308\n",
      "episode: 335 | score avg: -1459.51 | loss: 0.237 | sigma: 0.267\n",
      "episode: 336 | score avg: -1465.21 | loss: 0.239 | sigma: 0.188\n",
      "episode: 337 | score avg: -1464.35 | loss: 0.236 | sigma: 0.291\n",
      "episode: 338 | score avg: -1443.86 | loss: 0.231 | sigma: 0.386\n",
      "episode: 339 | score avg: -1449.00 | loss: 0.238 | sigma: 0.351\n",
      "episode: 340 | score avg: -1454.25 | loss: 0.239 | sigma: 0.366\n",
      "episode: 341 | score avg: -1453.12 | loss: 0.235 | sigma: 0.403\n",
      "episode: 342 | score avg: -1457.64 | loss: 0.238 | sigma: 0.547\n",
      "episode: 343 | score avg: -1462.50 | loss: 0.239 | sigma: 0.444\n",
      "episode: 344 | score avg: -1467.20 | loss: 0.238 | sigma: 0.536\n",
      "episode: 345 | score avg: -1457.25 | loss: 0.235 | sigma: 0.651\n",
      "episode: 346 | score avg: -1459.81 | loss: 0.238 | sigma: 0.765\n",
      "episode: 347 | score avg: -1450.48 | loss: 0.289 | sigma: 0.727\n",
      "episode: 348 | score avg: -1453.27 | loss: 0.243 | sigma: 0.686\n",
      "episode: 349 | score avg: -1453.73 | loss: 0.241 | sigma: 0.685\n",
      "episode: 350 | score avg: -1454.06 | loss: 0.243 | sigma: 0.669\n",
      "episode: 351 | score avg: -1459.52 | loss: 0.244 | sigma: 0.665\n",
      "episode: 352 | score avg: -1459.95 | loss: 0.555 | sigma: 0.543\n",
      "episode: 353 | score avg: -1458.68 | loss: 0.237 | sigma: 0.640\n",
      "episode: 354 | score avg: -1453.68 | loss: 0.267 | sigma: 0.553\n",
      "episode: 355 | score avg: -1454.70 | loss: 0.244 | sigma: 0.476\n",
      "episode: 356 | score avg: -1456.87 | loss: 0.239 | sigma: 0.498\n",
      "episode: 357 | score avg: -1459.76 | loss: 0.237 | sigma: 0.576\n",
      "episode: 358 | score avg: -1460.49 | loss: 0.249 | sigma: 0.470\n",
      "episode: 359 | score avg: -1466.35 | loss: 0.267 | sigma: 0.364\n",
      "episode: 360 | score avg: -1465.55 | loss: 0.275 | sigma: 0.370\n",
      "episode: 361 | score avg: -1468.49 | loss: 0.242 | sigma: 0.404\n",
      "episode: 362 | score avg: -1462.85 | loss: 0.238 | sigma: 0.456\n",
      "episode: 363 | score avg: -1467.88 | loss: 0.240 | sigma: 0.371\n",
      "episode: 364 | score avg: -1471.86 | loss: 0.238 | sigma: 0.491\n",
      "episode: 365 | score avg: -1471.74 | loss: 0.238 | sigma: 0.408\n",
      "episode: 366 | score avg: -1473.14 | loss: 0.239 | sigma: 0.482\n",
      "episode: 367 | score avg: -1477.06 | loss: 0.271 | sigma: 0.444\n",
      "episode: 368 | score avg: -1479.50 | loss: 0.240 | sigma: 0.358\n",
      "episode: 369 | score avg: -1479.58 | loss: 0.238 | sigma: 0.444\n",
      "episode: 370 | score avg: -1482.73 | loss: 0.240 | sigma: 0.431\n",
      "episode: 371 | score avg: -1482.42 | loss: 0.240 | sigma: 0.449\n",
      "episode: 372 | score avg: -1486.41 | loss: 0.238 | sigma: 0.388\n",
      "episode: 373 | score avg: -1482.98 | loss: 0.265 | sigma: 0.360\n",
      "episode: 374 | score avg: -1481.90 | loss: 0.241 | sigma: 0.350\n",
      "episode: 375 | score avg: -1482.76 | loss: 0.237 | sigma: 0.365\n",
      "episode: 376 | score avg: -1482.00 | loss: 0.237 | sigma: 0.349\n",
      "episode: 377 | score avg: -1484.33 | loss: 0.282 | sigma: 0.328\n",
      "episode: 378 | score avg: -1487.27 | loss: 0.239 | sigma: 0.272\n",
      "episode: 379 | score avg: -1482.51 | loss: 0.234 | sigma: 0.249\n",
      "episode: 380 | score avg: -1476.43 | loss: 0.295 | sigma: 0.261\n",
      "episode: 381 | score avg: -1470.03 | loss: 0.240 | sigma: 0.258\n",
      "episode: 382 | score avg: -1468.70 | loss: 0.238 | sigma: 0.228\n",
      "episode: 383 | score avg: -1464.60 | loss: 0.239 | sigma: 0.270\n",
      "episode: 384 | score avg: -1465.71 | loss: 0.238 | sigma: 0.263\n",
      "episode: 385 | score avg: -1468.38 | loss: 0.238 | sigma: 0.284\n",
      "episode: 386 | score avg: -1470.70 | loss: 0.239 | sigma: 0.248\n",
      "episode: 387 | score avg: -1473.73 | loss: 0.241 | sigma: 0.291\n",
      "episode: 388 | score avg: -1477.81 | loss: 0.239 | sigma: 0.229\n",
      "episode: 389 | score avg: -1460.63 | loss: 0.243 | sigma: 0.302\n",
      "episode: 390 | score avg: -1461.49 | loss: 0.238 | sigma: 0.257\n",
      "episode: 391 | score avg: -1454.08 | loss: 0.243 | sigma: 0.254\n",
      "episode: 392 | score avg: -1457.80 | loss: 0.240 | sigma: 0.270\n",
      "episode: 393 | score avg: -1462.73 | loss: 0.237 | sigma: 0.222\n",
      "episode: 394 | score avg: -1467.06 | loss: 0.235 | sigma: 0.175\n",
      "episode: 395 | score avg: -1465.12 | loss: 0.238 | sigma: 0.243\n",
      "episode: 396 | score avg: -1469.65 | loss: 0.240 | sigma: 0.195\n",
      "episode: 397 | score avg: -1469.71 | loss: 0.236 | sigma: 0.239\n",
      "episode: 398 | score avg: -1450.05 | loss: 0.234 | sigma: 0.246\n",
      "episode: 399 | score avg: -1454.69 | loss: 0.238 | sigma: 0.191\n",
      "episode: 400 | score avg: -1456.36 | loss: 0.238 | sigma: 0.207\n",
      "episode: 401 | score avg: -1441.33 | loss: 0.238 | sigma: 0.251\n",
      "episode: 402 | score avg: -1449.49 | loss: 0.239 | sigma: 0.271\n",
      "episode: 403 | score avg: -1447.26 | loss: 0.237 | sigma: 0.258\n",
      "episode: 404 | score avg: -1454.57 | loss: 0.301 | sigma: 0.252\n",
      "episode: 405 | score avg: -1453.72 | loss: 0.253 | sigma: 0.207\n",
      "episode: 406 | score avg: -1456.04 | loss: 0.238 | sigma: 0.214\n",
      "episode: 407 | score avg: -1458.27 | loss: 0.239 | sigma: 0.190\n",
      "episode: 408 | score avg: -1461.21 | loss: 0.238 | sigma: 0.187\n",
      "episode: 409 | score avg: -1448.04 | loss: 0.234 | sigma: 0.199\n",
      "episode: 410 | score avg: -1451.08 | loss: 0.246 | sigma: 0.193\n",
      "episode: 411 | score avg: -1458.70 | loss: 0.262 | sigma: 0.212\n",
      "episode: 412 | score avg: -1463.79 | loss: 0.299 | sigma: 0.174\n",
      "episode: 413 | score avg: -1464.50 | loss: 0.238 | sigma: 0.128\n",
      "episode: 414 | score avg: -1453.74 | loss: 0.236 | sigma: 0.135\n",
      "episode: 415 | score avg: -1458.05 | loss: 0.239 | sigma: 0.139\n",
      "episode: 416 | score avg: -1465.61 | loss: 0.239 | sigma: 0.163\n",
      "episode: 417 | score avg: -1467.21 | loss: 0.240 | sigma: 0.147\n",
      "episode: 418 | score avg: -1464.32 | loss: 0.238 | sigma: 0.152\n",
      "episode: 419 | score avg: -1465.43 | loss: 0.239 | sigma: 0.156\n",
      "episode: 420 | score avg: -1467.47 | loss: 0.239 | sigma: 0.160\n",
      "episode: 421 | score avg: -1471.75 | loss: 0.301 | sigma: 0.185\n",
      "episode: 422 | score avg: -1472.54 | loss: 0.268 | sigma: 0.143\n",
      "episode: 423 | score avg: -1474.81 | loss: 0.237 | sigma: 0.099\n",
      "episode: 424 | score avg: -1467.94 | loss: 0.248 | sigma: 0.104\n",
      "episode: 425 | score avg: -1473.47 | loss: 0.241 | sigma: 0.101\n",
      "episode: 426 | score avg: -1473.55 | loss: 0.246 | sigma: 0.087\n",
      "episode: 427 | score avg: -1473.60 | loss: 0.239 | sigma: 0.083\n",
      "episode: 428 | score avg: -1474.56 | loss: 0.239 | sigma: 0.081\n",
      "episode: 429 | score avg: -1478.22 | loss: 0.240 | sigma: 0.093\n",
      "episode: 430 | score avg: -1478.47 | loss: 0.240 | sigma: 0.081\n",
      "episode: 431 | score avg: -1471.07 | loss: 0.236 | sigma: 0.081\n",
      "episode: 432 | score avg: -1471.62 | loss: 0.237 | sigma: 0.087\n",
      "episode: 433 | score avg: -1472.21 | loss: 0.238 | sigma: 0.093\n",
      "episode: 434 | score avg: -1473.23 | loss: 0.239 | sigma: 0.104\n",
      "episode: 435 | score avg: -1471.06 | loss: 0.236 | sigma: 0.126\n",
      "episode: 436 | score avg: -1476.28 | loss: 0.304 | sigma: 0.151\n",
      "episode: 437 | score avg: -1470.64 | loss: 0.239 | sigma: 0.138\n",
      "episode: 438 | score avg: -1472.90 | loss: 0.237 | sigma: 0.171\n",
      "episode: 439 | score avg: -1475.12 | loss: 0.240 | sigma: 0.165\n",
      "episode: 440 | score avg: -1478.08 | loss: 0.243 | sigma: 0.168\n",
      "episode: 441 | score avg: -1481.36 | loss: 0.266 | sigma: 0.164\n",
      "episode: 442 | score avg: -1471.61 | loss: 0.246 | sigma: 0.114\n",
      "episode: 443 | score avg: -1473.87 | loss: 0.237 | sigma: 0.124\n",
      "episode: 444 | score avg: -1481.78 | loss: 0.236 | sigma: 0.131\n",
      "episode: 445 | score avg: -1480.90 | loss: 0.298 | sigma: 0.158\n",
      "episode: 446 | score avg: -1506.29 | loss: 0.301 | sigma: 0.240\n",
      "episode: 447 | score avg: -1500.77 | loss: 0.309 | sigma: 0.217\n",
      "episode: 448 | score avg: -1500.92 | loss: 0.294 | sigma: 0.220\n",
      "episode: 449 | score avg: -1498.33 | loss: 0.238 | sigma: 0.179\n",
      "episode: 450 | score avg: -1497.39 | loss: 0.298 | sigma: 0.216\n",
      "episode: 451 | score avg: -1516.79 | loss: 0.300 | sigma: 0.297\n",
      "episode: 452 | score avg: -1517.53 | loss: 0.300 | sigma: 0.294\n",
      "episode: 453 | score avg: -1536.23 | loss: 0.291 | sigma: 0.383\n",
      "episode: 454 | score avg: -1540.50 | loss: 0.292 | sigma: 0.386\n",
      "episode: 455 | score avg: -1554.50 | loss: 0.282 | sigma: 0.400\n",
      "episode: 456 | score avg: -1582.53 | loss: 0.287 | sigma: 0.393\n",
      "episode: 457 | score avg: -1608.79 | loss: 0.295 | sigma: 0.349\n",
      "episode: 458 | score avg: -1623.01 | loss: 0.297 | sigma: 0.338\n",
      "episode: 459 | score avg: -1644.71 | loss: 0.294 | sigma: 0.395\n",
      "episode: 460 | score avg: -1664.85 | loss: 0.294 | sigma: 0.449\n",
      "episode: 461 | score avg: -1678.59 | loss: 0.289 | sigma: 0.505\n",
      "episode: 462 | score avg: -1690.89 | loss: 0.287 | sigma: 0.466\n",
      "episode: 463 | score avg: -1690.54 | loss: 0.291 | sigma: 0.389\n",
      "episode: 464 | score avg: -1701.99 | loss: 0.294 | sigma: 0.394\n",
      "episode: 465 | score avg: -1725.65 | loss: 0.295 | sigma: 0.439\n",
      "episode: 466 | score avg: -1721.65 | loss: 0.326 | sigma: 0.520\n",
      "episode: 467 | score avg: -1728.36 | loss: 0.297 | sigma: 0.451\n",
      "episode: 468 | score avg: -1739.31 | loss: 0.294 | sigma: 0.469\n",
      "episode: 469 | score avg: -1743.09 | loss: 0.297 | sigma: 0.466\n",
      "episode: 470 | score avg: -1734.52 | loss: 0.297 | sigma: 0.467\n",
      "episode: 471 | score avg: -1736.00 | loss: 0.297 | sigma: 0.517\n",
      "episode: 472 | score avg: -1727.35 | loss: 0.295 | sigma: 0.532\n",
      "episode: 473 | score avg: -1716.97 | loss: 0.295 | sigma: 0.540\n",
      "episode: 474 | score avg: -1701.64 | loss: 0.300 | sigma: 0.582\n",
      "episode: 475 | score avg: -1696.56 | loss: 0.285 | sigma: 0.608\n",
      "episode: 476 | score avg: -1687.61 | loss: 0.294 | sigma: 0.571\n",
      "episode: 477 | score avg: -1685.99 | loss: 0.294 | sigma: 0.631\n",
      "episode: 478 | score avg: -1678.08 | loss: 0.290 | sigma: 0.631\n",
      "episode: 479 | score avg: -1677.45 | loss: 0.297 | sigma: 0.624\n",
      "episode: 480 | score avg: -1665.38 | loss: 0.298 | sigma: 0.608\n",
      "episode: 481 | score avg: -1658.45 | loss: 0.297 | sigma: 0.651\n",
      "episode: 482 | score avg: -1642.82 | loss: 0.324 | sigma: 0.622\n",
      "episode: 483 | score avg: -1633.30 | loss: 0.283 | sigma: 0.576\n",
      "episode: 484 | score avg: -1623.44 | loss: 0.238 | sigma: 0.490\n",
      "episode: 485 | score avg: -1607.32 | loss: 0.234 | sigma: 0.469\n",
      "episode: 486 | score avg: -1598.32 | loss: 0.297 | sigma: 0.529\n",
      "episode: 487 | score avg: -1575.19 | loss: 0.234 | sigma: 0.415\n",
      "episode: 488 | score avg: -1563.05 | loss: 0.257 | sigma: 0.466\n",
      "episode: 489 | score avg: -1559.10 | loss: 0.237 | sigma: 0.334\n",
      "episode: 490 | score avg: -1552.56 | loss: 0.292 | sigma: 0.445\n",
      "episode: 491 | score avg: -1539.24 | loss: 0.245 | sigma: 0.320\n",
      "episode: 492 | score avg: -1538.00 | loss: 0.282 | sigma: 0.400\n",
      "episode: 493 | score avg: -1531.70 | loss: 0.236 | sigma: 0.211\n",
      "episode: 494 | score avg: -1518.48 | loss: 0.238 | sigma: 0.297\n",
      "episode: 495 | score avg: -1513.99 | loss: 0.237 | sigma: 0.215\n",
      "episode: 496 | score avg: -1512.18 | loss: 0.238 | sigma: 0.229\n",
      "episode: 497 | score avg: -1506.33 | loss: 0.282 | sigma: 0.379\n",
      "episode: 498 | score avg: -1504.20 | loss: 0.236 | sigma: 0.194\n",
      "episode: 499 | score avg: -1503.81 | loss: 0.263 | sigma: 0.324\n",
      "episode: 500 | score avg: -1499.00 | loss: 0.256 | sigma: 0.163\n",
      "episode: 501 | score avg: -1498.45 | loss: 0.235 | sigma: 0.188\n",
      "episode: 502 | score avg: -1494.60 | loss: 0.247 | sigma: 0.181\n",
      "episode: 503 | score avg: -1495.84 | loss: 0.238 | sigma: 0.141\n",
      "episode: 504 | score avg: -1496.26 | loss: 0.277 | sigma: 0.283\n",
      "episode: 505 | score avg: -1495.85 | loss: 0.240 | sigma: 0.133\n",
      "episode: 506 | score avg: -1495.47 | loss: 0.235 | sigma: 0.151\n",
      "episode: 507 | score avg: -1485.02 | loss: 0.235 | sigma: 0.249\n",
      "episode: 508 | score avg: -1486.13 | loss: 0.235 | sigma: 0.156\n",
      "episode: 509 | score avg: -1489.67 | loss: 0.275 | sigma: 0.268\n",
      "episode: 510 | score avg: -1486.19 | loss: 0.244 | sigma: 0.127\n",
      "episode: 511 | score avg: -1480.71 | loss: 0.304 | sigma: 0.236\n",
      "episode: 512 | score avg: -1479.98 | loss: 0.240 | sigma: 0.126\n",
      "episode: 513 | score avg: -1479.39 | loss: 0.238 | sigma: 0.129\n",
      "episode: 514 | score avg: -1481.44 | loss: 0.240 | sigma: 0.128\n",
      "episode: 515 | score avg: -1482.68 | loss: 0.240 | sigma: 0.148\n",
      "episode: 516 | score avg: -1481.61 | loss: 0.232 | sigma: 0.155\n",
      "episode: 517 | score avg: -1481.31 | loss: 0.249 | sigma: 0.135\n",
      "episode: 518 | score avg: -1472.72 | loss: 0.240 | sigma: 0.134\n",
      "episode: 519 | score avg: -1474.57 | loss: 0.244 | sigma: 0.147\n",
      "episode: 520 | score avg: -1475.33 | loss: 0.242 | sigma: 0.127\n",
      "episode: 521 | score avg: -1476.68 | loss: 0.237 | sigma: 0.156\n",
      "episode: 522 | score avg: -1480.08 | loss: 0.292 | sigma: 0.329\n",
      "episode: 523 | score avg: -1478.91 | loss: 0.237 | sigma: 0.161\n",
      "episode: 524 | score avg: -1460.21 | loss: 0.238 | sigma: 0.139\n",
      "episode: 525 | score avg: -1451.18 | loss: 0.237 | sigma: 0.207\n",
      "episode: 526 | score avg: -1453.79 | loss: 0.238 | sigma: 0.249\n",
      "episode: 527 | score avg: -1448.77 | loss: 0.235 | sigma: 0.305\n",
      "episode: 528 | score avg: -1452.90 | loss: 0.239 | sigma: 0.235\n",
      "episode: 529 | score avg: -1458.79 | loss: 0.239 | sigma: 0.197\n",
      "episode: 530 | score avg: -1449.97 | loss: 0.250 | sigma: 0.172\n",
      "episode: 531 | score avg: -1456.59 | loss: 0.237 | sigma: 0.207\n",
      "episode: 532 | score avg: -1462.66 | loss: 0.258 | sigma: 0.292\n",
      "episode: 533 | score avg: -1465.68 | loss: 0.304 | sigma: 0.263\n",
      "episode: 534 | score avg: -1470.55 | loss: 0.239 | sigma: 0.161\n",
      "episode: 535 | score avg: -1473.56 | loss: 0.283 | sigma: 0.293\n",
      "episode: 536 | score avg: -1473.71 | loss: 0.244 | sigma: 0.133\n",
      "episode: 537 | score avg: -1471.08 | loss: 0.239 | sigma: 0.248\n",
      "episode: 538 | score avg: -1473.19 | loss: 0.239 | sigma: 0.119\n",
      "episode: 539 | score avg: -1467.85 | loss: 0.236 | sigma: 0.170\n",
      "episode: 540 | score avg: -1472.11 | loss: 0.237 | sigma: 0.151\n",
      "episode: 541 | score avg: -1473.97 | loss: 0.236 | sigma: 0.238\n",
      "episode: 542 | score avg: -1476.36 | loss: 0.288 | sigma: 0.294\n",
      "episode: 543 | score avg: -1480.81 | loss: 0.238 | sigma: 0.162\n",
      "episode: 544 | score avg: -1485.01 | loss: 0.272 | sigma: 0.255\n",
      "episode: 545 | score avg: -1484.64 | loss: 0.240 | sigma: 0.137\n",
      "episode: 546 | score avg: -1484.90 | loss: 0.297 | sigma: 0.246\n",
      "episode: 547 | score avg: -1484.01 | loss: 0.237 | sigma: 0.133\n",
      "episode: 548 | score avg: -1481.44 | loss: 0.240 | sigma: 0.193\n",
      "episode: 549 | score avg: -1483.44 | loss: 0.237 | sigma: 0.158\n",
      "episode: 550 | score avg: -1485.13 | loss: 0.288 | sigma: 0.223\n",
      "episode: 551 | score avg: -1482.11 | loss: 0.235 | sigma: 0.126\n",
      "episode: 552 | score avg: -1486.37 | loss: 0.239 | sigma: 0.194\n",
      "episode: 553 | score avg: -1490.64 | loss: 0.275 | sigma: 0.182\n",
      "episode: 554 | score avg: -1478.45 | loss: 0.235 | sigma: 0.095\n",
      "episode: 555 | score avg: -1478.17 | loss: 0.236 | sigma: 0.090\n",
      "episode: 556 | score avg: -1482.84 | loss: 0.240 | sigma: 0.147\n",
      "episode: 557 | score avg: -1483.83 | loss: 0.291 | sigma: 0.169\n",
      "episode: 558 | score avg: -1483.20 | loss: 0.242 | sigma: 0.077\n",
      "episode: 559 | score avg: -1486.07 | loss: 0.239 | sigma: 0.093\n",
      "episode: 560 | score avg: -1485.12 | loss: 0.241 | sigma: 0.121\n",
      "episode: 561 | score avg: -1485.13 | loss: 0.239 | sigma: 0.112\n",
      "episode: 562 | score avg: -1487.01 | loss: 0.285 | sigma: 0.158\n",
      "episode: 563 | score avg: -1484.82 | loss: 0.237 | sigma: 0.090\n",
      "episode: 564 | score avg: -1486.19 | loss: 0.240 | sigma: 0.101\n",
      "episode: 565 | score avg: -1490.64 | loss: 0.239 | sigma: 0.105\n",
      "episode: 566 | score avg: -1495.14 | loss: 0.239 | sigma: 0.131\n",
      "episode: 567 | score avg: -1495.09 | loss: 0.241 | sigma: 0.137\n",
      "episode: 568 | score avg: -1493.64 | loss: 0.240 | sigma: 0.113\n",
      "episode: 569 | score avg: -1490.88 | loss: 0.290 | sigma: 0.147\n",
      "episode: 570 | score avg: -1493.62 | loss: 0.238 | sigma: 0.090\n",
      "episode: 571 | score avg: -1495.03 | loss: 0.238 | sigma: 0.107\n",
      "episode: 572 | score avg: -1497.73 | loss: 0.238 | sigma: 0.088\n",
      "episode: 573 | score avg: -1500.19 | loss: 0.239 | sigma: 0.087\n",
      "episode: 574 | score avg: -1495.43 | loss: 0.235 | sigma: 0.111\n",
      "episode: 575 | score avg: -1500.70 | loss: 0.304 | sigma: 0.145\n",
      "episode: 576 | score avg: -1504.56 | loss: 0.238 | sigma: 0.128\n",
      "episode: 577 | score avg: -1509.29 | loss: 0.237 | sigma: 0.141\n",
      "episode: 578 | score avg: -1507.82 | loss: 0.254 | sigma: 0.166\n",
      "episode: 579 | score avg: -1494.56 | loss: 0.301 | sigma: 0.141\n",
      "episode: 580 | score avg: -1494.44 | loss: 0.239 | sigma: 0.113\n",
      "episode: 581 | score avg: -1490.17 | loss: 0.238 | sigma: 0.115\n",
      "episode: 582 | score avg: -1492.82 | loss: 0.240 | sigma: 0.094\n",
      "episode: 583 | score avg: -1482.23 | loss: 0.300 | sigma: 0.129\n",
      "episode: 584 | score avg: -1484.42 | loss: 0.239 | sigma: 0.093\n",
      "episode: 585 | score avg: -1474.58 | loss: 0.256 | sigma: 0.091\n",
      "episode: 586 | score avg: -1478.50 | loss: 0.239 | sigma: 0.081\n",
      "episode: 587 | score avg: -1484.73 | loss: 0.238 | sigma: 0.084\n",
      "episode: 588 | score avg: -1478.31 | loss: 0.240 | sigma: 0.099\n",
      "episode: 589 | score avg: -1484.69 | loss: 0.267 | sigma: 0.119\n",
      "episode: 590 | score avg: -1484.11 | loss: 0.256 | sigma: 0.094\n",
      "episode: 591 | score avg: -1489.18 | loss: 0.238 | sigma: 0.084\n",
      "episode: 592 | score avg: -1491.93 | loss: 0.289 | sigma: 0.097\n",
      "episode: 593 | score avg: -1493.61 | loss: 0.237 | sigma: 0.082\n",
      "episode: 594 | score avg: -1497.62 | loss: 0.236 | sigma: 0.069\n",
      "episode: 595 | score avg: -1494.73 | loss: 0.237 | sigma: 0.065\n",
      "episode: 596 | score avg: -1493.31 | loss: 0.260 | sigma: 0.067\n",
      "episode: 597 | score avg: -1492.01 | loss: 0.238 | sigma: 0.039\n",
      "episode: 598 | score avg: -1475.84 | loss: 0.235 | sigma: 0.048\n",
      "episode: 599 | score avg: -1480.53 | loss: 0.303 | sigma: 0.058\n",
      "episode: 600 | score avg: -1485.31 | loss: 0.240 | sigma: 0.040\n",
      "episode: 601 | score avg: -1469.64 | loss: 0.248 | sigma: 0.048\n",
      "episode: 602 | score avg: -1472.75 | loss: 0.238 | sigma: 0.049\n",
      "episode: 603 | score avg: -1475.70 | loss: 0.278 | sigma: 0.055\n",
      "episode: 604 | score avg: -1479.95 | loss: 0.239 | sigma: 0.042\n",
      "episode: 605 | score avg: -1482.09 | loss: 0.240 | sigma: 0.043\n",
      "episode: 606 | score avg: -1488.51 | loss: 0.237 | sigma: 0.037\n",
      "episode: 607 | score avg: -1490.50 | loss: 0.238 | sigma: 0.046\n",
      "episode: 608 | score avg: -1490.29 | loss: 0.241 | sigma: 0.042\n",
      "episode: 609 | score avg: -1482.49 | loss: 0.235 | sigma: 0.050\n",
      "episode: 610 | score avg: -1488.75 | loss: 0.310 | sigma: 0.056\n",
      "episode: 611 | score avg: -1489.98 | loss: 0.310 | sigma: 0.072\n",
      "episode: 612 | score avg: -1492.75 | loss: 0.268 | sigma: 0.086\n",
      "episode: 613 | score avg: -1492.75 | loss: 0.239 | sigma: 0.066\n",
      "episode: 614 | score avg: -1498.46 | loss: 0.238 | sigma: 0.072\n",
      "episode: 615 | score avg: -1503.39 | loss: 0.307 | sigma: 0.082\n",
      "episode: 616 | score avg: -1502.99 | loss: 0.306 | sigma: 0.089\n",
      "episode: 617 | score avg: -1504.21 | loss: 0.236 | sigma: 0.083\n",
      "episode: 618 | score avg: -1510.30 | loss: 0.238 | sigma: 0.074\n",
      "episode: 619 | score avg: -1516.82 | loss: 0.303 | sigma: 0.082\n",
      "episode: 620 | score avg: -1519.04 | loss: 0.239 | sigma: 0.066\n",
      "episode: 621 | score avg: -1518.92 | loss: 0.309 | sigma: 0.075\n",
      "episode: 622 | score avg: -1518.30 | loss: 0.246 | sigma: 0.075\n",
      "episode: 623 | score avg: -1517.78 | loss: 0.295 | sigma: 0.083\n",
      "episode: 624 | score avg: -1510.58 | loss: 0.238 | sigma: 0.070\n",
      "episode: 625 | score avg: -1507.83 | loss: 0.301 | sigma: 0.075\n",
      "episode: 626 | score avg: -1522.28 | loss: 0.309 | sigma: 0.065\n",
      "episode: 627 | score avg: -1527.42 | loss: 0.276 | sigma: 0.076\n",
      "episode: 628 | score avg: -1519.39 | loss: 0.703 | sigma: 0.072\n",
      "episode: 629 | score avg: -1526.83 | loss: 0.295 | sigma: 0.078\n",
      "episode: 630 | score avg: -1534.34 | loss: 0.311 | sigma: 0.058\n",
      "episode: 631 | score avg: -1541.36 | loss: 0.310 | sigma: 0.065\n",
      "episode: 632 | score avg: -1542.01 | loss: 0.322 | sigma: 0.072\n",
      "episode: 633 | score avg: -1538.02 | loss: 0.309 | sigma: 0.077\n",
      "episode: 634 | score avg: -1541.93 | loss: 0.307 | sigma: 0.089\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2f3eff565711>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'losses'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                 \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./save_model/pendulum_sac.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0;31m# 이동 평균이 400 이상일 때 종료\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf240_gpu/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 937\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    938\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# need this if 'transparent=True' to reset colors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf240_gpu/lib/python3.7/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[1;32m   2960\u001b[0m                 \u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_edgecolor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'none'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2962\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2964\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtransparent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf240_gpu/lib/python3.7/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2259\u001b[0m                         \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2260\u001b[0m                         \u001b[0mbbox_inches_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_bbox_inches_restore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2261\u001b[0;31m                         **kwargs)\n\u001b[0m\u001b[1;32m   2262\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2263\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbbox_inches\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrestore_bbox\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf240_gpu/lib/python3.7/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1667\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1669\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf240_gpu/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs, *args)\u001b[0m\n\u001b[1;32m    506\u001b[0m             \u001b[0;34m*\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincluding\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0;34m'Software'\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m         \"\"\"\n\u001b[0;32m--> 508\u001b[0;31m         \u001b[0mFigureCanvasAgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m         mpl.image.imsave(\n\u001b[1;32m    510\u001b[0m             \u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer_rgba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"png\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morigin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"upper\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf240_gpu/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0;31m# docstring inherited\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_renderer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleared\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m         \u001b[0;31m# Acquire a lock on the shared font cache.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mRendererAgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlock\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf240_gpu/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mget_renderer\u001b[0;34m(self, cleared)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         reuse_renderer = (hasattr(self, \"renderer\")\n\u001b[0;32m--> 415\u001b[0;31m                           and getattr(self, \"_lastKey\", None) == key)\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreuse_renderer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRendererAgg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%matplotlib tk\n",
    "\n",
    "ENV_NAME = 'Pendulum-v0'\n",
    "EPISODES = 1000\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    env = gym.make(ENV_NAME)\n",
    "    state_size = env.observation_space.shape[0]\n",
    "    action_size = env.action_space.shape[0]\n",
    "\n",
    "    agent = CACAgent(state_size, action_size,\n",
    "                        env.action_space.low[0],\n",
    "                        env.action_space.high[0])\n",
    "    scores, episodes, losses, sigmas = [], [], [], []\n",
    "    score_avg = 0\n",
    "\n",
    "    end = False\n",
    "    \n",
    "    for e in range(EPISODES):\n",
    "        done = False\n",
    "        score = 0\n",
    "        loss_list, sigma_list = [], []\n",
    "\n",
    "        state = env.reset()\n",
    "        state = np.reshape(state, [1, state_size])\n",
    "\n",
    "        while not done:\n",
    "            env.render()\n",
    "\n",
    "            action = agent.get_action(state)\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            next_state = np.reshape(next_state, [1, state_size])\n",
    "\n",
    "            score += reward\n",
    "            reward = 0.1 if not done or score == 500 else -1\n",
    "\n",
    "            loss, sigma = agent.train_model(state, action, reward, next_state, done)\n",
    "            loss_list.append(loss)\n",
    "            sigma_list.append(sigma)\n",
    "            \n",
    "            state = next_state\n",
    "            if done:\n",
    "                score_avg = 0.9 * score_avg + 0.1 * score if score_avg != 0 else score\n",
    "                print(\"episode: {:3d} | score avg: {:3.2f} | loss: {:.3f} | sigma: {:.3f}\".format(\n",
    "                      e, score_avg, np.mean(loss_list), np.mean(sigma)))\n",
    "\n",
    "                episodes.append(e)\n",
    "                scores.append(score_avg)\n",
    "                losses.append(np.mean(loss_list))\n",
    "                sigmas.append(np.mean(sigma))\n",
    "\n",
    "                plt.subplot(311)\n",
    "                plt.plot(episodes, scores, 'b')\n",
    "                plt.xlabel('episode')\n",
    "                plt.ylabel('average score')\n",
    "                plt.title('pendulum SAC')\n",
    "                plt.grid()\n",
    "                \n",
    "                plt.subplot(312)\n",
    "                plt.plot(episodes, sigmas, 'b')\n",
    "                plt.xlabel('episode')\n",
    "                plt.ylabel('sigma')\n",
    "                plt.grid()\n",
    "                \n",
    "                plt.subplot(313)\n",
    "                plt.plot(episodes, losses, 'b')\n",
    "                plt.xlabel('episode')\n",
    "                plt.ylabel('losses')\n",
    "                plt.grid()\n",
    "                plt.savefig(\"./save_model/pendulum_sac.png\")\n",
    "\n",
    "                # 이동 평균이 400 이상일 때 종료\n",
    "                if score_avg > 400:\n",
    "                    agent.model.save_weights(\"./save_model/pendulum_sac\", save_format=\"tf\")\n",
    "                    end = True\n",
    "                    break\n",
    "        if end == True:\n",
    "            env.close()\n",
    "            np.save('./save_model/pendulum_sac_epi',  episodes)\n",
    "            np.save('./save_model/pendulum_sac_score',scores)\n",
    "            np.save('./save_model/pendulum_sac_loss', losses)\n",
    "            np.save('./save_model/pendulum_sac_sigmas', sigmas)\n",
    "            print(\"End\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./save_model/pendulum_sac_epi',  episodes)\n",
    "np.save('./save_model/pendulum_sac_score',scores)\n",
    "np.save('./save_model/pendulum_sac_loss', losses)\n",
    "np.save('./save_model/pendulum_sac_sigmas', sigmas)\n",
    "agent.model.save_weights(\"./save_model/pendulum_sac\", save_format=\"tf\")"
   ]
  }
 ]
}